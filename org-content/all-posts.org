# -*- mode: org; mode: visual-line; mode: visual-fill-column; mode: org-hugo-auto-export -*-
#+hugo_section: post/
#+hugo_base_dir: ../
#+export_hugo_weight: auto
#+hugo_auto_set_lastmod: t
#+startup: inlineimages
#+startup: logdone
#+property: header-args:sql :session reporter :exports result :colnames yes  :engine postgresql :results replace table
#+hugo_paired_shortcodes: %table %marginnote %newthought
#+macro: newthought @@hugo:{{% newthought %}}@@$1@@hugo:{{% /newthought %}}@@
#+macro: marginnote @@hugo:{{% marginnote %}}@@$1@@hugo:{{% /marginnote %}}@@
#+macro: sc @@hugo:{{% $1 %}}@@
#+macro: <sc @@hugo:{{< $1 >}}@@

#+seq_todo: TODO DRAFT DONE

* Bakehouse Diary :@bakehouse-diary:
:PROPERTIES:
:export_hugo_custom_front_matter: :series "Bakehouse Diary"
:ID:       1704207D-154F-4BA2-A7AA-35585A21295E
:END:

** Bakehouse Diary
:PROPERTIES:
:export_file_name: back-to-the-bakehouse
:export_date: [2018-02-01 Thu]
:export_hugo_custom_front_matter: :description "Back to the bakehouse" :series "Bakehouse Diary"
:ID:       A734F151-393D-4609-A408-8942FE197BBB
:END:

I know! It's been a while. But we're in! I have baked, and it was
good. There's still a ton of stuff to do (plumbing, mostly) but the
really important bits of kit are all in place and looking good.

We celebrated getting in by turning one of the decks up as high as it
would go and making lots of pizzas and a few loaves of bread.

#+attr_html: :width 100%
#+caption: An early pizza
[[file:./back-to-the-bakehouse/margherita-pizza.jpg]]

#+hugo: more

*** The story so far…
    :PROPERTIES:
    :ID:       9B5B244B-A654-4254-BCEA-9CE31C600321
    :END:

In my [[file:/2016/11/11/taking-stock/][last entry]] (over a year ago, argh! Gill is /much/ better) the
oven and all my kit were still in my garage, up on blocks waiting for
Dad to build an A-frame so we could winch it up and assemble it. Which
happened, and we managed to get one section of oven up onto the base.
And there we stopped because the fully assembled oven is very tall, and
the A-frame isn't tall enough to accommodate a fully assembled oven +
the winch + space for the straps (and my garage roof isn't high enough
to accommodate a sufficently tall A-frame). Still, it allowed us to
start in on prEocess of breaking the heads of very old brass
machine screws and generally failing to get the oven beds out where
they could be cleaned. This was frustrating, but it's not like I was
unused to frustration.

Meanwhile, the bakehouse site moved again. We had thought it would be
a relatively easy (and thus cheap) matter to run the necessary 3-phase
power to the space, but it turns out there wasn't quite enough power
going to the building to support what we needed. That would mean a new
substation and some very expensive cable laying. So it wasn't going to
fly. Luckily, there is also an old cafe in the yard. And it already has 3
phase, and enough 3 phase at that. So we set about making that into a
bakehouse. A lick of paint; some new flooring; wider, taller doorways
so we could get the oven in. Minor stuff like that.

By now we're up to late spring of 2017. I'd given up on trying to
renovate the decks myself, so I got onto Martin Passey at [[http://becketts.co.uk/][Becketts]] and
arranged for them to sort out the electrics and replace the rusty
steel beds with ceramic ones instead, which are generally reckoned to
be the best choice if you want to make 'hearth' breads on the oven
floor. We just needed to work out how to get the oven from Doncaster
to Heywood.

Guess what? It wasn't straightforward.

When we picked up my oven from the Isle of Wight, we'd got it into a
large Luton bodied van with a tail lift, and it was kind of fine. I
suppose I could have hired another one, roped in a few volunteers and
driven it over myself, but the fact that we'd partially assembled the
oven was going to make that rather trickier than it could have been.
Disassembling it was going to be tricky too - after we got the straps
out from the top decks when we'd assembled it, we discovered we'd been
very lucky indeed, and the strap had /very/ nearly broken.

The best option was to get a flatbed truck with a Hiab or similar
hydraulic crane which would make short work of getting the oven up
onto the truck and off to be fettled. But the access (up a 10 foot
wide back lane) proved daunting. All the haulage companies I talked to
took one look at it and backed away, muttering darkly and making the
sign of the cross. "Get a bunch of strong Polish lads to carry it down
the alley and stick it on the back of a truck" was the best (but very
unofficial) suggestion. Not ideal.

So now it's July and I'm chatting to a fellow guest at my brother's
silver wedding anniversary about my shipping woes. "You want to talk
to Dan!" he said.

"Dan?"

"Yeah, [[http://www.danpunchard.co.uk/][Dan Punchard]]. He's great, he's moved a couple of lathes for me
with some really tight access."

"Thanks!"

My informant was not wrong. Dan was brilliant. We exchanged a few
emails and photos of the access and /bang/ the oven was off into the
tender loving care of Becketts for its electrical fettling and new
floors. And soon the money was flowing out of my savings as I bought a
new spiral mixer, wire cooling baskets, steel work table, scales (both
electronic for weighing ingredients into the mixer and a balance
scale, which is /still/ the fastest way of scaling dough when you
divide it), lots of [[https://www.bakerybits.co.uk/bakery-equipment/proving-baskets-and-cloths/wicker-baskets/heavy-duty.html][bannetons]] (probably not enough) from Bakery Bits,
workwear, flour, wire shelving, and a bewildering amount of janitorial
bits and bobs from [[https://nisbets.co.uk/][Nisbets]]. Fettling the oven wasn't exactly cheap,
but wow, do those baskets add up!

*** It's arrived, and it fits
    :PROPERTIES:
    :ID:       AD747BAF-5C59-4456-B10E-EC021530372C
    :END:

On the 8th of December last year I sent mail Martin some mail with the
subject "It's arrived, and it fits!" and over the next couple of weeks
the rest of the stuff I needed to bake arrived and, on the 20th of
December, I fired up the mixer for batch of 16 loaves and what proved
to be far too many pizza doughballs.

On Friday 21st of December, I pulled my first loaves out of my ~40
year old oven, and /damn/, but they were good.

#+attr_html: :width 100%
#+caption: The first loaf
[[file:./back-to-the-bakehouse/first-loaf.jpg]]

*** What next?
    :PROPERTIES:
    :ID:       6006477E-9259-4548-BE06-AA284C35787B
    :END:

Of course, no enterprise like this is ever finished, here's a
selection from my to do list.


**** Plumbing
     :PROPERTIES:
     :ID:       C3EF1AE5-0633-4355-9A9E-AADC63202AC2
     :END:
A bigger sink! Water near the scale so I'm not carrying buckets
back and forth! A handwash basin!

**** Qualifications
     :PROPERTIES:
     :ID:       D2940478-569D-4A68-8A85-A3FB832E0DD7
     :END:
Environmental Health Officers do like you to have a certificate
to show you're not a complete moron when it comes to hygiene.
Breadmaking is relatively low risk because everything gets so
very hot during the cooking process, but even so.

**** Refrigeration
     :PROPERTIES:
     :ID:       7C336767-BFD8-4C6F-AB3F-379D615EF2CF
     :END:
Right now everything's at the ambient temperature, which can mean
staying in the bake house until the early hours in order to get
the loaves into the oven when they're perfectly proved. A better
approach would be to stick the dough into a retarder (big
fridge, racked for standard bakers' sheet pans) and bake them
first thing in the morning after a decent night's sleep. I have a
retarder, but transport is annoyingly tricky because it's 2m
tall, and should ideally be transported vertically too.

**** Fitness
     :PROPERTIES:
     :ID:       0599F968-72F3-467F-B4A8-5ADE5EBC6548
     :END:
Right now, I can just about cope with two bakes a week, but if
I'm going to actually make money at this, I'm going to need to be
able to manage more. Hopefully, as I bake it'll improve my
fitness, so as demand grows I'll be able to meet it.

**** Marketing
     :PROPERTIES:
     :ID:       584A5EC0-B1AA-425F-80E1-071BE00980FD
     :END:
Oh boy, do I suck at marketing? Still, the product is good and
there's nobody else in the local area making this sort of bread,
so I have a few advantages. I still haven't made a Loafery
website though. At least I have the loafery.co.uk domain.

**** Online ordering
     :PROPERTIES:
     :ID:       FD89D3AC-84C8-4884-B2B4-FA445111D76D
     :END:
If I can get people ordering online, I can use that to produce
production schedules, and generally have a better idea of how
much to make on each bake day, which help minimise any wasted
bread. With two bakes done this year, I've sold every loaf - I'd
like to keep that up.

*** In the next bakehouse diary...
    :PROPERTIES:
    :ID:       6B4B05DF-007B-4559-ACFE-BB21BCEADA42
    :END:
I'll talk about how a bake goes and the process of developing an
initial range of products, sourcing flour and other ingredients
and hopefully some news about online ordering.




** DRAFT Literate Baking
:PROPERTIES:
:EXPORT_DATE: 2018-10-25
:export_file_name: literate-baking
:ID:       466D29CA-D294-4651-8529-202BB121098A
:END:

My baking day goes like this:

I come into the bakehouse, open up Emacs and type =M-m o c B= and up comes the skeleton of an entry for my baking daybook. I review it quickly, then type =C-c C-c=

** DONE Running a bakery on Emacs and PostgreSQL
:PROPERTIES:
:EXPORT_FILE_NAME: baking-with-emacs
:export_hugo_slug: baking-with-emacs
:export_hugo_custom_front_matter: :series "Bakehouse diary"
:export_date: 2019-02-25
:ID:       92F8529F-9830-4DE4-8E26-61B606BAF48B
:END:

Just over a year ago now, I finally opened the bakery I'd been dreaming of for years. It's been a big change in my life, from spending all my time sat in front of a computer, to spending most of it making actual stuff. And stuff that makes people happy, at that. It's been a huge change, but I can't think of a single job change that's ever made me as happy as this one.

#+hugo: more

One of the big changes that came with going pro was that suddenly I was having to work out how much stuff I needed to mix to fill the orders I needed. On the face of it, this is really simple, just work out how much dough you need, then work out what quantities to mix to make that much dough. Easy. You can do it with a pencil and paper. Or, in traditional bakers' fashion, by scrawling with your finger on a floured work bench.

And that's how I coped for a few weeks early on. But I kept making mistakes, which makes for an inconsistent product (bread is very forgiving, you have to work quite hard to make something that isn't bread, but consistency /matters/). I needed to automate.

I'd been on one of Bread Matters' "Baking for a Living" courses and as part of the course materials had received a copy of a spreadsheet that could be used to go from a list of orders to a list of ingredients to mix alongside accurate costings and other useful bits and bobs. It was great and certainly opened my eyes to the possibilities for automation of this part of the job.

And then I tried to add a new recipe.

Spreadsheets aren't my favourite computational model so maybe it was just my lack of experience with them, but adding a new recipe was like pulling teeth; lots of tedious copying, pasting and repetition of formulae. It just seemed wrong, especially as the underlying computations were so straightforward (ish). There had to be a better way.

The key insight is that a bakery formula is so cliched that it can be represented as data. Here's the formula for seedy malt loaves:

| recipe           | ingredient       | quantity |
|------------------+------------------+----------|
| Small Seedy Malt | Seedy malt dough | .61 kg   |
| Large Seedy Malt | Seedy malt dough | .92 kg   |

Of course, that's not the full set of formulae, because it doesn't tell you how to make 'Seedy malt dough', but that's just another formula, which consists of flour, water, starter, salt and a multiseed 'soaker', where the starter and the soaker are the results of other formulae, which are (finally) made from basic ingredients. @@hugo:{{%marginnote%}}@@ With a certain amount of handwaving to deal with the fact that a starter is strictly made with flour, water and starter.@@hugo:{{%/marginnote%}}@@ I did consider reaching for the object oriented hammer at this point, but thought that I might be able to do everything I needed without leaving SQL. It was relatively straightforward to move the shape of the calculations in the Bread Matters spreadsheet into my database schema, the only real sticking point being the recursive nature of the formulae, but it turns out that recursive queries are a thing in modern SQL, albeit a little tricky to get absolutely right@@hugo:{{% marginnote %}}@@A few bakes went a little weird before I finally got things sorted.@@hugo:{{% /marginnote %}}@@ first time.
If you're curious about the details of the schema, you can find it in my [[https://github.com/pdcawley/bakehouse][github repo]] for the bakery.@@hugo:{{% marginnote %}}@@ And several of you seem to be, so I wrote [[file:/2019/03/04/recursive-sql-recipes/][another post]] with a bit more detail and some sample code.@@hugo:{{% /marginnote %}}@@

So now, a few days before a bake, I'd setup my ~production_order~ table with the orders for the bake, and run a query on the ~production_list~ view to find out what I needed to mix when. And all was great. Well, sort of. I had to add a bit extra onto the quantities in the initial starter mix to allow for the bits that get stuck to the bowl and lost to the final dough, and it was all very well until I wanted to bake two days in a row (a bake is a two day process from mixing the starters on a Wednesday evening, through mixing, fermenting and shaping on Thursday to baking the resulting loaves at four on Friday morning). But, vitally, it was much, much easier to add and adjust formulae, and the limitations were no worse than the limitations of the spreadsheet. All was well.

It's the nature of business that you need to keep records. How much got baked? How much sold? Did we clean the floor? Were there any accidents? What sort? How do we prevent them next time? The list is endless. It all needs to be recorded, for both legal and pragmatic reasons. So I started a day book. This is just an .org file@@hugo:{{% marginnote %}}@@ Org-mode is an amazing emacs package that's a sort of outliner/task manager/publishing tool/spreadsheet/diary/literate programming environment. It's bewilderingly capable, and is probably the primary driver of the emacs renaissance as people are coming to the editor for org-mode, and porting the rest of their environment - hence the rise of ~evil-mode~, the emacs vim emulation layer.@@hugo:{{% /marginnote %}}@@ Every day I come into the bakery, I run ~org-capture~ and I get a template for the day's entry in the daybook, which I fill in as the day goes on.

One of the features of org-mode is ~org-babel~, a literate programming environment, which lets me write something like:

#+name: 07CEE761-D52F-4A44-B4C6-4F6284D947BB
#+begin_src org
,#+begin_src sql
SELECT ingredient, quantity
  FROM bakehouse.production_list
 WHERE work_date = 'today';
,#+end_src
#+end_src

and then, with the cursor somewhere in the code block, hit ~C-c C-c~ whereupon Emacs will run that SQL against the bakery database and populate a table like:

| ingredient  | quantity |
|-------------+----------|
| Old starter |      1.3 |
| Water       |     2.08 |
| White flour |      2.6 |
| ...         |      ... |

If that were all org-mode did to assist, it'd be awesome enough, but the queries I make are a little more complex than that, the current version of the database understands about dates and can cope with overlapping bakes, but all that makes the queries a little more complex. Org-mode helps with that too, because I can file away snippets of code in a 'library of babel' and just reference them from the daybook. And I can set arbitrary variables at any point in the hierarchy of the document.

So I have a bit of code in my emacs config that tweaks the day's entry in a daybook like so:

#+name: 1A928B6D-FED5-44C5-9AD1-5E50181B0199
#+begin_src emacs-lisp
  (defun pdc//in-bakery-daybook? ()
    "Are we in the bakery daybook?"
    (equal (buffer-name) "CAPTURE-loafery-daybook.org"))

  (defun pdc/set-daybook-entry-properties ()
    "Set the properties we rely on in our boilerplated daybook queries"
    (save-excursion
      (while (not (looking-at "*+ [[:digit:]]\\{4\\}\\(-[[:digit:]]\\{2\\}\\)\\{2\\}"))
        (org-up-element))
      (let ((entry-date (first (s-split " " (org-entry-get (point) "ITEM")))))
        (org-entry-put
         (point)
         "header-args+"
         (format ":var work_date=\"'%s'\"" entry-date)))
      (org-babel-execute-subtree)))

  (defun pdc/org-capture-before-finalize-daybook-entry ()
    (when (pdc//in-bakery-daybook?)
      (pdc/set-daybook-entry-properties)))

  (add-hook 'org-capture-before-finalize-hook
            #'pdc/org-capture-before-finalize-daybook-entry)
#+end_src

It won't win any code beauty contests, but it does the job of setting a ~work_date~ variable for the day's entry and running any code in the subtree as part of the capture process. The capture template has lines like ~#+call:mixes()~, which call the stored code snippets, that reference the variable set in the current subtree and so make the query for the right day. This means that all I have to do to know what I should be doing when I get into the bakehouse is to run an org-capture and check the resulting entry in my daybook. Provided, that is, that I've added the appropriate rows to the database.

*** Next steps
    :PROPERTIES:
    :ID:       30E7B083-080A-45CC-AED5-A9D55E210170
    :END:

The software isn't done, of course, no software ever is. But it's good enough that it's been managing my mixes without a hitch for the last few months, telling me what to pack for which customer and generally removing the need to work anything out with a pencil and paper. It's nowhere near as mature or capable of commercial production management software, but it fits me. I understand what it does and why, how it does it, the limitations it has and how to work around them. When it becomes annoying enough, I might sit down and work out how to fix it, but I'll do that when I'm in the right frame of mind. My current list of niggles looks something like this:

- Accounting :: The database already knows how to do costings based on raw ingredient costs etc, but I should probably be able to use it to keep my books as well, using ~org-ledger~
- Parametric recipes :: At a certain point, it becomes easier to mix a 'stiff starter' in my mixer than it is to just mix the usual wet starter by hand. This breakpoint comes at around 3kg of flour. Right now, I manage this by looking at the mixes for my starters and, if it looks like a lot, changing the order to use 2-stage versions of the formulae and running the query again. I think it should be possible to automate this through a more sophisticated query, but I need to work that out.
- Better scheduling :: things get weird if a batch of dough would be more than I can mix in a single go. Right now there are other physical limitations that mean that I simply can't make that much bread anyway, but once I get a few more bannetons and racks, this will become a much more pressing issue.
- Order management :: Right now, I manage orders through Postico talking to the database, which is okay, but a little frustrating in places. An autocompleting environment for orders within emacs would be a much neater way to manage things.

*** Putting the personal in personal computing
    :PROPERTIES:
    :ID:       EB0497C2-51A6-4452-8CEE-E587BE2AA695
    :END:
Computers are amazing. They are versatile tools even if you don't know how to program them, because there's almost always an app for what you want, or something close enough that you cant work around its infelicities. It's quite remarkable the things that folks can do with their kit with no programming skill at all.

But... learn to program, and a whole other vista of possibility opens up to you. With good programmable tooling you're only really limited by your skill and understanding. Instead of accommodating yourself to your software, you can accommodate your software to you, and make the right functionality trade-offs for you. There's a brilliant commercial piece of music looping sofware I use that could be massively more brilliant if there were a way of picking up the tempo automatically from the first recorded loop - it would free me from having to sing to a click and generally make the whole process easier. The developers have other (understandable) priorities, like porting the app to windows. And they're not wrong to do so. There were folk clamoring for a windows version, and if a developer isn't making money from a commercial application, then development will stop. I'm definitely not complaining, the feature is not so dramatically necessary that I'm prepared to spend the time learning how to do real time music programming in order to implement it, but if I want software to dance to /my/ tune then doing it myself is the only way.

So... choose tools that let you program them. I choose emacs and PostgreSQL, you might choose vim and SQLite or Atom and a NoSQL database, or you might just live in your Smalltalk image. Once you start to see your computing environment as truly soft and malleable, you can do amazing things, assisted by a computer that is truly /yours/.


** DONE "A recipe is just a directed acyclic graph…"
:PROPERTIES:
:export_hugo_slug: recursive-sql-recipes
:export_file_name: recursive-sql-recipes
:export_date: 2019-03-04
:export_hugo_custom_front_matter: :series "Bakehouse diary" :math true
:ID:       F00B26A5-3E3A-42EC-858E-77A47CA209E3
:END:

In [[file:/2019/02/25/baking-with-emacs][the last post]] I handwaved the way I represented bakery formulae in the bakery database, so here's a little more detail. It helps to think of a bakery formula as a node on a directed acyclic@@hugo:{{% marginnote %}}@@If you ignore the fact that a starter is made of flour, water and starter. Which, of course, we're going to.@@hugo:{{% /marginnote %}}@@ graph with weighted edges, where the weights are literally weights. Here's the graph a for a  couple of products

# #+begin_src dot :file formulae.svg :exports none :results file :cmdline -Tsvg
# digraph G {
# rankdir=LR;
# node [shape=box];
# { rank = same; "5 seed soaker"; "80% starter"; }
# { rank = same; node [shape=ellipse]; "water"; "white flour"; "salt"; "malthouse flour";
# "5 seed mix"; }

# "Small Seedy Malt" -> "Seedy Malt Dough" [label="600g"];
# "Small White Wild" -> "Basic White Sour" [label="600g"];

# "Basic White Sour" -> "80% starter" [label="90%"];
# "Basic White Sour" -> "white flour" [label="100%"];
# "Basic White Sour" -> "water" [label="55%"];
# "Basic White Sour" -> "salt" [label="3%"];

# "Seedy Malt Dough" -> "5 seed soaker" [label="50%"];
# "Seedy Malt Dough" -> "80% starter" [label="45%"];
# "Seedy Malt Dough" -> "malthouse flour" [label="100%"];
# "Seedy Malt Dough" -> "water" [label="47.5%"];
# "Seedy Malt Dough" -> "salt" [label="3%"];

# "5 seed soaker" -> "5 seed mix" [label="100%"];
# "5 seed soaker" -> "water" [label="120%"];

# "80% starter" -> "white flour" [label="100%"];
# "80% starter" -> "water" [label="80%"];
# }
# #+end_src

#+results:
#+begin_RESULTS
[[file:formulae.svg]]
#+end_RESULTS

#+hugo: more

And here's how we represent that in the database@@hugo:{{% marginnote %}}@@This table is the result of a query on my real database, where the quantities are in kg, as opposed to the graph representation which was handrolled and adjusted to use bakers' percentages which is how formulae are traditionally written.@@hugo:{{% /marginnote %}}@@:

#+begin_comment
#+begin_src sql :exports results
WITH RECURSIVE f(name,ingredient,amount) AS (
  SELECT recipe, ingredient, amount
    FROM bakehouse.recipe_item
   WHERE recipe IN ('Small Seedy Malt', 'Small White Wild')
 UNION
  SELECT ri.recipe, ri.ingredient, ri.amount
   FROM f
   JOIN bakehouse.recipe_item ri ON ri.recipe = f.ingredient
)
select name, ingredient, format('%s kg', ROUND(amount, 2)) from f order by name;
#+end_src
#+end_comment

#+results:
| name             | ingredient                    | format  |
|------------------+-------------------------------+---------|
| Small Seedy Malt | Seedy Malt Dough              | 0.63 kg |
| Small White Wild | Basic White Sour              | 0.63 kg |
| Basic White Sour | Organic white flour           | 2.00 kg |
| Basic White Sour | Sea salt                      | 0.06 kg |
| Basic White Sour | Water                         | 1.10 kg |
| Basic White Sour | 80% starter                   | 1.80 kg |
| Seedy Malt Dough | 5 Seed Soaker                 | 4.00 kg |
| Seedy Malt Dough | Water                         | 3.80 kg |
| Seedy Malt Dough | Sea salt                      | 0.22 kg |
| Seedy Malt Dough | 80% starter                   | 3.60 kg |
| Seedy Malt Dough | Organic light malthouse flour | 8.00 kg |
| 5 Seed Soaker    | Water                         | 1.20 kg |
| 5 Seed Soaker    | 5 seed mix                    | 1.00 kg |
| Mother           | Water                         | 3.20 kg |
| Mother           | Organic white flour           | 4.00 kg |

Suppose we have an order for 8 Small White loaves. We need to know how much starter to mix tonight. We know that we need 0.63 kg of dough for each loaf, so that's a total of 5.04 kg of Basic White Sour. The formula for Basic White Sour makes a total of $1.10 + 1.80 + 0.06 + 2.00 = 4.96 \mathrm{kg}$ of dough. So we need to multiply each quantity in that formula by the weight of dough we need divided by the total weight of the recipe $(5.04/4.96 = 1.016)$. This is straightforward enough for flour, water and salt, which are basic ingredients, but we'll need to do a similar calculation to work out how much flour and water we'll need to make $1.016 × 1.8 = 1.829 \mathrm{kg}$ of starter. You can see how this might become a little tedious.

If I were going to be doing these calculations by hand, it would definitely pay me to normalize my intermediate formulae so they all made a total of 1 kg of stuff. But screw that, we have a computer, so we can make it do the work.

I'm going to simplify things a little (the real database understands about dates, and we need to know a little more about recipes, products and ingredients than will fit in the ~recipe_item~ table that describes the graph) but this should give you an idea of the recursive queries that drive production planning.

Let's introduct a ~production_order~ table, where we stash our orders@@hugo:{{% marginnote %}}@@The real table has extra information about customers and order dates: @@hugo:{{% /marginnote %}}@@

| product          | quantity |
|------------------+----------|
| Small White Wild |        5 |
| Small Seedy Malt |        5 |

And that's all we need to fire off a recursive query. @@hugo:{{% marginnote %}}@@ I'm writing this using the literate programming capabilities of org-mode, so the code you see is being run against my production database, and the results are using my working formulae. Which is why we're not querying the real ~production_order~ table.@@hugo:{{% /marginnote %}}@@

#+name: 6A645983-A0FF-42B1-A9D8-A0756FCD1A45
#+begin_src sql
WITH RECURSIVE po(product, quantity) AS (
    SELECT 'Small White Wild', 5
  UNION
    SELECT 'Large White Wild', 5
), rw(recipe, weight) AS (
    SELECT recipe, sum(amount)
      FROM bakehouse.recipe_item
  GROUP BY recipe
), job(product, ingredient, quantity) AS (
    SELECT po.product,
           ri.ingredient,
           po.quantity * ri.amount
      FROM po
      JOIN bakehouse.recipe_item ri ON po.product = ri.recipe
      JOIN rw ON ri.recipe = rw.recipe
  UNION
    SELECT job.ingredient, ri.ingredient, job.quantity * ri.amount / rw.weight
      FROM job
      join bakehouse.recipe_item ri on job.ingredient = ri.recipe
      join rw on job.ingredient = rw.recipe
)
SELECT product formula, ingredient, ROUND(sum(quantity),2) quantity from job group by job.product, job.ingredient order by formula;
#+end_src

Which gives the following result:

#+results:
| formula          | ingredient          | quantity |
|------------------+---------------------+----------|
| Basic White Sour | Sea salt            |     0.09 |
| Basic White Sour | Water               |     1.72 |
| Basic White Sour | Mother              |     2.81 |
| Basic White Sour | Organic white flour |     3.13 |
| Large White Wild | Basic White Sour    |     4.65 |
| Mother           | Organic white flour |     1.56 |
| Mother           | Water               |     1.25 |
| Small White Wild | Basic White Sour    |     3.10 |

A quick sanity check seems to show this is correct (we're making 7.75kg of Basic White Sour, which tallies with the weights needed to make the loaves).
So what's going on in the query? In SQL, ~WITH~ is a way of giving names to your intermediate results, akin to ~let~ in a Lisp. We fake up a table to hold our production orders (~po~) and the ~rw~ clause is totals the weights of all our recipes (in the real database, it's a view). The magic really starts to happen when you use the ~WITH RECURSIVE~ form. With ~RECURSIVE~ in play, the last query is treated differently. Instead of being a simple two part ~UNION~ what happens is that we first run:

#+name: 729E572D-94B2-4170-8561-FA051EE59B22
#+begin_src sql
SELECT po.product, ri.ingredient, po.quantity * ri.amount
  FROM po
  JOIN bakehouse.recipe_item ri on po.product = ri.recipe
  JOIN rw on ri.recipe = rw.recipe
#+end_src

and call the results ~job~ and then run the second query, adding any extra rows generated to the results, and repeating that query until the result set stops growing. If we didn't have ~WITH RECURSIVE~ available, and we knew the maximum depth of recursion we would need, we could fake it by making a bunch of intermediate clauses in our ~WITH~. In fact, until I worked out how ~WITH RECURSIVE~ works, that's exactly what I did.

Have you spotted the mistake? I didn't, until a few bakes when horribly wrong.

Here's what happens when we have an order for 3 small loaves and two large ones

| formula          | ingredient          | quantity |
|------------------+---------------------+----------|
| Basic White Sour | Sea salt            |     0.02 |
| Basic White Sour | Water               |     0.41 |
| Basic White Sour | Mother              |     0.68 |
| Basic White Sour | Organic white flour |     0.75 |
| Large White Wild | Basic White Sour    |     1.86 |
| Mother           | Organic white flour |     0.38 |
| Mother           | Water               |     0.30 |
| Small White Wild | Basic White Sour    |     1.86 |

We're only making 1.86 kg of dough? What's going on?

It turns out that the way a ~UNION~ works is akin to doing ~SELECT DISTINCT~ on the combined table, so it selects only unique rows. When two orders end up requiring exactly the same amount of the 'same' dough, they get smashed together and we lose half the weight. This is not ideal.@@hugo:{{% marginnote %}}@@It's /especially/ not ideal when you don't spot there's a problem and end up making far fewer loaves than you expect. Or on one /really/ annoying occasion, making a dough that was far too dry because we lost some water along the way. You can correct this during the mix, but it was a nasty shock.@@hugo:{{% /marginnote %}}@@ I fixed it by adding a 'path' to the query, keeping track of how we arrived at a particular formula. Something like:

#+name: 48148626-CBC5-4AF1-9E88-7821F8099F36
#+begin_src sql
WITH RECURSIVE po(product, quantity) AS (
    SELECT 'Small White Wild', 3
  UNION
    SELECT 'Large White Wild', 2
), rw(recipe, weight) AS (
    SELECT recipe, sum(amount)
      FROM bakehouse.recipe_item
  GROUP BY recipe
), job(path, product, ingredient, quantity) AS (
    SELECT po.product,
           po.product,
           ri.ingredient,
           po.quantity * ri.amount
      FROM po
      JOIN bakehouse.recipe_item ri ON po.product = ri.recipe
      JOIN rw ON ri.recipe = rw.recipe
  UNION
    SELECT job.path || '.' || job.ingredient,
           job.ingredient,
           ri.ingredient,
           job.quantity * ri.amount / rw.weight
      FROM job
      join bakehouse.recipe_item ri on job.ingredient = ri.recipe
      join rw on job.ingredient = rw.recipe
)
SELECT product formula, ingredient, round(sum(quantity),2) weight from job group by formula, ingredient order by formula;
#+end_src

This query gives us:

#+results:
| formula          | ingredient          | weight |
|------------------+---------------------+--------|
| Basic White Sour | Sea salt            |   0.05 |
| Basic White Sour | Water               |   0.83 |
| Basic White Sour | Mother              |   1.35 |
| Basic White Sour | Organic white flour |   1.50 |
| Large White Wild | Basic White Sour    |   1.86 |
| Mother           | Organic white flour |   0.75 |
| Mother           | Water               |   0.60 |
| Small White Wild | Basic White Sour    |   1.86 |

This time we're making 3.74 kg of dough, which is right.

In order to see what's going on, we can change the final ~SELECT~ to ~SELECT formula, path, ingredient, round(quantity,2) weight FROM job~, and now we get:

| formula          | path                                     | ingredient          | weight |
|------------------+------------------------------------------+---------------------+--------|
| Large White Wild | Large White Wild                         | Basic White Sour    |   1.86 |
| Basic White Sour | Large White Wild.Basic White Sour        | Mother              |   0.68 |
| Basic White Sour | Large White Wild.Basic White Sour        | Organic white flour |   0.75 |
| Basic White Sour | Large White Wild.Basic White Sour        | Water               |   0.41 |
| Basic White Sour | Large White Wild.Basic White Sour        | Sea salt            |   0.02 |
| Mother           | Large White Wild.Basic White Sour.Mother | Water               |   0.30 |
| Mother           | Large White Wild.Basic White Sour.Mother | Organic white flour |   0.38 |
| Small White Wild | Small White Wild                         | Basic White Sour    |   1.86 |
| Basic White Sour | Small White Wild.Basic White Sour        | Organic white flour |   0.75 |
| Basic White Sour | Small White Wild.Basic White Sour        | Sea salt            |   0.02 |
| Basic White Sour | Small White Wild.Basic White Sour        | Water               |   0.41 |
| Basic White Sour | Small White Wild.Basic White Sour        | Mother              |   0.68 |
| Mother           | Small White Wild.Basic White Sour.Mother | Organic white flour |   0.38 |
| Mother           | Small White Wild.Basic White Sour.Mother | Water               |   0.30 |

Which shows that we're considering two lots of Basic White Sour with exactly the same weights, but we (and more importantly, the database engine) know that they're distinct amounts because we get to them through different routes. Hurrah! The problem is solved and we can accurately work out what we should be mixing.

*** What's still missing
    :PROPERTIES:
    :ID:       868FF41D-EB97-4079-8710-EBBE6B50AB15
    :END:

As a baker, I know  if I've got an order for bread on Friday, then I need to mix the starters on Wednesday night, then spend Tuesday mixing, fermenting and shaping the loaves, which will spend the night in the retarder ready to be baked at 4 on Friday morning. But the schema I've outlined here doesn't. In my full bakehouse schema, I have a few extra tables which hold timing data and such. In particular, I have a ~product~ table, which knows about everything I sell. This table knows holds info about how many I can make per hour of work and the bake time and temperature. Then there's a ~recipe~ table which holds information about how long a formula needs to rest. @@hugo:{{% marginnote %}}@@This could be the bulk fermentation time if it's a formula for a dough or a starter, a proof time if it's a loaf, or a soaking time for a soaker (a soaker is usually a mixture of seeds or fruit and a liquid, usually water, but occasionally fruit juice or booze depending on the final product). @@hugo:{{% /marginnote %}}@@ The real queries take this into account to allow us to work back from the ~due_date~ of a real order to the day we need to do the work. If you want to dig into how I handle dates  you can check out the repository at [[https://github.com/pdcawley/bakehouse/]].


*** The perils of writing stuff up

Never write your work up for your blog. Especially if you're mostly happy with it. As I was writing this, I realised there's an annoying bit of code duplication that I think I can eliminate. In the current code, I repeat what's essentially the same query structure in a couple of different views, but the formula graph is essentially static unless I add or adjust a recipe. Now I'm wondering if I could make a materialised view that has enough information to shortcut the calculations for both making the production list (what needs to be mixed, when) and for working out my costings (to put a price on a loaf, you need to know how much the raw ingredients cost, and that involves walking the tree again. Maybe a table like:

| product          | sub_formula      | ingredient  | factor | lead_time |
|------------------+------------------+-------------+--------+-----------|
| Large White Wild | Basic White Sour | White Flour |  0.403 | 1 day     |
| Large White Wild | Basic White Sour | Salt        |  0.012 | 1 day     |
| Large White Wild | Basic White Sour | Water       |  0.222 | 1 day     |
| Large White Wild | Basic White Sour | 80% Starter |  0.462 | 1 day     |
| Large White Wild | 80% Starter      | White Flour |  0.288 | 2 days    |
| Large White Wild | 80% Starter      | Water       |  0.173 | 2 days    |

If we have that table, then two days before our bread is due, if we have an order for 10 white loaves, we'll need to mix \(9.3 × .288 \approxeq 2.68\) kg of flour and $9.3 × 0.173 \approxeq 1.61$ kg of water. Which we can do with a simple non-recursive ~SELECT~. Something like:@@hugo:{{% marginnote %}}@@NB: I've not tested this because I don't have the precalculated table, but it seems like it should work. In fact, thinking about it, we could probably build the ~precalc~ table so that we can simply do ~precalc.factor * po.quantity~, since any change that affects recipe weight will also affect our precalculated table.@@hugo:{{% /marginnote %}}@@

#+name: A9B65C0A-2496-4A3B-B0FB-8AEBE9B5BE6A
#+begin_src sql
WITH weighted(formula, ingredient, weight, due) AS (
    SELECT precalc.sub_formula,
           precalc.ingredient,
           precalc.factor * po.quantity * rw.weight,
           po.due_date - precalc.lead_time
      FROM precalc
      JOIN production_order po ON precalc.product = po.product
      JOIN recipe_weight rw ON precalc.product = rw.recipe
)
  SELECT formula, ingredient, sum(weight)
    FROM weighted
   WHERE due = 'today'
GROUP BY formula, ingredient
#+end_src

We can use the same table to calculate the raw material costs for a given recipe, using a simple non-recursive query too.

I think, however, I'm going to leave it alone until I have to write another recursive view that walks the same graph, at which point I'll bite the bullet and do the pre-calculated version.


* Book Reports                                            :@book-report:
:PROPERTIES:
:export_hugo_custom_front_matter: :series "Book Reports"
:ID:       AE556F3E-BD2C-46E6-BE13-AD819A39EE6D
:END:

** DONE A Wizard of Earthsea
:PROPERTIES:
:EXPORT_FILE_NAME: a-wizard-of-earthsea
:export_hugo_slug: a-wizard-of-earthsea
:export_date: 2019-05-30
:ID:       DB913EAC-FB57-44B7-9645-DBD26957CE72
:END:
This was the first.

Before I read Tolkien at the suggestion of the wonderful Miss Reese, my teacher for my last year of primary school; before I pulled Diana Wynne Jones, Alan Garner, Susan Cooper and others from the shelves of Bawtry's small, but enchanting branch library; before Anne McCaffrey's DragonSong found me in my school library and set a fire in my imagination. Before all that, I read /A Wizard of Earthsea/ and it stuck with me.

#+hugo: more

I remember one Saturday with 50p in my pocket from singing for a couple of weddings at St George's church in Doncaster (25p for each wedding, paid cash in hand on the day. It always felt like a bonus after singing Bach's /Jesu Joy of Man's Desiring/ in the side chapel as the register was signed in the vestry and Magnus Black, the choir and organmaster, brought that beautiful tune dancing with such delicacy from in instrument that would shake the walls later as the happy couple left the church to Vidor's toccata and fugue@@hugo:{{% marginnote %}}@@That was if we were lucky. It was usually Mendelssohn – not bad, Magnus was far too good an organist for it to sound dull, but not a patch on Vidor.@@hugo:{{% /marginnote %}}@@). I was never one for saving, I'm still not, so I was straight round to Donny's nearest thing to a bookshop, the WH Smith in the Arndale in search of something to read. A voracious reader, I'd gone through all the /Swallows and Amazons/ and /Narnia/ books and I needed more. The cover of the second Puffin edition, with its white youths and bizzare half man half hawk fascinated me, so I handed over my 50p@@hugo:{{% marginnote %}}@@The bibliography I found tells me that it probably cost 35p, so I no doubt bought a load of sweets as well – books and sugar have always been my vices.@@hugo:{{% /marginnote %}}@@ and headed home with my prize.

I read /A Wizard of Earthsea/ once or twice and loved it, but I've not reread it since. As a kid, I borrowed rest of the then trilogy from the library and found them rather hard going at  (my memory says that I found /The Tombs of Atuan/ a real slog. I got through it, but it took a couple of goes and at least one renewal to get to the end). A few weeks ago though, I went to the [[https://www.soundpost.org.uk/][Sound Post]] 'Modern Fairies' singing weekend and fell into conversation with [[https://terriwindling.com][Terri Windling]] about the books that had shaped me and I told her about my experience with the Earthsea trilogy and I thought maybe I'd been a little too young for them (I think I was eight or nine when I read AWoE, and maybe twelve when I read /The Tombs of Atuan/ and /The Furthest Shore/). I hadn't revisted them since. Terri made me promise to reread them and to let her know what I thought. So that's what I'm doing. Terri, this book report's for you. I owe you a few more and I promise I'll get to them.

By the way, if you've never read /A Wizard of Earthsea,/ there will be spoilers in this article. Read the book before continuing. It shouldn't take you long, and it's well worth the time.

It's not so much what happens in this story as the way it's told that left its impression on me. Earthsea is made of words – all stories are, of course – sung into being by Segoy. Words are power. A wizard spends a large part of his@@hugo:{{% marginnote %}}@@The wizards are all men. There are female witches in the story, but at this stage of the tale they're definitely underpowered and untrustworthy compared to the men. Le Guin fixes this later.@@hugo:{{% /marginnote %}}@@ education learning the "the Deeds of heroes and the Lays of wisdom" and year under the Master Namer just learning the true names of things in the Old Speech: the language of dragons; the language in which the world was made. In the period when the book is set, there is written language, but I get the feeling that it's very much the preserve of the wise. Songs, orally transmitted, are how the people of the archipelago hold their history and Le Guin's language reflects that. Every sentence seems to have been shaped to be spoken, and beautifully so. I kept stopping and reading passages out because the words were just so... right.

I sometimes wonder who the tale's narrator is telling the story to. It's a question that can break a lot of first person SF and exposes lazy storytelling. If a book that's supposedly the product of a completely different culture or time feels like it's written for an early 21st century reader, it breaks the book for me.@@hugo:{{% marginnote %}}@@Sometimes I don't care though. God alone knows why Bertie Wooster is telling the Jeeves stories, or who he's telling them too – I'm just very glad he's chosen to tell them at all.@@hugo:{{% /marginnote %}}@@ The language and idiom of /A Wizard of Earthsea/ seem entirely right and consistent. We learn so much about the world as Ged's story is told from things mentioned in passing. We know that this happened a long time ago and it's assumed we already know about /The Deed of Ged/, /The Creation of Ea/ and all the other songs, deeds and festivals that are referred to in passing through the book. At the end we are told that no songs have survived that tell how Ged came to terms with his shadow – the entire book is a footnote in a much larger story that's just out of reach. I'm reminded of the fact that we only have the Norse myths we know because an ancient Icelander worried that readers wouldn't recognize the allusions in the sagas and eddas, so they wrote down the bones of the older stories to help future readers understand. If Le Guin had left Earthsea at this point, all we would know of Earthsea would be the glimpses of it in this story. And what glimpses they are.

You can find echoes /A Wizard of Earthsea/ in so much subsequent fantasy literature. The possibility of a wizard being trapped in another, for instance. Pratchett plays with and develops this in the /Witches/ sequence of Discworld books, for instance. I loved this sentence though: "And no one knows how many of the dolphins that leap in the waters of the Inmost Sea were men once, wise men, who forgot their wisdom and their name in the joy of the restless sea." If I had the power to become a dolphin I wouldn't be keen to return to the body of a fat 51 year old with diabetes and a bunch of aches and pains that I try not to think about. You can keep your wisdom sometimes.

As a kid, I didn't really understand what was going on with Ged and his Shadow. It was easy to see myself in the ever noticed that he didn't have the same colour skin as me). I loved learning and especially /knowing/. It wasn't hard to take my undoubtedly superior intelligence@@hugo:{{% marginnote %}}@@Yeah. I know. I must have been insufferable as a kid (and an adult, if I'm honest). First to stick their hand up in every class. Happy to "Well, actually..." at every opportunity.@@hugo:{{% /marginnote %}}@@ as analogous to a wizard's power. Then, though, the shape of the story confused me, especially the ending. Ged and his friend sail off the page. The sea becomes land. Ged steps off the boat and confronts the Shadow, addressing it with his own name. And the shadow disappears/merges with Ged. And they all live on to do the Deeds which are sung of them. What? Nine year old me had no /idea/ what was going on there, but the imagery stuck.

Now, of course, it all seems a clearer. Thesis. Antithesis. Synthesis. Ged does a terrible thing in his ignorance  and pride. In shame he runs from it, almost losing his humanity in the process. He is tempted by a dark power, but rejects it. A friend and teacher restores him to himself and tells him that running is the sure road to doom. He turns and chases his Shadow instead. Finally he comes to an acceptance that the Shadow is a part of himself and by giving it his name he reintegrates that part into himself and finally becomes a whole man. There you go – no need to read the book now.

Of course you need to read this book. It's language sings and the places and people it evokes are beautifully drawn. Rereading this after more than 30 years, so much was familiar. I would have said I'd forgotten almost all of it but the bare outline of the story and a few character names, but that stuff clearly went in deep and helped make me myself because as I read, the whole shape of the thing unfolded in my head. It was almost like recognising roads and pathways in a place you holidayed repeatedly as a kid, then didn't return for 20 years. Familiar and surprising at the same time. "Oh yeah, that's where Daniel used to live! And do you remember walking up there to buy ice creams at the village shop? Oh! I'd forgotten this view!"

Right... onwards to /The Tombs of Atuan./


* Posts
** DONE My Virtual Gig-Like Thing
:PROPERTIES:
:export_hugo_slug: virtual-gig-like-thing
:export_date: 2020-04-08T00:00:00
:EXPORT_FILE_NAME: virtual-gig-like-thing
:ID:       C2642DFD-B4E8-44DB-B576-BED6A8C96223
:END:

On Thursday the 9th of April at 7pm UK time, I'm streaming my first attempt
at a  full folk club style gig from my study to my
Twitch stream]] and I would  love for you to be there.


*** Schedule
   :PROPERTIES:
   :ID:       6769254B-F1F3-46DF-814F-63D96F985D7C
   :END:

It all kicks off at 7pm, UK time with a kind of Q&A session and
introduction to Twitch for newcomers. I'm particurly planning to help
other independent musicians reach their audience through the platform.@@hugo:{{% marginnote %}}@@Recent deals with [[https://soundcloud.com][SoundCloud]] have made it /much/ easier for experienced
performers to access the means to get paid on Twitch, and it seems to be
the most transparent platform for getting paid.@@hugo:{{% /marginnote %}}@@


Then, I plan to follow the Royal Traditions/Singing Together format of two
forty minute sets of folk material with a 10 minute refreshment and raffle
break in the middle.

After the folk club concert I'll be jumping onto [[https://twitch.tv/sings/download/][Twitch Sings]] to round out
the evening singing implausible songs with friends from that community and
any folky friends who've managed to get themselves up on Twitch by then. I'm
hoping it'll be a lot of fun.


*** Ticket Prices
   :PROPERTIES:
   :ID:       0E43DD7E-5512-435C-B7C4-73910B049C75
   :END:
It's the internet! It won't cost you a penny to watch me perform. However,
right now, daft stuff like this is my only potential source of income, so
I would be deeply grateful if you could either [[https://ko-fi.com/pdcawley]["Buy me a coffee"]] via Ko-Fi
or [[https://twitch.tv/signup][sign up]] for a free Twitch account and subscribe to my channel.

*** Free money for your favourites!
    :PROPERTIES:
    :ID:       AFDB4ED1-8FAB-461B-816A-CD0BF60D7CC2
    :END:
If you are an Amazon Prime subscriber and you don't yet have a Twitch
Subscription, there's a wonderful thing you can do that means that Amazon
will give me (or any other streamer you enjoy) some money and it won't
cost you a penny. [[https://twitch.amazon.com/prime][Sign up]] for Twitch Prime, which is just like a regular
twitch account, but you can subscribe to one channel for free each month.
The streamer gets paid by Twitch as if you'd signed up for a regular
subscription, but you don't get charged a penny because you're already
paying Amazon for your Prime account. The only difference between a Prime
subscription and a regular one on Twitch is that you can't set up a Prime
sub to renew. If you would like to keep making regular payments to the
streamer of your choice, you need to remember to resubscribe every month.

*** One off tips
    :PROPERTIES:
    :ID:       95E39426-BE56-4078-9BF5-E7B2BE229683
    :END:
A Ko-Fi coffee comes in at £3, but if you want to tip me or any other
twitch performer with an arbitrary amount, then Twitch Bits are your
friend. You buy 'em from [[https://bits.twitch.tv/][Twitch]] and can then use them as a virtual
currency. For the performer, 100 bits is equivalent to $1, but they will
cost you more than that to buy, because Twitch are (understandably, it's
not a cheap platform to run!) going to have to take a cut somewhere. By
loading it on the cost of bits to the giver, they make things really
transparent. It's not like the weird alchemy where you pay a music
streaming site 69p for a track or whatever and, unbeknownst to you unless
you really dig into it, the artist sees maybe 6p of that.

Other performers have other ways for you to support them, whether it be
public amazon wishlist, paypal tip jar, patreon page or some other service
I've not heard of yet. In some ways, it's never been easier for you to
support the work of artists you love.


** TODO Streaming Folk Music
  :PROPERTIES:
  :ID:       2AB0850A-2FC4-42B3-BAA6-6E1A9512FB3B
  :END:
  I'll be entering my sixth month of streaming live folk music on the Internet next month, and I've learned a good deal about it as I've done it. Primarily I've learned that a stream isn't the same as a live gig or a prerecorded concert segment; it's it's own thing and, I think it's something that will continue to be a viable form of performance for people as we finally emerge from lockdown because it offers something that traditional modes of performance don't, and that has value.
  Live streaming isn't the only new form that's emerged from All This. One of the first, and most successful has been the 'virtual festival' that was pretty much pioneered and perfected by the people behind the [[https://folkonfoot.com][Folk On Foot]] podcast. On the early and late May bank holidays, they curated a lot of short performance videos from their artists which were then very capably linked together by Matthew Bannister. It was interesting comparing the relative slickness of Bannister, presenting from his living room and some of the artists who had varying degrees of experience of performing down the lens, but on the whole it was glorious. They solicited donations, which were shared between the artists and the charity [[https://www.helpmusicians.org.uk][Help Musicians]], and the whole thing was glorious. Other festivals have followed suit with greater or lesser success {{marginnote}}I really enjoyed the [[https://www.folkbytheoak.com/about/familynestfest/][Folk by the Oak 'Family Nest' Fest]], which again split the money between the artists and their chosen charity, with some of the real world festival's vibe captured by interspersing the performances with short videos from their regular vendors and kids workshop performers{{/marginnote}}.

*** Platforms
   :PROPERTIES:
   :ID:       4D0E27C9-6823-4569-80F0-216CBFB0D79B
   :END:

*** Share the load
   :PROPERTIES:
   :ID:       78283C00-98D5-40F4-AC1D-5A1FDCFEB1C0
   :END:

*** Payment models
   :PROPERTIES:
   :ID:       DFF1A992-401A-46D9-8B64-E35C2CB166D8
   :END:

*** Liveness
   :PROPERTIES:
   :ID:       DE8760EC-239D-44A2-A9D4-3D7C2FD433B4
   :END:

** DONE Asshole Free Devil's Advocacy                     :philosophy:blether:
:PROPERTIES:
:export_file_name: devils-advocacy-without-asshattery
:export_hugo_slug: devils-advocacy-without-tears
:export_date: 2018-10-25
:ID:       B96DE889-2A35-4276-B716-EB558186DB55
:END:


So, you want to play Devil's Advocate, but you're afraid you might come across as a bit (or a lot) of an asshole? Here's some suggestions for how to avoid that.

#+hugo: more

*** Maybe don't?
   :PROPERTIES:
   :ID:       DFD8CB3D-98AB-414B-8766-B64DBC5E1D04
   :END:

Seriously, why does the Devil need an advocate? If you want to play DA because you think the position you want to argue has some merit, then argue the position honestly and own it. If it doesn't survive the discussion (or is shouted down), then "Ah right, I hadn't thought of that, you're right" or words to that effect and file that position in your memory as a bad one (along with the skeleton of /why/ it's bad). Nothing wrong with holding strong opinions, the thing that's bad is holding onto them if they're shown to be bad. If the group you're talking with just shouts you down and doesn't convince you that your position is a bad one, maybe find a different group? Or agree with them to steer clear of that topic.

What's really intellectually dishonest is to say "I was only playing Devil's Advocate!" after an idea has been shot down. I'm sure your intentions are entirely honorable, but what if they weren't? Say you genuinely held that the best thing to do with the children of the poor was to turn them into cheap and delicious meals for the richest in society. Say you advanced this position to your friends and were utterly appalled by the idea. Then maybe you'd try to distance yourself from it by saying "Whoah! Guys@@hugo:{{% marginnote %}}@@​ I know. But the kind of people who make this move in an argument are usually the kind of people who'd address a mixed group of folk as "guys".@@hugo:{{% /marginnote %}}@@! I was only playing Devil's Advocate!"

When I hear someone playing that card, how am I supposed to distinguish between the well-meaning "There is this argument I've come across that I'm not sure I agree with, but it maybe has some merit and I don't know how I'd argue convincingly against it" types and the assholes who were flying a kite? Maybe the non-assholes will have friends who'll tell me that "They might seem like a bit of an arse, but they're not really." I've been that guy, and I don't want to be him again. Why is it okay for me to load the work of explaining that I'm not dickhead onto my friends rather than just not acting like a dickhead in the first place? Eventually, friends get tired. Eventually they'll shift to "Yeah, I know he seems like an ass, and he kind of is, but..." and then one day, they won't be your friends any more.

@@hugo:{{% newthought %}}@@Before you introduce the idea@@hugo:{{% /newthought %}}@@ you want to play Devil's Advocate for, say something like "D'you mind if I play Devil's Advocate for a moment?" And when the group tells you "Yes, we do mind. Why help the devil?" listen to them. If it's genuinely that you've heard some argument that on the face of it seems repugnant, but you can't find a hole in it, then say as much: "What's wrong with this idea? Clearly feeding poor babies to the 1% is utterly repellant, but I can't find an effective counterargument."

Don't keep doing it, mind, or you'll start looking like the kite flying asshole again.

** DONE Adding a generic oembed handler for Hugo :hugo:
:PROPERTIES:
:export_hugo_slug: oembed-for-hugo
:export_file_name: oembed-for-hugo
:export_date: 2020-05-12
:ID:       950F43FF-3632-48D9-B768-02CC5154A220
:END:
If you're at all like me, you have content on a bunch of different sites (Instagram, Youtube, Flickr, Soundcloud, Bandcamp...) and, especially for multimedia content, it's great to be able to link to 'live' versions of that content. Of course, all those sites will let you 'share' content and usually have an 'embed' option that hands you a bunch of HTML that you can paste into your blog entry. But screw that! I'm a programmer for whom laziness is one of the cardinal virtues -- if it's at all possible, I prefer to let the computer do the work for me.@@hugo:{{< marginnote >}}@@If nothing else, once I've got the programming right, it's less likely to screw up than me@@hugo:{{< /marginnote >}}@@

Hugo[fn:2] sort of supports this out of the box with its ~youtube~, ~instagram~, ~vimeo~ etc. built in shortcodes. The thing is, they're not lazy enough -- you have to dig into each URL to extract a content ID and pass that in to ~{{%/* youtube kb-Aq6S4QZQ */%}}~ or whatever. Which would be kind of fine, if you weren't used to the way sites like Facebook, Twitter, Tumblr and so on work. With those sites, you enter a URL and they disappear off behind the scenes and fill in a fancy preview of the page you linked to. Why can't Hugo do that?

#+hugo: more

Well, it can. It just takes a little work.[fn:1] The ~question~ to ask is how do all those user friendly sites do there thing? Twitter and Facebook, being the walled garden behemoths that they are do it by dictating two different microformats@@hugo:{{% marginnote %}}@@
Of bloody course!
@@hugo:{{%/marginnote%}}@@ that live in a page's ~HEAD~ section. The microformat approach has a good deal to be said for it: In theory, you can just make a ~HEAD~ request to the URL you're interested in, parse out the microformat of your choice and build your own media card. I've not worked out how to do this yet though. However, before Twitter and FB started throwing their weight around, there was an open standard that lots of sites support, it's /really/ easy to use. It's called [[https://oembed.com/][oembed]] and it's great. The idea is that it too is discoverable via a ~HEAD~ request to your media page. You look for something matching src_html{<link rel="alternate" type="application/json+oembed" href="..." ...>}, make a JSON request to the ~href~ url and paste in the contents of the ~html~ key in the object you get back. The catch, of course, is that you still end up having to parse the document's HEAD.

The cool thing about ~oembed~, though, is that you /can/ discover its endpoints that way,@@hugo:{{<marginnote>}}@@Though, I'm seeing fewer and fewer oembed links cropping up in sites that I /know/ support the protocol@@hugo:{{</marginnote>}}@@ but there's also a big list of known endpoints on the [[https://oembed.com/][Oembed homepage]], which is also available as a big old JSON object if you want to go the full programmatic route. There are JavaScript libraries available that will walk your webpage and the JSON object and replace all your links with chunks of embedded content, that that's what I used to use on this site. But... that's not how I currently roll at Just A Summary. There are currently no ~<script>~ tags to be found on here and I plan to keep it that way. So I wrote a Hugo shortcode. Here it is:

#+name: Initial embed shortcode
#+caption: Initial embed shortcode
#+begin_src go-html-template
{{ $url := (.Get 0) }}
{{- range $.Site.Data.embed }}
  {{- if le 1 ( findRE .pattern $url | len ) }}
    {{- with (getJSON .endpoint "?" (querify "format" "json" "url" $url)) }}
      {{ .html | safeHTML }}
    {{ end }}
  {{ end }}
{{ end }}
#+end_src

We use it like: ~{{</* embed "https://youtub.be/kb-Aq6S4QZQ" */>}}~, which displays like this:

@@hugo:{{< embed "https://youtu.be/kb-Aq6S4QZQ" />}}@@

@@hugo:{{% newthought %}}@@"But how does it work?"@@hugo:{{% /newthought %}}@@ I hear you ask? It works in conjunction with some per-site data entries that I've added to the directory ~data/embed~ in this site's base directory. You might have guessed that the data entries are maps with two entries, a ~pattern~ and an ~endpoint~. If the URL argument matches the ~.pattern~, then we make a ~getJSON~ request to ~.endpoint~ with a sanitised version of the URL argument tacked on as our query string and inserting the JSON response's ~.html~ entry. @@hugo:{{< marginnote >}}@@It's rather tricky to implement oembed for on a strictly static site, but I love the simplicity of it. I have a few thoughts abotu that though. Watch this space.@@hugo:{{</marginnote>}}@@

I made the data files by taking the big JSON object from https://oembed.com/providers.json and massaging the supplied patterns into regular expressions. In theory, I could write a script to do the conversion for me, but I'm only really interested in four providers for this site, so I just did it by hand. So the entry for [[https://instagram.com/][Instagram]]:

#+caption: The https://oembed.com/providers.json entry for Instagram
#+name: 521EC4E0-5CE6-4667-9558-16262848DD6D
#+begin_src json
{
    "provider_name": "Instagram",
    "provider_url": "https:\/\/instagram.com",
    "endpoints": [
        {
            "schemes": [
                "http:\/\/instagram.com\/*\/p\/*,",
                "http:\/\/www.instagram.com\/*\/p\/*,",
                "https:\/\/instagram.com\/*\/p\/*,",
                "https:\/\/www.instagram.com\/*\/p\/*,",
                "http:\/\/instagram.com\/p\/*",
                "http:\/\/instagr.am\/p\/*",
                "http:\/\/www.instagram.com\/p\/*",
                "http:\/\/www.instagr.am\/p\/*",
                "https:\/\/instagram.com\/p\/*",
                "https:\/\/instagr.am\/p\/*",
                "https:\/\/www.instagram.com\/p\/*",
                "https:\/\/www.instagr.am\/p\/*",
                "http:\/\/instagram.com\/tv\/*",
                "http:\/\/instagr.am\/tv\/*",
                "http:\/\/www.instagram.com\/tv\/*",
                "http:\/\/www.instagr.am\/tv\/*",
                "https:\/\/instagram.com\/tv\/*",
                "https:\/\/instagr.am\/tv\/*",
                "https:\/\/www.instagram.com\/tv\/*",
                "https:\/\/www.instagr.am\/tv\/*"
            ],
            "url": "https:\/\/api.instagram.com\/oembed",
            "formats": [
                "json"
            ]
        }
    ]
}
#+end_src

becomes

#+name: instagram.yaml
#+caption: ~./data/embed/instagram.yaml~
#+begin_src yaml
endpoint: "https://api.instagram.com/oembed/"
pattern: "^https?://(www\\.)?instagr(\\.am|am\\.com)/((.*/)?p/|tv/)"
#+end_src

Collapsing all those ~scheme~ entries down to a single regular expression was a slight pain to do by hand, and I'm not /entirely/ sure the regular expression will match exactly what the schemes match, but it's not broken on any of the Instagram links I've thrown at it so far, so that's good enough for me.

@@hugo:{{< newthought >}}@@This isn't the shortcode's final form@@hugo:{{< /newthought >}}@@ -- it's not as robust as I'd like it to be in the face of a missing or temporarily down oembed endpoint, so it would be good to have some kind of fallback in case an endpoint changes or goes away. Also, there are some sites that have their own methods for embedding previews, which don't support oembed @@hugo:{{< marginnote >}}@@All those IndieWeb sites that use ~h-entry~ and ~h-card~ microformats to make the webpage machine parseable, for instance.@@hugo:{{< /marginnote >}}@@ and it would be great to get at those somehow. I suspect I will end up with a shortcode which is essentially a big case statement dispatching to different partials which will handle the real rendering. Again... watch this space


** DONE «tap tap» is this thing on? :indieweb:
CLOSED: [2022-04-12 Tue 16:26]
:PROPERTIES:
:export_file_name: 20220412-is-this-thing-on
:export_hugo_slug: is-this-thing-still-on
:END:

#+begin_description
In which Piers attempts to explain why he's not been blogging in years, and makes vague noises about getting back to it again, in the hope that this time his [[https://indieweb.org/][IndieWeb]] inspired enthusiasm will last longer than a couple of weeks.
#+end_description

It's been a while hasn't it? I've been blogging on and (mostly) off since 2004 (at least according to the oldest article on here), and the [[https://indieweb.org/][IndieWeb]] movement reminds me of those heady days before Facebook, Twitter and the other monoliths scooped up all the bloggers.

It was probably Twitter that killed my regular blogging -- before Twitter, if I had something to say, I'd write a blog (or a LiveJournal for more personal stuff) post. Maybe a few days later, someone would reply, or write a blogpost of their own as a reaction and I'd get a pingback. These days, when I blog, my posts sit in splendid isolation, which wasn't really a thing back in Blogging's heyday. Spam killed my will to support comments and the growing complexity of blogging software was a real turn off. {{{marginnote(And I speak as someone who was the maintainer of [[https://typosphere.org/][Typo]] for a few years.)}}}

I burned out.

I ran this site on Typo, but most of the work I was doing on it was implementing features I didn't need which made the code slower and harder to understand, so I stepped back just as Twitter started its rise.

I've made a few abortive returns to blogging since, prompted by the rise of static site generation engines @@hugo:{{% marginnote %}}@@I'm now using [[https://gohugo.io][Hugo]], [[https://orgmode.org/][org-mode]] and [[https://github.com][Github Actions]] to manage the site, and it's all hosted as a bunch of text files on a Raspberry Pi in one of [[https://mythic-beasts.com/][Mythic Beasts]]' racks somewhere.@@hugo:{{% /marginnote %}}@@ and the fact that I like having something to fiddle with. I could have just installed WordPress, but the idea of simply serving up a pile of static files (and no JavaScript!) seems way more sustainable (and secure) to me. @@hugo:{{% marginnote %}}@@ Executing code that's exposed to the internet when I could just be serving textfiles is a recipe for pain and suffering.@@hugo:{{% /marginnote %}}@@

{{{newthought(Not running code on my server)}}} makes it a bit tricky to be fully engaged in IndieWeb ideal of a /connected/ web of websites using [[https://www.w3.org/TR/webmention/][WebMentions]] to make those interactions visible, but [[https://www.w3.org/TR/webmention/][it can be done]], and I too shall achieve it! One day. Baby steps, eh? I might resort to a Javascript based setup initially, but long term I want to keep the site completely script-free and fast.

*** Other writing

{{{newthought(I've written a few pieces)}}} now for [[https://jonwilks.online/][Jon Wilks]]' new and rather wonderful  [[https://tradfolk.co/][Tradfolk]] website. You can find those (and any future articles) at [[https://tradfolk.co/author/pierscawley/]] if you're interested in my suggestions on how to get started singing without accompaniment and building your repertoire.

I think that's what's got me returning to this site frankly. I'd forgotten how much I enjoyed writing long-ish form stuff rather than 280 character miniatures.

*** Coming up

{{{sc(newthought)}}}I suspect that,{{{sc(/newthought)}}} like every other IndieWeb blogger, I'll have a few upcoming articles detailing how I make things work here, {{{marginnote(Can there be anything more fascinating than tech navel gazing?)}}} but there's a few things in my drafts folder that I want to return to, and probably some discussion of my experiences streaming folk songs every Friday night for the best part of two years now.

Let's revisit this in a couple of months and see if it's still the most recent article on the site, eh?

** DONE We have WebMentions
:PROPERTIES:
:export_file_name: we-have-webmentions
:END:
CLOSED: [2022-04-16 Sat 14:53]

#+begin_description
Taking one more step on the road to full IndieWeb citizenship or whatever it's called, [[/][Just A Summary]] now displays webmentions.
#+end_description

After much fiddling with [[https://n8n.io/][N8N]], [[https://webmention.io/][webmention.io]], and the usual combination of [[https://gohugo.io][Hugo]]'s powerful, yet inscrutable templating language and my tenuous understanding of CSS, we're now /displaying/ our webmentions. We've been directing them to webmention.io for years now, but scratching my head over what to do with them.

The way it works at the moment is I run a task every few hours that checks webmention.io, merges the results with the stuff we already know about and commits the updated data files to Github, which triggers a github action that rebuilds the site. This is… inefficient. My next step is to either expose the n8n workflow via a webhook, or work out how to retain some information from the previous run and use that to ensure we only fetch any mentions that've arrived since the last time we checked. But that's work for another day. Right now I'm calling what I have a win, merging this branch to main and basking in the warm glow of taking one more step down the IndieWeb road.

** DONE Keep it Simple, But Where's The Fun In That? :indieweb:webmentions:
CLOSED: [2022-04-24 Sun 16:30]
:PROPERTIES:
:export_file_name: 20220423-keep-it-simple-but-where-s-the-fun-in-that
:export_hugo_slug: not-so-simple
:END:

#+begin_description
The beauty of using a static site generator to build your website is supposed to be that it's all delightfully simple. Simple markdown formatted files go in at one end and a slim, fast and easy to serve website comes out the other end. All that remains is to upload those files to the appropriate directory on your server and all is well.

But never underestimate the ability of a long time Emacs user to complicate things.
#+end_description

The beauty of using a static site generator to build your website is supposed to be that it's all delightfully simple. Simple markdown formatted files go in at one end and a slim, fast and easy to serve website comes out the other end. All that remains is to upload those files to the appropriate directory on your server and all is well.

But never underestimate the ability of a long time Emacs user to complicate things. For instance, markdown is all well and good, but I've been doing most of my writing in [[https://orgmode.org/][Org Mode]][fn:5] so I really want to stay in Org mode to write these blog posts. [[https://gohugo.io/][Hugo]] understands =.org= files, so I could just lean on that, but the way Hugo treats org files seems slightly out of whack with what I think of as the Org way and I'd end up having to stick with the subset of org syntax that Hugo know. So I use [[https://ox-hugo.scripter.co][ox-hugo]], there's a bit of configuration needed to make it work the way I like, but I prefer to change software to accommodate me rather than change me to accommodate software

#+begin_marginnote
I'd go so far as to say it's a point of pride.
#+end_marginnote

I've had all that set up for a while. As I say, a tad fiddly at first, but once it's in place, it just works.

{{{newthought(Except…)}}} =ox-hugo= works by generating =.md= files from an org source, which are then used to generate the site, and I had things set up to autogenerate the html whenever I commited to the main branch of the blog repo, and the git server hook based system I was using only worked if those exported files were in repo.

That's the sort of thing that makes me itch, because there were two files for any given article:

 - =all-posts.org= :: the org file in which I write all my articles
 - =article.md= :: the generated file that hugo uses to build the site.

The generated file is an artefact of the build process and simply repeats the info in the org file, which should be our single source of truth. It's not a file that should be left around to be edited willy nilly because it could get out of sync with its source file. It's certainly not the sort of file that should live in the repository.

I didn't worry about this for /ages,/ but it niggled at me. Then one day I read an article about using [[https://github.com/features/actions][Github Actions]] to build an ox-hugo based site by installing emacs and ox-hugo on the VM that does the build step and generating the markdown files during the build by running Emacs
@@hugo:{{% marginnote %}}@@Yes, Emacs is an editor, but if you do 「@@html:<code>@@emacs all‑posts.org ‑‑batch ‑l ox-hugo ‑‑eval='(org-hugo-export-wim-to-md t)' ‑‑kill@@html:</code>@@」 it will happily execute any lisp code you care to ask it to.@@hugo:{{% /marginnote %}}@@ in batch mode. The markdown files never exist anywhere that anyone can edit them. So, of course I had to do that. Again, fiddly to set up, and arguably only of philosophical benefit, but worth it, I think.[fn:3]

{{{newthought(I could've left it there,)}}} but the thing I miss about the old, slow, hard to maintain version of this site, is the sense of connection. The old site had comments, and pingback links to other blogs. There was a sense of connectedness that's missing from a collection of articles. I want some of that back.

There is a way. In the time I've been mostly not blogging, some the folks who kept at it have been cooking up a collection of tools, technologies and standards under the [[https://indieweb.org][IndieWeb]] banner. There's a whole suite of technologies involved, but the piece of the puzzle that I'm interested in right now is the [[https://indieweb.org/WebMention][WebMention]], described as

#+begin_quote
… an @ mention that works across websites; so that you don't feel immovable from Twitter or Fb
#+begin_cite
[[https://twitter.com/rngala][Roney Ngala]] ([[https://twitter.com/rngala][@rngala]]) on [[https://twitter.com/rngala/status/852354426983591937][Twitter]]
#+end_cite
#+end_quote

Now we're talking! It's a really simple standard too. When you mention, like, comment on, repost, reply to, bookmark or simply publicly interact with an "h-entry"[fn:4] on the IndieWeb, you can send a webmention by sending a small chunk of JSON to the webmention endpoint of the entry you mentioned. Assuming all the content is marked up correctly, /sending/ a webmention is delightfully easy. You can do it with ~curl~, if that's your thing, but I'm in an emacs buffer, so let's use [[https://github.com/pashky/restclient.el][~restclient~]]

We mention [[https://indieweb.org]] in this post, so let's find out its webmention endpoint.

#+begin_src restclient :exports both
  HEAD https://indieweb.org
       #+end_src

       #+RESULTS:
       #+BEGIN_SRC html
       <!-- HEAD https://indieweb.org -->
       <!-- HTTP/1.1 200 OK -->
       <!-- Server: nginx/1.14.0 -->
       <!-- Date: Sun, 24 Apr 2022 13:18:45 GMT -->
       <!-- Content-Type: text/html; charset=UTF-8 -->
       <!-- Connection: keep-alive -->
       <!-- X-Powered-By: PHP/7.2.7-1+ubuntu16.04.1+deb.sury.org+1 -->
       <!-- Link: <https://webmention.io/indiewebcamp/webmention>; rel="webmention" -->
       <!-- Cache-Control: no-cache -->
       <!-- Request duration: 0.833706s -->
       #+END_SRC

We're looking for the 「@@html:<code>@@Link: … ; rel="webmention"@@html:</code>@@」 line. This tells us that to send a webmention targeting https://indieweb.org, we need to post it to https://webmention.io/indiewebcamp/webmention. Which is almost as simple as finding the end point. Here we go:

  #+begin_src restclient :exports both
  POST https://webmention.io/indiewebcamp/webmention
  Content-Type: application/x-www-form-urlencoded

  source=https://bofh.org.uk/2022/04/24/not-so-simple&target=https://indieweb.org
#+end_src

#+RESULTS:
#+BEGIN_SRC js
{
  "status": "queued",
  "summary": "Webmention was queued for processing",
  "location": "https://webmention.io/indiewebcamp/webmention/9Ltol-qmDoZxsD6YQ8U9",
  "source": "https://bofh.org.uk/2022/04/24/not-so-simple",
  "target": "https://indieweb.org"
}
// POST https://webmention.io/indiewebcamp/webmention
// HTTP/1.1 201 Created
// Content-Type: application/json;charset=UTF-8
// Content-Length: 236
// Connection: keep-alive
// Status: 201 Created
// Cache-Control: no-store
// Access-Control-Allow-Origin: *
// Location: https://webmention.io/indiewebcamp/webmention/9Ltol-qmDoZxsD6YQ8U9
// X-Content-Type-Options: nosniff
// Date: Sun, 24 Apr 2022 13:18:51 GMT
// X-Powered-By: Phusion Passenger 5.3.1
// Server: nginx/1.14.0 + Phusion Passenger 5.3.1
// Request duration: 0.685421s
#+END_SRC

The job is done, and we get a nice JSON formatted summary of what's going on to boot.

Of course, if a webmention is so simple to send then it's probably a pain in the bum to receive and it is… sort of. To receive a webmention request, you need to:

  1. Run a web app to handle the request
  2. Visit the source link
  3. Parse out the microformats associated with the entry, its author and content
  4. Figure out how to display the information

Steps 1--3 aren't particularly hard, but they're fiddly to get right and involve making web connections to potentially unsafe sites and I'm using Hugo to generate this site because I don't want to be running potentially insecure code that's exposed to the internet on a server that I own if I can possibly help it. Thankfully, I don't have to. I can take a leaf out of indiweb.org's book and just delegate that part to [[https://webmention.io][webmention.io]]. Webmention.io handles all that icky visiting of foreign websites and parsing out microformats for you and instead presents you with a feed consisting of all the webmention's that've been sent to your site in a variety of formats. I've been consuming their ~.jf2~ formatted feed for a while now. JF2 is a JSON representation of the microformats associated with the webmention's source. Let's grab something from that feed

#+begin_src restclient :exports both
  GET https://webmention.io/api/mentions.jf2?per-page=2&page=0&sort-dir=up&target=https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/
#+end_src

#+RESULTS:
#+BEGIN_SRC jsonc
{
  "type": "feed",
  "name": "Webmentions",
  "children": [
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "David Gallows",
        "photo": "https://webmention.io/avatar/pbs.twimg.com/e7b750d847ffdcfc174845aadc9196125b83647258a1789bb2b92b493d223e8b.jpg",
        "url": "https://twitter.com/DavidGallows"
      },
      "url": "https://twitter.com/pdcawley/status/1517783526049001472#favorited-by-877428607",
      "published": null,
      "wm-received": "2022-04-23T09:59:17Z",
      "wm-id": 1385464,
      "wm-source": "https://brid.gy/like/twitter/pdcawley/1517783526049001472/877428607",
      "wm-target": "https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/",
      "like-of": "https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/",
      "wm-property": "like-of",
      "wm-private": false
    },
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "David Gallows",
        "photo": "https://webmention.io/avatar/pbs.twimg.com/e7b750d847ffdcfc174845aadc9196125b83647258a1789bb2b92b493d223e8b.jpg",
        "url": "https://twitter.com/DavidGallows"
      },
      "url": "https://twitter.com/DavidGallows/status/1517852498555555840",
      "published": "2022-04-23T13:06:50+00:00",
      "wm-received": "2022-04-23T15:12:04Z",
      "wm-id": 1385681,
      "wm-source": "https://brid.gy/comment/twitter/pdcawley/1517783526049001472/1517852498555555840",
      "wm-target": "https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/",
      "content": {
        "html": "enjoyed reading about it :)\n\nI've been a trackball man since the word go, But have never been able to move away from Qwerty keyboards\n<a class=\"u-mention\" href=\"http://bofh.org.uk/\"></a>\n<a class=\"u-mention\" href=\"https://twitter.com/DrugCrazed\"></a>\n<a class=\"u-mention\" href=\"https://twitter.com/keyboardio\"></a>\n<a class=\"u-mention\" href=\"https://twitter.com/pdcawley\"></a>",
        "text": "enjoyed reading about it :)\n\nI've been a trackball man since the word go, But have never been able to move away from Qwerty keyboards"
      },
      "in-reply-to": "https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/",
      "wm-property": "in-reply-to",
      "wm-private": false
    }
  ]
}
// GET https://webmention.io/api/mentions.jf2?per-page=2&page=0&sort-dir=up&target=https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/
// HTTP/1.1 200 OK
// Content-Type: application/json;charset=UTF-8
// Transfer-Encoding: chunked
// Connection: keep-alive
// Status: 200 OK
// Cache-Control: no-store
// Access-Control-Allow-Origin: *
// X-Content-Type-Options: nosniff
// Date: Sun, 24 Apr 2022 13:01:16 GMT
// X-Powered-By: Phusion Passenger 5.3.1
// Server: nginx/1.14.0 + Phusion Passenger 5.3.1
// Request duration: 0.721250s
#+END_SRC

Lot's of lovely structured data. Webmention.io has worked out that one mention was a ~like-of~ [[/2013/03/10/in-which-piers-prepares-to-void-the-warranty/][the blog post]], and the other was ~in-reply-to~ it. We get details of the author of the mentioning post and, where appropriate, its content. If I wanted to run more Javascript on here (and I want to run less), I could attach a script which would consume the post's feed and build a display of all of the mentions. It has a certain appeal, just add one script to the site and a dummy ~<div>~ or ~<ul>~ somewhere and I'm laughing. Plenty of sites do just that.

This is not one of those sites. {{{marginnote(Of course, this couldn't possibly because I tried to use the Javascript, couldn't make it work and decided to actually include webmentions in the generated files, that would be foolish!)}}} It's not even the first statically generated site to go down the route of statically generating a post's webmentions. I was mostly inspired by [[https://randomgeekery.org][Brian Wisti]]'s post about [[https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/][consuming the webmention.io API]] (except, of course, I don't use /any/ of his actual code.)

The site's [[https://github.com/pdcawley/bofh.org.uk/][Github repo]] is configured so any commit on the ~main~  @@hugo:{{% marginnote %}}It's 2022 already -- let's stop having 'master' branches, eh?{{% /marginnote %}}@@ branch fires off a workflow that builds the site and ships all the files over to the webserver using ~rsync.~ If I take Brian's idea for grabbing all my webmentions {{{marginnote(I set up the ~rel="webmention"~ link /ages/ ago and never quite got around to doing anything with the data)}}} and ignore his warning about splitting it out into Hugo data files and just do it, I can start building the webmentions for posts. Huzzah!

{{{newthought(It started so innocently,)}}} I have a server here that hosts a couple of Docker images and one of them is [[https://n8n.io/][N8N]], a super powered, self-hosted open source replacement for [[https://ifttt.com/][IFTTT]] with all sorts of hooks into other services and a much more powerful Github client than the IFTTT offering. It's a bit… JavaScript-y for my tastes, but you can't have everything.

With a bit of fiddling, I had something that grabbed the webmention.io feed for the site every few hours, split it out into multiple files in ~data/mentions~ and updated GitHub. That's what I was celebrating in [[*We have WebMentions][We have WebMentions]]. I've moved on {{{marginnote(A cynical person might well read that as "broken things")}}} since then, because /of course/ sorting out de-duplication and remembering information between runs of the script is annoyingly fiddly and full of edge cases. Basically, I ended up trying to emulate a proper database. Which is why the latest iteration of webmention handling uses a proper database. I would have used [[https://sqlite.org/][SQLite]], but N8N doesn't have a SQLite node available out of the box. It does have a [[https://postgresql.org/][PostgreSQL]] one though, and recent versions of that have really good JSON support. I'd tell you more, but ~wc-mode~ tells me I'm nearly 2500 words in to this article, I think I'll wrap up for now and promise to give you the gory details in an upcoming article.

{{{newthought(To be continued…)}}}

* Footnotes
  :PROPERTIES:
  :ID:       43822ABC-ED28-4066-82D3-040188E7A6E6
  :END:

[fn:5]  @@html:<dfn><code>org-mode</code></dfn>@@ is an Emacs outliner that grew into a calendar/outliner/spreadsheet/document processor/literate programming tool/dessert wax/floor topping.

It's what I used to use [[https://bofh.org.uk/2019/02/25/baking-with-emacs/][to manage my bakery]], and it's amazing.

Like Emacs itself, it's almost infinitely flexible, which makes it incredibly hard to get started with. There's oodles of org configurations out there to crib from and all of them are a mixture of the useful and irrelevant, because it turns out that people have different opinions about how they want to organise their writing and/or life. My config is very much under construction.

[fn:4] An @@html:<dfn>@@h-entry@@html:</dfn>@@ is something that a web user might want to mention. At present, all the h-entries on this site are articles, but other people use them to mark up photos, videos, notes, calendar entries or anything else that makes sense to think of as an entry in a collection of stuff. If you'll look at this page in your browser's inspector, you'll see that the content is wrapped in ~<article class="h-entry" …>…</article>~ tags. Other tags within that block are are marked with other classes (so the title has ~p-name~ and the body has ~e-content~), according to the definition of the [[http://microformats.org/wiki/h-entry][h-entry microformat]]. By marking my site up with these micropformats, life becomes much easier for any IndieWeb tools to extract appropriate information from the site.

[fn:2] [[https://gohugo.io][Hugo]] is the static site generator I use to build this blog. Another example of letting the computer do all the fiddly repetitive bits. In this case, to handle all the fiddly bits of writing full HTML pages, building index pages and the rest.

[fn:1] It's also annoyingly temperamental at the moment; I'm working on that though.

[fn:3] The Github Actions based build process is also substantially more reliable than the hand rolled server hook I was using. There's something to be said assembling your build pipeline from a bunch of stuff that lots of other people use (and maintain). Also, it reduces the number of moving parts on the Raspberry Pi that's serving these pages, which is no bad thing.
