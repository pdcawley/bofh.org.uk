# -*- mode: org; -*-
#+hugo_section: post/
#+hugo_base_dir: .
#+export_hugo_weight: auto
#+hugo_auto_set_lastmod: t
#+startup: inlineimages
#+startup: logdone
#+startup: show2levels
#+property: header-args:sql :session reporter :exports result :colnames yes  :engine postgresql :results replace table
#+property: header-args: :exports code
#+hugo_paired_shortcodes: %table %marginnote %newthought
#+macro: newthought @@hugo:{{% newthought %}}@@$1@@hugo:{{% /newthought %}}@@
#+macro: marginnote (eval (concat "@@hugo:{{% marginnote %}}@@" (mapconcat 'identity (remove nil (list $1 $2 $3 $4 $5 $6 $7 $8 $9)) ", ") "@@hugo:{{% /marginnote %}}@@"))
#+macro: sc @@hugo:{{% $1 %}}@@
#+macro: <sc @@hugo:{{< $1 >}}@@
#+seq_todo: TODO(t) DRAFT(d) OPEN(o) | DONE(D) PUBLISHED(p) CANCELLED(x)


* Week Notes :weekNotes:
:PROPERTIES:
:export_hugo_custom_front_matter: :series Week Notes
:END:
** 2023
*** DONE Week ending 2023-07-16
CLOSED: [2023-07-16 Sun 18:32]
:PROPERTIES:
:export_file_name: week-ending-20230716
:export_hugo_slug: week-note
:END:
Small victory of the week: I'm starting to get on top of the washing

#+hugo: more

**** Tuesday

Overwhelm had left us with a huge pile of washing to do, filling the sink, the draining board, and various work surfaces and I kept putting off tackling it because my brainweasels just saw the sheer amount of work involved and shut down. No fun. Anyway, Gill grabbed her perching stool and set to and before I knew it there was a full dishwasher burbling away, an empty sink, a full draining board and the beginnings of a system to keep it that way. The goal is to keep the sink empty and the draining board full. Before I cook, I clear the draining board. Any pans I use go in the sink and the next time I make tea, I wash up what's in the sink and anything that's still not been done of the mahoosive pile, until there's a full draining board again. Next time I'm brewing up, I can put the dry stuff away and, if I have the spoons, chip away at some more of the pile (though, post-COVID, I rarely have the spoons for much -- I can only stand for so long).

It's not perfect, but it gets stuff done, and I'm calling that a win.

**** Wednesday

Emily came over for rehearsal and Carcassonne. It was mostly Carcassonne, if I'm honest, but /The Housewife's Lament/ is starting to seem like we've learned it, as is /We'll Sit Upon The Gate,/ though that one feels like it could use another verse. /The Mary Ellen Carter/ is pretty damned solid too, which is good.

We set a new record city score in Carcassonne too, managing to share a 105 point city. We even managed my first ever draw in the second game.

**** Friday

A solo stream this week. Again with the Overwhelm getting in the way of getting more guests booked, but I'm starting to fill the diary again, which is good. I've got Alex Cumming as my guest in a couple of weeks, and Helen Edwards, Talis Kimberley, Emily, and a folk legend who will remain nameless for the time being lined up for August and September.

Loopy Pro was mostly rock solid. The one-shot overdub whine cropped up once, and there was a hard crash to the home screen at one point, but a restart was fast and clean. Perils of running beta versions of sofware, I guess.

**** Saturday

I toddled over for the morning and afternoon sessions at the Bradfield Traditional Music Weekend -- spent a happy few hours singing Americana (I sang /Cabin in Glory/ and /We're Gonna Camp a Little While in the Wilderness/ which seemed to go down well) in the first session, then there was a lovely, ballad heavy, song session. I sang /Tamlyn/ about as well as I've ever sung it, and it went down really well. I was knocked out by a cracking version of /The Famous Flower of Serving Men/ in particular, but the whole session was great.


**** Sunday

Dim sum at the China Palace for lunch with Dougal & Liz, Matt and Jo and a few of the kids. Excellent as always. We may have overordered

I'm off to the closing session of BTMW later. I suspect it will be as good as the Saturday sessions.


*** DONE Week ending 2023-07-23
CLOSED: [2023-07-23 Sun 21:37]
:PROPERTIES:
:export_file_name: week-ending-20230723
:export_hugo_slug: week-note
:END:

Small victory of the week: Actually got off my arse and did something about selling off my old /Magic the Gathering/ cards. For my next trick, I hope to do the same with my collection of [mostly card] magic books.

#+hugo: more

**** Tuesday
Made a capture template for adding a week note. Support functions are currently not the prettiest, and don't deal with a bunch of corner cases, but they seem to work for my case, so I'll leave 'em be for the time being. I plan to write it up in a longer post, and that will no doubt tweak my coder pride enough to make things suck a little less.

Oh god, once I start fiddling with my Emacs configuration, it's impossible to stop!

**** Wednesday
Nipped over to Mum and Dad's for lunch at Zini's, and to borrow dad's drills for my on going cigar box MIDI controller project. Managed to get eight holes accurately placed enough that I only had to drill 7.8mm holes for the M7 threaded rotary encoders I'd soldered to my stripboard. I'm calling that a win! Next trick, get the microcontroller wired up and appropriate software written.

Also discussed making PID controller I promised to make dad for his heat treatment setup a while back. A Pi Pico and one of its mini displays looks like it should do the job nicely. The plan is to make an extension cable with an SSR as a separate bit of kit, then control that from the prototype controller. Once they're working as separate parts, we can work out how to bring it all into one container. I shall wuss out of making the kind of thing I saw in a commercial radio controlled plug, which powered the control circuit with a very simple capacitor based power supply, with the slightly worrying wrinkle that the controller's 0V line was floating at around 5V below mains Vmax. Clever, sure, but scarier than I'm prepared to work with.

**** Friday

Holy crap, but old /Magic the Gathering/ cards are getting horrifically pricy. According to the buy list of the shop I just took my cards in to, I should be expecting about Â£400 for just four of my cards. And probably another couple of hundred for the two dual lands (assuming they're not from the Unlimited set, in which case they're worth a /lot/ more). All being well that's covered the cost of getting my grandfather's old recliner reupholstered and fixed.

If I could be arsed with it, I could probably get a lot more by selling direct on eBay, but I was already losing the will to live just sorting things out to take in to the shop.

Do /not/ ask me about the /Tabernacle at Pendrell Vale/ and /Black Lotus/ that I sold far too early, because that might make me grumpy.

*** DONE Week ending 2023-07-30
CLOSED: [2023-07-30 Sun 22:48]
:PROPERTIES:
:export_file_name: week-ending-20230730
:export_hugo_slug: week-note
:END:

Three weeks on the trot. Definitely calling that a win.

Also, Good Omens 2 is a delight. Still enough of Terry's character hanging
around it, and the new writers help it not feel too Neil-y.
#+hugo: more

**** Wednesday

After a bit of fiddling, I've worked out how to add helpers to the Emacs `C-x 8` keymap, so now I have shortcuts for typing 'Î»', 'ðŸ™‚' and various other characters that I type more or less frequently. Beats the crap out of doing `C-x 8 <ret>` and then typing out the name of the character I'm looking for.

In case you're interested, here's the code:

#+begin_src emacs-lisp
    (general-define-key
      :keymaps 'iso-transl-ctl-x-8-map
      ". ," "â€¦"
      ": )" "ðŸ™‚"
      ": D" "ðŸ˜€"
      "; )" "ðŸ˜‰"
      "\\"  "Î»"
      "a ^" "â†‘"
      "a u" "â†‘"
      "a v" "â†“"
      "a d" "â†“"
      "a |" "â†•")
#+end_src

If you're not using `general`, but you've got `use-package` installed, you can do something similar with `bind-keys`:

#+begin_src emacs-lisp

  (bind-keys
   :map 'iso-transl-ctl-x-8-map
   (". ," . "â€¦")
   (": )" . "ðŸ™‚")
   (": D" . "ðŸ˜€")
   (":|"  . "ðŸ˜")
   ("; )" . "ðŸ˜‰")
   ("\\"  . "Î»")
   ("a ^" . "â†‘")
   ("a u" . "â†‘")
   ("a v" . "â†“")
   ("a d" . "â†“")
   ("a |" . "â†•"))

#+end_src

You can no doubt use define-key as well, but I find `general` or `bind-keys` to be much nicer to work with. The latter has the advantage that it's included in Emacs as part of `use-package` and plays nice with `which-key`, so I might go and redo my key bindings and get rid of `general`, nice as it is, since the real selling point of that library is how easy it is to bind stuff in `evil-mode` states.
**** Sunday

I still miss /Twitch Sings./ It's how I started streamingâ€”long before the Friday night Song Swaps and folk streams. I'd be happily belting out Lady Gaga's /Bad Romance/, hamming it up to /You Spin Me Round/ or giving it my best Johnny Cash
#+begin_marginnote
Not a particularly good impression. I can't get that low!
#+end_marginnote
on /Hurt./ It was just huge fun and a great way to make friends on Twitch.

Twitch ended up pulling the plug because it was a free app andâ€¦ well, free apps and sync rights really don't play well together.

You'll still find people doing Karaoke on Twitch though, many of them the same faces I met back in /Twitch Sings/ days. This morning, I woke up early and spotted some friends Karaoke-ing it up on a Discord, so I pulled on pyjamas and went and joined 'em for a few songs. These days, I just use [[https://loopypro.com][Loopy Pro]] rather than searching YouTube for backing tracks. It's great fun though, and definitely makes for a more enjoyable way to spend the occasional hour or so of early morning insomnia.

Singing in company, even virtual company is still the best thing you can do in public with your clothes on. I encourage you all to sing more. What's the worst that could happen?
*** DONE Week ending 2023-08-13
CLOSED: [2023-08-14 Mon 09:02]
:PROPERTIES:
:export_file_name: week-ending-20230813
:export_hugo_slug: week-note
:END:
Oops, missed a week; seems I didn't have anything interesting to say, or I was too busy doing stuff to write about it. Probably the former.

Not a bad week, this week. My step daughter and her family called in on their way back from holiday on Friday night and we spent a pleasant evening with them and a few Cawleys who were knocking about, sat outside the Wool Market. Mostly good food, but apparently the Greek place isn't that good. Rustic Pizza is still good though.

#+hugo:more
**** Friday

Most of the proceeds of my /Magic: The Gathering/ cards will be spent on repairing my grandfather's recliner. But... I wouldn't be me if I didn't spend some of it on something gamelike. So I bought myself a 'GameDad'. In my case, an [[https://anbernic.com/products/rg353v-rg353vs][Anbernic RG 353VS]] and it's a hell of a thing. Not much bigger than an old school Game Boy (and /cheaper!/ Not just in real terms, but the Game Boy launched at $89.99 and I got mine for $87.99), but with a large, bright colour screen and enough grunt to play SNES and PlayStation games at full tilt. Apparently, you can even make it play Nintendo 64 stuff, but not necessarily at full speed.

I don't really care about emulating consoles I never owned though. I want to play /Manic Miner/, /Tempest/, /Dig Dug/, /Galaxians/ and the other games that gladly ate my pocket money, ten pence at a time, down the local arcade (the building's still there in all it's new brutalist concrete glory, but the arcade where I boggled at /I, Robot/ and thrilled to the exploits of the masters of /Defender/ and /Robotron/ is long gone).

So, in search of that heady thrill and those unmistakable sound effects, I've been frequenting archive.org's library of delights and installing a few of my old favourites.

The first to get seriously played was my old favourite /Tempest/ -- Atari's miracle of colour vector graphics where you controlled a spiky yellow thing running around the top of a blue tube shooting the terrifying geometric shapes that were climbing up towards you with deadly intent. When I first started playing it, I'd hold the fire button down and spin madly round the top of the tube and die all too quickly. But it was such fun I'd just shove another coin in the slot until my money was all gone. Then, in an arcade in Whitby, I watched someone playing the game in an entirely new way and my mind was blown. The walls weren't blue! The colours were different and there were new, scary shapes. This guy wasn't spinning around, and he wasn't just holding down the fire button either.

Tempest was unusual for the time in that it had autofire. If you held down the fire button on most games of the era, you'd fire one shot, then nothing would happen. But in Tempest, you'd autofire bursts of eight missiles, then a slight pause and the cycle would repeat. And it was the slight pause that would kill you. The Whitby guy had sussed that out and was mashing the fire button at a measured speed that kept up a constant stream of evenly spaced bullets that were far more likely to save you when a Flipper had reached the top of the tube and was making its way towards you; they could only kill you if they in the same space as you and were vulnerable to your shots while they were flipping that last step towards you. If you were simply relying on autofire, you could bet that that flip would happen during the short pause between bursts.

Whitby guy had also worked out that the larger the angle a flipper had to flip through, the more chance you had of killing it before it killed you, so for lots of levels, it was just a matter of finding the safest place and staying there. There are a couple of levels where you were only 'safe' from flippers coming from one side. Those were the levels that killed you unless you got good at moving from place of safety to place of safety.

I watched intently and, when I returned to my home arcade, suddenly the top three scores -- the ones that got burned into non volatile memory -- on the arcade's machine belonged to PDC. I could reliably reach the red levels and even the next, yellow, set.

I can't do that on the Game Dad. Not yet at least. I'm old enough and RSI'd enough, that the thought of bashing the fire button at 8 Hertz just gives me the shivers.

But! Modern emulators have all sorts of convenience functions, surely I could configure something that would emulate the steady rate of fire that my youthful fingers were capable of. And maybe I could do something about the incredibly sensitive controls, where even the lightest touch of the analog stick would see me moving two or more segments when what I really wanted was a surgical one step move.[fn:12]

I turns out that I could. But, frustratingly, not via the very slick UI. I had to edit text files! I had to make new text files. And because popping the Micro SD card out of the Game Dad and into a card reader, editing a file, putting it back in the GD, testing it and then having to fiddle with the text file again isâ€¦ less than ideal, I did it by /logging into my handheld games console via SSH from my iPad, editing the file and just restarting the game!/

You can't do that with an original Game Boy can you? The damned thing's running Linux. I'm at once annoyed that I had to log in to it and fiddle with text files and astonished that I could even do that.

It's not the nostalgia that's making me feel old, it's my assumptions about what's capable of what kind of computing.
*** DONE Week ending 2023-08-20
CLOSED: [2023-08-21 Mon 10:17]
:PROPERTIES:
:export_file_name: week-ending-20230820
:export_hugo_slug: week-note
:END:

A quiet week. Had to cancel Friday night's singing session with Emily â€“ initially because Emily's still recovering from COVID, but on the night itself, my diabetes meds decided to give me hellacious indigestion. Ozempic/semaglutide might well do wonders for my HBA1c readings, but it can't half mess with my guts as well.
*** DONE Week ending 2023-08-27
CLOSED: [2023-08-27 Sun 12:32]
:PROPERTIES:
:export_file_name: week-ending-20230827
:export_hugo_slug: week-note
:END:

A bit of a mixed week, mood wise. Capped by a great day's singing and chatting in Peterborough yesterday.

It's great to get out of the house sometimes. Gill coped really well by herself too -- I'm a full time carer, but it's definitely good to know that I can have the odd day off without it completely buggering things up.

#+hugo: more
**** Monday
***** Folk FOMO
Whitby Folk Festival FOMO is real. But also, there's a COVID spike going on, and crowded rooms full of unmasked singers aren't the safest of environments, so I think I'll comfort myself in the knowledge that at least I won't be likely to bring an infection home with me.
***** Blog fiddling
I swear I'm going to wrap my head around the workings of the way to optionally build a custom formatted Date tree using =org-capture=, but for now I've just tweaked the template I use to add

#+begin_src org
#+hugo: more
#+end_src

to the heading for the week. This means that, when Hugo's rendering the index page, the week's notes will be represented by a summary which links to the extended per-day notes for the week.

Furthermore, I've added a new capture to let me capture a weeks' summary. I think I'll probably end up wrapping that in a =summarize-week= command that will show me the wider weeknote context while I write the note, then mark the week as =DONE=, then bring up =magit= so I can commit and push the changes. But maybe not for a while yet, on the "fake it until you can't stand /not/ to automate it." principle.
**** Thursday

So, I have the ADHD thing of putting a thing down and completely forgetting where I put it, or even its very existence. Object permanence is clearly not a thing with me.

Or I thought it was.

We have a house guest right now, and she has this habit of trying to help by tidying putting stuff in 'sensible' places. So I'll find the squash in amongst the bottles of oil, vinegar and sauces in a /completely other part of the kitchen;/ or Gill's socks will show up in an admittedly convenient, but surprising, new place after I've given up looking for them in the place I usually put them, and the airer I dry them on, and in the washing machine and laundry basket. Maybe it's on the floor between any of those placesâ€¦ Grrr.

It turns out I'm kind of comfortable with not quite knowing where a thing is, but I am absolutely viscerally /infuriated/ by finding said thing in the wrong fucking place, somewhere I would never ever ever in a month of Sundays deliberately put it.

And don'tâ€¦ don't get me started on the utter utter utter wrongness of using the lids of things as shelves. I will end up foaming at the mouth and shouting. Ask me how I know.

It's all the more distressing because I hate getting angry about stuff, especially objectively trivial stuff like this, and so the rate spirals. Bah!
**** Saturday

Had a great day at Mill Con 2 down in Peterborough. I still think filk music as a genre is a bit weird, but there's no denying that the people who make it are lovely people, and it's hard to beat singing in company for lifting your mood.

Mike Whitaker was kind enough to give me a concert spot at a week's notice too, so I did a forty minute set with a couple of songs with Loopy Pro in what was only the second time I've used the gear in any setting but my 'streaming studio.' It went well, but there's still a way larger profusion of wires than I'm happy with, and I definitely want to assemble some kind of all in one pedal setup if I'm going to be taking the gear out of the house more often.
*** DONE Week ending 2023-09-03
CLOSED: [2023-09-03 Sun 13:47]
:PROPERTIES:
:export_file_name: week-ending-20230903
:export_hugo_slug: week-note
:END:

Another quiet week. Streamed tired on Friday night, so quite a bit of pilot error with the looper, but folk still seemed to enjoy it.

Scrooby show was lovely on Saturday. Nice to catch up with a few folk I've not seen in quite a while and the weather was flat out gorgeous. I took some modelling balloons, planning to do a few balloon animals and hats, had something like a 60% burst rate with the Sempertex 260Ss that were all I could get hold of at short notice. Won't be using those again. Qualatex all the way, I think.
*** DONE Week ending 2023-09-24
CLOSED: [2023-09-24 Sun 10:47]
:PROPERTIES:
:export_file_name: week-ending-20230924
:export_hugo_slug: week-note
:END:

I'm not quite sure where the time went these last couple of weeks, but here we are at another Sunday. We've spent quite a bit of the time watching a new family of kittens that have taken to playing on the flat roof of our garage. They're almost obscenely cute scraps of black and white fur and just delightful to watch.

#+hugo: more
**** Sunday

Back in 2012, we were living in Cornwall and used to go to the regular Farmers' Markets in Mullion and Helston. One week, at Mullion, a new trader showed up selling home made bean to bar chocolate under the name of [[https://chocolarder.com/][Chocolarder]]. I got chatting with Mike, the guy who made the stuff, and bought a few bars and some of his [[https://www.chocolarder.com/shop/sea-salt-caramel-truffles/][sea salt caramel truffles]]. If we weren't actually his first customer, we were damned close.

Every month, he showed up with plain looking bars of /amazing/ chocolate. One time he'd bought a bunch of rose petals (apparently, they can be had quite reasonably after Valentine's Day because there's something of a glut), dessicated them, ground them fine and added them to the chocolate. Bloody delicious!

I told Mike about some milk chocolate with sea salt that I'd tried and really loved and suggested he do something similar. He'd have a go he said. Months later (after many experiments, apparently) there he was with some bars of salted milk chocolate so I bought as many as I had the cash for and loved every mouthful. He didn't make them again though. Except, today, with a bit of birthday money burning a hole in my pocket, I thought "I'd love some Chocolarder chocolate, it's been an age" and what did they have? You guessed it: [[https://www.chocolarder.com/shop/sea-salt-milk/][Cornish sea salt]] milk chocolate. So that's a chunk of birthday money spent.

Yes, it's a lot of money for a bar of chocolate, but believe me, it's amazing stuff and Mike is as committed to ethical and sustainable manufacture as anyone I've ever met. We've visited the factory a couple of times and I remember the time we visited and he was more excited about showing off his new, plastic free packaging as he was about the chocolate. He buys direct from cacao farmers and has been known to get his beans shipped by sail rather than container ship.

* Bakehouse Diary :@bakehouse-diary:
:PROPERTIES:
:export_hugo_custom_front_matter: :series "Bakehouse Diary"
:ID:       1704207D-154F-4BA2-A7AA-35585A21295E
:END:

** Bakehouse Diary
:PROPERTIES:
:export_file_name: back-to-the-bakehouse
:export_date: [2018-02-01 Thu]
:export_hugo_custom_front_matter: :description "Back to the bakehouse" :series "Bakehouse Diary"
:ID:       A734F151-393D-4609-A408-8942FE197BBB
:END:

I know! It's been a while. But we're in! I have baked, and it was
good. There's still a ton of stuff to do (plumbing, mostly) but the
really important bits of kit are all in place and looking good.

We celebrated getting in by turning one of the decks up as high as it
would go and making lots of pizzas and a few loaves of bread.

#+attr_html: :width 100%
#+caption: An early pizza
[[file:./back-to-the-bakehouse/margherita-pizza.jpg]]

#+hugo: more

*** The story so farâ€¦
:PROPERTIES:
:ID:       9B5B244B-A654-4254-BCEA-9CE31C600321
:END:

In my [[file:/2016/11/11/taking-stock/][last entry]] (over a year ago, argh! Gill is /much/ better) the
oven and all my kit were still in my garage, up on blocks waiting for
Dad to build an A-frame so we could winch it up and assemble it. Which
happened, and we managed to get one section of oven up onto the base.
And there we stopped because the fully assembled oven is very tall, and
the A-frame isn't tall enough to accommodate a fully assembled oven +
the winch + space for the straps (and my garage roof isn't high enough
to accommodate a sufficently tall A-frame). Still, it allowed us to
start in on prEocess of breaking the heads of very old brass
machine screws and generally failing to get the oven beds out where
they could be cleaned. This was frustrating, but it's not like I was
unused to frustration.

Meanwhile, the bakehouse site moved again. We had thought it would be
a relatively easy (and thus cheap) matter to run the necessary 3-phase
power to the space, but it turns out there wasn't quite enough power
going to the building to support what we needed. That would mean a new
substation and some very expensive cable laying. So it wasn't going to
fly. Luckily, there is also an old cafe in the yard. And it already has 3
phase, and enough 3 phase at that. So we set about making that into a
bakehouse. A lick of paint; some new flooring; wider, taller doorways
so we could get the oven in. Minor stuff like that.

By now we're up to late spring of 2017. I'd given up on trying to
renovate the decks myself, so I got onto Martin Passey at [[http://becketts.co.uk/][Becketts]] and
arranged for them to sort out the electrics and replace the rusty
steel beds with ceramic ones instead, which are generally reckoned to
be the best choice if you want to make 'hearth' breads on the oven
floor. We just needed to work out how to get the oven from Doncaster
to Heywood.

Guess what? It wasn't straightforward.

When we picked up my oven from the Isle of Wight, we'd got it into a
large Luton bodied van with a tail lift, and it was kind of fine. I
suppose I could have hired another one, roped in a few volunteers and
driven it over myself, but the fact that we'd partially assembled the
oven was going to make that rather trickier than it could have been.
Disassembling it was going to be tricky too - after we got the straps
out from the top decks when we'd assembled it, we discovered we'd been
very lucky indeed, and the strap had /very/ nearly broken.

The best option was to get a flatbed truck with a Hiab or similar
hydraulic crane which would make short work of getting the oven up
onto the truck and off to be fettled. But the access (up a 10 foot
wide back lane) proved daunting. All the haulage companies I talked to
took one look at it and backed away, muttering darkly and making the
sign of the cross. "Get a bunch of strong Polish lads to carry it down
the alley and stick it on the back of a truck" was the best (but very
unofficial) suggestion. Not ideal.

So now it's July and I'm chatting to a fellow guest at my brother's
silver wedding anniversary about my shipping woes. "You want to talk
to Dan!" he said.

"Dan?"

"Yeah, [[http://www.danpunchard.co.uk/][Dan Punchard]]. He's great, he's moved a couple of lathes for me
with some really tight access."

"Thanks!"

My informant was not wrong. Dan was brilliant. We exchanged a few
emails and photos of the access and /bang/ the oven was off into the
tender loving care of Becketts for its electrical fettling and new
floors. And soon the money was flowing out of my savings as I bought a
new spiral mixer, wire cooling baskets, steel work table, scales (both
electronic for weighing ingredients into the mixer and a balance
scale, which is /still/ the fastest way of scaling dough when you
divide it), lots of [[https://www.bakerybits.co.uk/bakery-equipment/proving-baskets-and-cloths/wicker-baskets/heavy-duty.html][bannetons]] (probably not enough) from Bakery Bits,
workwear, flour, wire shelving, and a bewildering amount of janitorial
bits and bobs from [[https://nisbets.co.uk/][Nisbets]]. Fettling the oven wasn't exactly cheap,
but wow, do those baskets add up!

*** It's arrived, and it fits
:PROPERTIES:
:ID:       AD747BAF-5C59-4456-B10E-EC021530372C
:END:

On the 8th of December last year I sent mail Martin some mail with the
subject "It's arrived, and it fits!" and over the next couple of weeks
the rest of the stuff I needed to bake arrived and, on the 20th of
December, I fired up the mixer for batch of 16 loaves and what proved
to be far too many pizza doughballs.

On Friday 21st of December, I pulled my first loaves out of my ~40
year old oven, and /damn/, but they were good.

#+attr_html: :width 100%
#+caption: The first loaf
[[file:./back-to-the-bakehouse/first-loaf.jpg]]

*** What next?
:PROPERTIES:
:ID:       6006477E-9259-4548-BE06-AA284C35787B
:END:

Of course, no enterprise like this is ever finished, here's a
selection from my to do list.


**** Plumbing
:PROPERTIES:
:ID:       C3EF1AE5-0633-4355-9A9E-AADC63202AC2
:END:
A bigger sink! Water near the scale so I'm not carrying buckets
back and forth! A handwash basin!

**** Qualifications
:PROPERTIES:
:ID:       D2940478-569D-4A68-8A85-A3FB832E0DD7
:END:
Environmental Health Officers do like you to have a certificate
to show you're not a complete moron when it comes to hygiene.
Breadmaking is relatively low risk because everything gets so
very hot during the cooking process, but even so.

**** Refrigeration
:PROPERTIES:
:ID:       7C336767-BFD8-4C6F-AB3F-379D615EF2CF
:END:
Right now everything's at the ambient temperature, which can mean
staying in the bake house until the early hours in order to get
the loaves into the oven when they're perfectly proved. A better
approach would be to stick the dough into a retarder (big
fridge, racked for standard bakers' sheet pans) and bake them
first thing in the morning after a decent night's sleep. I have a
retarder, but transport is annoyingly tricky because it's 2m
tall, and should ideally be transported vertically too.

**** Fitness
:PROPERTIES:
:ID:       0599F968-72F3-467F-B4A8-5ADE5EBC6548
:END:
Right now, I can just about cope with two bakes a week, but if
I'm going to actually make money at this, I'm going to need to be
able to manage more. Hopefully, as I bake it'll improve my
fitness, so as demand grows I'll be able to meet it.

**** Marketing
:PROPERTIES:
:ID:       584A5EC0-B1AA-425F-80E1-071BE00980FD
:END:
Oh boy, do I suck at marketing? Still, the product is good and
there's nobody else in the local area making this sort of bread,
so I have a few advantages. I still haven't made a Loafery
website though. At least I have the loafery.co.uk domain.

**** Online ordering
:PROPERTIES:
:ID:       FD89D3AC-84C8-4884-B2B4-FA445111D76D
:END:
If I can get people ordering online, I can use that to produce
production schedules, and generally have a better idea of how
much to make on each bake day, which help minimise any wasted
bread. With two bakes done this year, I've sold every loaf - I'd
like to keep that up.

*** In the next bakehouse diary...
:PROPERTIES:
:ID:       6B4B05DF-007B-4559-ACFE-BB21BCEADA42
:END:
I'll talk about how a bake goes and the process of developing an
initial range of products, sourcing flour and other ingredients
and hopefully some news about online ordering.




** DONE Running a bakery on Emacs and PostgreSQL
:PROPERTIES:
:EXPORT_FILE_NAME: baking-with-emacs
:export_hugo_slug: baking-with-emacs
:export_hugo_custom_front_matter: :series "Bakehouse diary"
:export_date: 2019-02-25
:ID:       92F8529F-9830-4DE4-8E26-61B606BAF48B
:END:

Just over a year ago now, I finally opened the bakery I'd been dreaming of for years. It's been a big change in my life, from spending all my time sat in front of a computer, to spending most of it making actual stuff. And stuff that makes people happy, at that. It's been a huge change, but I can't think of a single job change that's ever made me as happy as this one.

#+hugo: more

One of the big changes that came with going pro was that suddenly I was having to work out how much stuff I needed to mix to fill the orders I needed. On the face of it, this is really simple, just work out how much dough you need, then work out what quantities to mix to make that much dough. Easy. You can do it with a pencil and paper. Or, in traditional bakers' fashion, by scrawling with your finger on a floured work bench.

And that's how I coped for a few weeks early on. But I kept making mistakes, which makes for an inconsistent product (bread is very forgiving, you have to work quite hard to make something that isn't bread, but consistency /matters/). I needed to automate.

I'd been on one of Bread Matters' "Baking for a Living" courses and as part of the course materials had received a copy of a spreadsheet that could be used to go from a list of orders to a list of ingredients to mix alongside accurate costings and other useful bits and bobs. It was great and certainly opened my eyes to the possibilities for automation of this part of the job.

And then I tried to add a new recipe.

Spreadsheets aren't my favourite computational model so maybe it was just my lack of experience with them, but adding a new recipe was like pulling teeth; lots of tedious copying, pasting and repetition of formulae. It just seemed wrong, especially as the underlying computations were so straightforward (ish). There had to be a better way.

The key insight is that a bakery formula is so cliched that it can be represented as data. Here's the formula for seedy malt loaves:

| recipe           | ingredient       | quantity |
|------------------+------------------+----------|
| Small Seedy Malt | Seedy malt dough | .61 kg   |
| Large Seedy Malt | Seedy malt dough | .92 kg   |

Of course, that's not the full set of formulae, because it doesn't tell you how to make 'Seedy malt dough', but that's just another formula, which consists of flour, water, starter, salt and a multiseed 'soaker', where the starter and the soaker are the results of other formulae, which are (finally) made from basic ingredients.
#+begin_marginnote
With a certain amount of handwaving to deal with the fact that a starter is strictly made with flour, water and starter.
#+end_marginnote
I did consider reaching for the object oriented hammer at this point, but thought that I might be able to do everything I needed without leaving SQL. It was relatively straightforward to move the shape of the calculations in the Bread Matters spreadsheet into my database schema, the only real sticking point being the recursive nature of the formulae, but it turns out that recursive queries are a thing in modern SQL, albeit a little tricky to get absolutely right
#+begin_marginnote
A few bakes went a little weird before I finally got things sorted.
#+end_marginnote
first time.
If you're curious about the details of the schema, you can find it in my [[https://github.com/pdcawley/bakehouse][github repo]] for the bakery.
#+begin_marginnote
 And several of you seem to be, so I wrote [[file:/2019/03/04/recursive-sql-recipes/][another post]] with a bit more detail and some sample code.
#+end_marginnote
@@

So now, a few days before a bake, I'd setup my ~production_order~ table with the orders for the bake, and run a query on the ~production_list~ view to find out what I needed to mix when. And all was great. Well, sort of. I had to add a bit extra onto the quantities in the initial starter mix to allow for the bits that get stuck to the bowl and lost to the final dough, and it was all very well until I wanted to bake two days in a row (a bake is a two day process from mixing the starters on a Wednesday evening, through mixing, fermenting and shaping on Thursday to baking the resulting loaves at four on Friday morning). But, vitally, it was much, much easier to add and adjust formulae, and the limitations were no worse than the limitations of the spreadsheet. All was well.

It's the nature of business that you need to keep records. How much got baked? How much sold? Did we clean the floor? Were there any accidents? What sort? How do we prevent them next time? The list is endless. It all needs to be recorded, for both legal and pragmatic reasons. So I started a day book. This is just an .org file
#+begin_marginnote
 Org-mode is an amazing emacs package that's a sort of outliner/task manager/publishing tool/spreadsheet/diary/literate programming environment. It's bewilderingly capable, and is probably the primary driver of the emacs renaissance as people are coming to the editor for org-mode, and porting the rest of their environment - hence the rise of ~evil-mode~, the emacs vim emulation layer.
#+end_marginnote
Every day I come into the bakery, I run ~org-capture~ and I get a template for the day's entry in the daybook, which I fill in as the day goes on.

One of the features of org-mode is ~org-babel~, a literate programming environment, which lets me write something like:

#+name: 07CEE761-D52F-4A44-B4C6-4F6284D947BB
#+begin_src org
,#+begin_src sql
SELECT ingredient, quantity
  FROM bakehouse.production_list
 WHERE work_date = 'today';
,#+end_src
#+end_src

and then, with the cursor somewhere in the code block, hit ~C-c C-c~ whereupon Emacs will run that SQL against the bakery database and populate a table like:

| ingredient  | quantity |
|-------------+----------|
| Old starter |      1.3 |
| Water       |     2.08 |
| White flour |      2.6 |
| ...         |      ... |

If that were all org-mode did to assist, it'd be awesome enough, but the queries I make are a little more complex than that, the current version of the database understands about dates and can cope with overlapping bakes, but all that makes the queries a little more complex. Org-mode helps with that too, because I can file away snippets of code in a 'library of babel' and just reference them from the daybook. And I can set arbitrary variables at any point in the hierarchy of the document.

So I have a bit of code in my emacs config that tweaks the day's entry in a daybook like so:

#+name: 1A928B6D-FED5-44C5-9AD1-5E50181B0199
#+begin_src emacs-lisp
  (defun pdc//in-bakery-daybook? ()
    "Are we in the bakery daybook?"
    (equal (buffer-name) "CAPTURE-loafery-daybook.org"))

  (defun pdc/set-daybook-entry-properties ()
    "Set the properties we rely on in our boilerplated daybook queries"
    (save-excursion
      (while (not (looking-at "*+ [[:digit:]]\\{4\\}\\(-[[:digit:]]\\{2\\}\\)\\{2\\}"))
        (org-up-element))
      (let ((entry-date (first (s-split " " (org-entry-get (point) "ITEM")))))
        (org-entry-put
         (point)
         "header-args+"
         (format ":var work_date=\"'%s'\"" entry-date)))
      (org-babel-execute-subtree)))

  (defun pdc/org-capture-before-finalize-daybook-entry ()
    (when (pdc//in-bakery-daybook?)
      (pdc/set-daybook-entry-properties)))

  (add-hook 'org-capture-before-finalize-hook
            #'pdc/org-capture-before-finalize-daybook-entry)
#+end_src

It won't win any code beauty contests, but it does the job of setting a ~work_date~ variable for the day's entry and running any code in the subtree as part of the capture process. The capture template has lines like ~#+call:mixes()~, which call the stored code snippets, that reference the variable set in the current subtree and so make the query for the right day. This means that all I have to do to know what I should be doing when I get into the bakehouse is to run an org-capture and check the resulting entry in my daybook. Provided, that is, that I've added the appropriate rows to the database.

*** Next steps
:PROPERTIES:
:ID:       30E7B083-080A-45CC-AED5-A9D55E210170
:END:

The software isn't done, of course, no software ever is. But it's good enough that it's been managing my mixes without a hitch for the last few months, telling me what to pack for which customer and generally removing the need to work anything out with a pencil and paper. It's nowhere near as mature or capable of commercial production management software, but it fits me. I understand what it does and why, how it does it, the limitations it has and how to work around them. When it becomes annoying enough, I might sit down and work out how to fix it, but I'll do that when I'm in the right frame of mind. My current list of niggles looks something like this:

- Accounting :: The database already knows how to do costings based on raw ingredient costs etc, but I should probably be able to use it to keep my books as well, using ~org-ledger~
- Parametric recipes :: At a certain point, it becomes easier to mix a 'stiff starter' in my mixer than it is to just mix the usual wet starter by hand. This breakpoint comes at around 3kg of flour. Right now, I manage this by looking at the mixes for my starters and, if it looks like a lot, changing the order to use 2-stage versions of the formulae and running the query again. I think it should be possible to automate this through a more sophisticated query, but I need to work that out.
- Better scheduling :: things get weird if a batch of dough would be more than I can mix in a single go. Right now there are other physical limitations that mean that I simply can't make that much bread anyway, but once I get a few more bannetons and racks, this will become a much more pressing issue.
- Order management :: Right now, I manage orders through Postico talking to the database, which is okay, but a little frustrating in places. An autocompleting environment for orders within emacs would be a much neater way to manage things.

*** Putting the personal in personal computing
:PROPERTIES:
:ID:       EB0497C2-51A6-4452-8CEE-E587BE2AA695
:END:
Computers are amazing. They are versatile tools even if you don't know how to program them, because there's almost always an app for what you want, or something close enough that you cant work around its infelicities. It's quite remarkable the things that folks can do with their kit with no programming skill at all.

But... learn to program, and a whole other vista of possibility opens up to you. With good programmable tooling you're only really limited by your skill and understanding. Instead of accommodating yourself to your software, you can accommodate your software to you, and make the right functionality trade-offs for you. There's a brilliant commercial piece of music looping sofware I use that could be massively more brilliant if there were a way of picking up the tempo automatically from the first recorded loop - it would free me from having to sing to a click and generally make the whole process easier. The developers have other (understandable) priorities, like porting the app to windows. And they're not wrong to do so. There were folk clamoring for a windows version, and if a developer isn't making money from a commercial application, then development will stop. I'm definitely not complaining, the feature is not so dramatically necessary that I'm prepared to spend the time learning how to do real time music programming in order to implement it, but if I want software to dance to /my/ tune then doing it myself is the only way.

So... choose tools that let you program them. I choose emacs and PostgreSQL, you might choose vim and SQLite or Atom and a NoSQL database, or you might just live in your Smalltalk image. Once you start to see your computing environment as truly soft and malleable, you can do amazing things, assisted by a computer that is truly /yours/.


** DONE "A recipe is just a directed acyclic graphâ€¦"
:PROPERTIES:
:export_hugo_slug: recursive-sql-recipes
:export_file_name: recursive-sql-recipes
:export_date: 2019-03-04
:export_hugo_custom_front_matter: :series "Bakehouse diary" :math true
:ID:       F00B26A5-3E3A-42EC-858E-77A47CA209E3
:END:

In [[file:/2019/02/25/baking-with-emacs][the last post]] I handwaved the way I represented bakery formulae in the bakery database, so here's a little more detail. It helps to think of a bakery formula as a node on a directed acyclic
#+begin_marginnote
If you ignore the fact that a starter is made of flour, water and starter. Which, of course, we're going to.
#+end_marginnote
graph with weighted edges, where the weights are literally weights. Here's the graph a for a  couple of products

# #+begin_src dot :file formulae.svg :exports none :results file :cmdline -Tsvg
# digraph G {
# rankdir=LR;
# node [shape=box];
# { rank = same; "5 seed soaker"; "80% starter"; }
# { rank = same; node [shape=ellipse]; "water"; "white flour"; "salt"; "malthouse flour";
# "5 seed mix"; }

# "Small Seedy Malt" -> "Seedy Malt Dough" [label="600g"];
# "Small White Wild" -> "Basic White Sour" [label="600g"];

# "Basic White Sour" -> "80% starter" [label="90%"];
# "Basic White Sour" -> "white flour" [label="100%"];
# "Basic White Sour" -> "water" [label="55%"];
# "Basic White Sour" -> "salt" [label="3%"];

# "Seedy Malt Dough" -> "5 seed soaker" [label="50%"];
# "Seedy Malt Dough" -> "80% starter" [label="45%"];
# "Seedy Malt Dough" -> "malthouse flour" [label="100%"];
# "Seedy Malt Dough" -> "water" [label="47.5%"];
# "Seedy Malt Dough" -> "salt" [label="3%"];

# "5 seed soaker" -> "5 seed mix" [label="100%"];
# "5 seed soaker" -> "water" [label="120%"];

# "80% starter" -> "white flour" [label="100%"];
# "80% starter" -> "water" [label="80%"];
# }
# #+end_src

#+results:
#+begin_RESULTS
[[file:formulae.svg]]
#+end_RESULTS

#+hugo: more

And here's how we represent that in the database
#+begin_marginnote
This table is the result of a query on my real database, where the quantities are in kg, as opposed to the graph representation which was handrolled and adjusted to use bakers' percentages which is how formulae are traditionally written.
#+end_marginnote
@@:

#+begin_comment
#+begin_src sql :exports results
WITH RECURSIVE f(name,ingredient,amount) AS (
  SELECT recipe, ingredient, amount
    FROM bakehouse.recipe_item
   WHERE recipe IN ('Small Seedy Malt', 'Small White Wild')
 UNION
  SELECT ri.recipe, ri.ingredient, ri.amount
   FROM f
   JOIN bakehouse.recipe_item ri ON ri.recipe = f.ingredient
)
select name, ingredient, format('%s kg', ROUND(amount, 2)) from f order by name;
#+end_src
#+end_comment

#+results:
| name             | ingredient                    | format  |
|------------------+-------------------------------+---------|
| Small Seedy Malt | Seedy Malt Dough              | 0.63 kg |
| Small White Wild | Basic White Sour              | 0.63 kg |
| Basic White Sour | Organic white flour           | 2.00 kg |
| Basic White Sour | Sea salt                      | 0.06 kg |
| Basic White Sour | Water                         | 1.10 kg |
| Basic White Sour | 80% starter                   | 1.80 kg |
| Seedy Malt Dough | 5 Seed Soaker                 | 4.00 kg |
| Seedy Malt Dough | Water                         | 3.80 kg |
| Seedy Malt Dough | Sea salt                      | 0.22 kg |
| Seedy Malt Dough | 80% starter                   | 3.60 kg |
| Seedy Malt Dough | Organic light malthouse flour | 8.00 kg |
| 5 Seed Soaker    | Water                         | 1.20 kg |
| 5 Seed Soaker    | 5 seed mix                    | 1.00 kg |
| Mother           | Water                         | 3.20 kg |
| Mother           | Organic white flour           | 4.00 kg |

Suppose we have an order for 8 Small White loaves. We need to know how much starter to mix tonight. We know that we need 0.63 kg of dough for each loaf, so that's a total of 5.04 kg of Basic White Sour. The formula for Basic White Sour makes a total of $1.10 + 1.80 + 0.06 + 2.00 = 4.96 \mathrm{kg}$ of dough. So we need to multiply each quantity in that formula by the weight of dough we need divided by the total weight of the recipe $(5.04/4.96 = 1.016)$. This is straightforward enough for flour, water and salt, which are basic ingredients, but we'll need to do a similar calculation to work out how much flour and water we'll need to make $1.016 Ã— 1.8 = 1.829 \mathrm{kg}$ of starter. You can see how this might become a little tedious.

If I were going to be doing these calculations by hand, it would definitely pay me to normalize my intermediate formulae so they all made a total of 1 kg of stuff. But screw that, we have a computer, so we can make it do the work.

I'm going to simplify things a little (the real database understands about dates, and we need to know a little more about recipes, products and ingredients than will fit in the ~recipe_item~ table that describes the graph) but this should give you an idea of the recursive queries that drive production planning.

Let's introduce a ~production_order~ table, where we stash our orders

#+begin_marginnote
The real table has extra information about customers and order dates:
#+end_marginnote

| product          | quantity |
|------------------+----------|
| Small White Wild |        5 |
| Small Seedy Malt |        5 |

And that's all we need to fire off a recursive query.
#+begin_marginnote
I'm writing this using the literate programming capabilities of org-mode, so the code you see is being run against my production database, and the results are using my working formulae. Which is why we're not querying the real ~production_order~ table.
#+end_marginnote

#+name: 6A645983-A0FF-42B1-A9D8-A0756FCD1A45
#+begin_src sql
WITH RECURSIVE po(product, quantity) AS (
    SELECT 'Small White Wild', 5
  UNION
    SELECT 'Large White Wild', 5
), rw(recipe, weight) AS (
    SELECT recipe, sum(amount)
      FROM bakehouse.recipe_item
  GROUP BY recipe
), job(product, ingredient, quantity) AS (
    SELECT po.product,
           ri.ingredient,
           po.quantity * ri.amount
      FROM po
      JOIN bakehouse.recipe_item ri ON po.product = ri.recipe
      JOIN rw ON ri.recipe = rw.recipe
  UNION
    SELECT job.ingredient, ri.ingredient, job.quantity * ri.amount / rw.weight
      FROM job
      join bakehouse.recipe_item ri on job.ingredient = ri.recipe
      join rw on job.ingredient = rw.recipe
)
SELECT product formula, ingredient, ROUND(sum(quantity),2) quantity from job group by job.product, job.ingredient order by formula;
#+end_src

Which gives the following result:

#+results:
| formula          | ingredient          | quantity |
|------------------+---------------------+----------|
| Basic White Sour | Sea salt            |     0.09 |
| Basic White Sour | Water               |     1.72 |
| Basic White Sour | Mother              |     2.81 |
| Basic White Sour | Organic white flour |     3.13 |
| Large White Wild | Basic White Sour    |     4.65 |
| Mother           | Organic white flour |     1.56 |
| Mother           | Water               |     1.25 |
| Small White Wild | Basic White Sour    |     3.10 |

A quick sanity check seems to show this is correct (we're making 7.75kg of Basic White Sour, which tallies with the weights needed to make the loaves).
So what's going on in the query? In SQL, ~WITH~ is a way of giving names to your intermediate results, akin to ~let~ in a Lisp. We fake up a table to hold our production orders (~po~) and the ~rw~ clause is totals the weights of all our recipes (in the real database, it's a view). The magic really starts to happen when you use the ~WITH RECURSIVE~ form. With ~RECURSIVE~ in play, the last query is treated differently. Instead of being a simple two part ~UNION~ what happens is that we first run:

#+name: 729E572D-94B2-4170-8561-FA051EE59B22
#+begin_src sql
SELECT po.product, ri.ingredient, po.quantity * ri.amount
  FROM po
  JOIN bakehouse.recipe_item ri on po.product = ri.recipe
  JOIN rw on ri.recipe = rw.recipe
#+end_src

and call the results ~job~ and then run the second query, adding any extra rows generated to the results, and repeating that query until the result set stops growing. If we didn't have ~WITH RECURSIVE~ available, and we knew the maximum depth of recursion we would need, we could fake it by making a bunch of intermediate clauses in our ~WITH~. In fact, until I worked out how ~WITH RECURSIVE~ works, that's exactly what I did.

Have you spotted the mistake? I didn't, until a few bakes when horribly wrong.

Here's what happens when we have an order for 3 small loaves and two large ones

| formula          | ingredient          | quantity |
|------------------+---------------------+----------|
| Basic White Sour | Sea salt            |     0.02 |
| Basic White Sour | Water               |     0.41 |
| Basic White Sour | Mother              |     0.68 |
| Basic White Sour | Organic white flour |     0.75 |
| Large White Wild | Basic White Sour    |     1.86 |
| Mother           | Organic white flour |     0.38 |
| Mother           | Water               |     0.30 |
| Small White Wild | Basic White Sour    |     1.86 |

We're only making 1.86 kg of dough? What's going on?

It turns out that the way a ~UNION~ works is akin to doing ~SELECT DISTINCT~ on the combined table, so it selects only unique rows. When two orders end up requiring exactly the same amount of the 'same' dough, they get smashed together and we lose half the weight. This is not ideal.
#+begin_marginnote
It's /especially/ not ideal when you don't spot there's a problem and end up making far fewer loaves than you expect. Or on one /really/ annoying occasion, making a dough that was far too dry because we lost some water along the way. You can correct this during the mix, but it was a nasty shock.
#+end_marginnote
I fixed it by adding a 'path' to the query, keeping track of how we arrived at a particular formula. Something like:

#+name: 48148626-CBC5-4AF1-9E88-7821F8099F36
#+begin_src sql
WITH RECURSIVE po(product, quantity) AS (
    SELECT 'Small White Wild', 3
  UNION
    SELECT 'Large White Wild', 2
), rw(recipe, weight) AS (
    SELECT recipe, sum(amount)
      FROM bakehouse.recipe_item
  GROUP BY recipe
), job(path, product, ingredient, quantity) AS (
    SELECT po.product,
           po.product,
           ri.ingredient,
           po.quantity * ri.amount
      FROM po
      JOIN bakehouse.recipe_item ri ON po.product = ri.recipe
      JOIN rw ON ri.recipe = rw.recipe
  UNION
    SELECT job.path || '.' || job.ingredient,
           job.ingredient,
           ri.ingredient,
           job.quantity * ri.amount / rw.weight
      FROM job
      join bakehouse.recipe_item ri on job.ingredient = ri.recipe
      join rw on job.ingredient = rw.recipe
)
SELECT product formula, ingredient, round(sum(quantity),2) weight from job group by formula, ingredient order by formula;
#+end_src

This query gives us:

#+results:
| formula          | ingredient          | weight |
|------------------+---------------------+--------|
| Basic White Sour | Sea salt            |   0.05 |
| Basic White Sour | Water               |   0.83 |
| Basic White Sour | Mother              |   1.35 |
| Basic White Sour | Organic white flour |   1.50 |
| Large White Wild | Basic White Sour    |   1.86 |
| Mother           | Organic white flour |   0.75 |
| Mother           | Water               |   0.60 |
| Small White Wild | Basic White Sour    |   1.86 |

This time we're making 3.74 kg of dough, which is right.

In order to see what's going on, we can change the final ~SELECT~ to ~SELECT formula, path, ingredient, round(quantity,2) weight FROM job~, and now we get:

| formula          | path                                     | ingredient          | weight |
|------------------+------------------------------------------+---------------------+--------|
| Large White Wild | Large White Wild                         | Basic White Sour    |   1.86 |
| Basic White Sour | Large White Wild.Basic White Sour        | Mother              |   0.68 |
| Basic White Sour | Large White Wild.Basic White Sour        | Organic white flour |   0.75 |
| Basic White Sour | Large White Wild.Basic White Sour        | Water               |   0.41 |
| Basic White Sour | Large White Wild.Basic White Sour        | Sea salt            |   0.02 |
| Mother           | Large White Wild.Basic White Sour.Mother | Water               |   0.30 |
| Mother           | Large White Wild.Basic White Sour.Mother | Organic white flour |   0.38 |
| Small White Wild | Small White Wild                         | Basic White Sour    |   1.86 |
| Basic White Sour | Small White Wild.Basic White Sour        | Organic white flour |   0.75 |
| Basic White Sour | Small White Wild.Basic White Sour        | Sea salt            |   0.02 |
| Basic White Sour | Small White Wild.Basic White Sour        | Water               |   0.41 |
| Basic White Sour | Small White Wild.Basic White Sour        | Mother              |   0.68 |
| Mother           | Small White Wild.Basic White Sour.Mother | Organic white flour |   0.38 |
| Mother           | Small White Wild.Basic White Sour.Mother | Water               |   0.30 |

Which shows that we're considering two lots of Basic White Sour with exactly the same weights, but we (and more importantly, the database engine) know that they're distinct amounts because we get to them through different routes. Hurrah! The problem is solved and we can accurately work out what we should be mixing.

*** What's still missing
:PROPERTIES:
:ID:       868FF41D-EB97-4079-8710-EBBE6B50AB15
:END:

As a baker, I know  if I've got an order for bread on Friday, then I need to mix the starters on Wednesday night, then spend Tuesday mixing, fermenting and shaping the loaves, which will spend the night in the retarder ready to be baked at 4 on Friday morning. But the schema I've outlined here doesn't. In my full bakehouse schema, I have a few extra tables which hold timing data and such. In particular, I have a ~product~ table, which knows about everything I sell. This table knows holds info about how many I can make per hour of work and the bake time and temperature. Then there's a ~recipe~ table which holds information about how long a formula needs to rest.
#+begin_marginnote
This could be the bulk fermentation time if it's a formula for a dough or a starter, a proof time if it's a loaf, or a soaking time for a soaker (a soaker is usually a mixture of seeds or fruit and a liquid, usually water, but occasionally fruit juice or booze depending on the final product).
#+end_marginnote
The real queries take this into account to allow us to work back from the ~due_date~ of a real order to the day we need to do the work. If you want to dig into how I handle dates  you can check out the repository at [[https://github.com/pdcawley/bakehouse/]].


*** The perils of writing stuff up

Never write your work up for your blog. Especially if you're mostly happy with it. As I was writing this, I realised there's an annoying bit of code duplication that I think I can eliminate. In the current code, I repeat what's essentially the same query structure in a couple of different views, but the formula graph is essentially static unless I add or adjust a recipe. Now I'm wondering if I could make a materialised view that has enough information to shortcut the calculations for both making the production list (what needs to be mixed, when) and for working out my costings (to put a price on a loaf, you need to know how much the raw ingredients cost, and that involves walking the tree again. Maybe a table like:

| product          | sub_formula      | ingredient  | factor | lead_time |
|------------------+------------------+-------------+--------+-----------|
| Large White Wild | Basic White Sour | White Flour |  0.403 | 1 day     |
| Large White Wild | Basic White Sour | Salt        |  0.012 | 1 day     |
| Large White Wild | Basic White Sour | Water       |  0.222 | 1 day     |
| Large White Wild | Basic White Sour | 80% Starter |  0.462 | 1 day     |
| Large White Wild | 80% Starter      | White Flour |  0.288 | 2 days    |
| Large White Wild | 80% Starter      | Water       |  0.173 | 2 days    |

If we have that table, then two days before our bread is due, if we have an order for 10 white loaves, we'll need to mix \(9.3 Ã— .288 \approxeq 2.68\) kg of flour and $9.3 Ã— 0.173 \approxeq 1.61$ kg of water. Which we can do with a simple non-recursive ~SELECT~. Something like:
#+begin_marginnote
NB: I've not tested this because I don't have the precalculated table, but it seems like it should work. In fact, thinking about it, we could probably build the ~precalc~ table so that we can simply do ~precalc.factor * po.quantity~, since any change that affects recipe weight will also affect our precalculated table.
#+end_marginnote
@@

#+name: A9B65C0A-2496-4A3B-B0FB-8AEBE9B5BE6A
#+begin_src sql
WITH weighted(formula, ingredient, weight, due) AS (
    SELECT precalc.sub_formula,
           precalc.ingredient,
           precalc.factor * po.quantity * rw.weight,
           po.due_date - precalc.lead_time
      FROM precalc
      JOIN production_order po ON precalc.product = po.product
      JOIN recipe_weight rw ON precalc.product = rw.recipe
)
  SELECT formula, ingredient, sum(weight)
    FROM weighted
   WHERE due = 'today'
GROUP BY formula, ingredient
#+end_src

We can use the same table to calculate the raw material costs for a given recipe, using a simple non-recursive query too.

I think, however, I'm going to leave it alone until I have to write another recursive view that walks the same graph, at which point I'll bite the bullet and do the pre-calculated version.




* Book Reports                                            :@book-report:
:PROPERTIES:
:export_hugo_custom_front_matter: :series "Book Reports"
:export_hugo_section: /book
:ID:       AE556F3E-BD2C-46E6-BE13-AD819A39EE6D
:END:

** DONE A Wizard of Earthsea
:PROPERTIES:
:EXPORT_FILE_NAME: a-wizard-of-earthsea
:export_hugo_slug: a-wizard-of-earthsea
:export_date: 2019-05-30
:export_hugo_aliases: /2019/05/30/a-wizard-of-earthsea/
:ID:       DB913EAC-FB57-44B7-9645-DBD26957CE72
:END:
This was the first.

Before I read Tolkien at the suggestion of the wonderful Miss Reese, my teacher for my last year of primary school; before I pulled Diana Wynne Jones, Alan Garner, Susan Cooper and others from the shelves of Bawtry's small, but enchanting branch library; before Anne McCaffrey's DragonSong found me in my school library and set a fire in my imagination. Before all that, I read /A Wizard of Earthsea/ and it stuck with me.

#+hugo: more

I remember one Saturday with 50p in my pocket from singing for a couple of weddings at St George's church in Doncaster (25p for each wedding, paid cash in hand on the day. It always felt like a bonus after singing Bach's /Jesu Joy of Man's Desiring/ in the side chapel as the register was signed in the vestry and Magnus Black, the choir and organmaster, brought that beautiful tune dancing with such delicacy from in instrument that would shake the walls later as the happy couple left the church to Vidor's toccata and fugue).
#+begin_marginnote
That was if we were lucky. It was usually Mendelssohn â€“ not bad, Magnus was far too good an organist for it to sound dull, but not a patch on Vidor.
#+end_marginnote
I was never one for saving, I'm still not, so I was straight round to Donny's nearest thing to a bookshop, the WH Smith in the Arndale in search of something to read. A voracious reader, I'd gone through all the /Swallows and Amazons/ and /Narnia/ books and I needed more. The cover of the second Puffin edition, with its white youth and bizzare half man half hawk fascinated me, so I handed over my 50p
#+begin_marginnote
The bibliography I found tells me that it probably cost 35p, so I no doubt bought a load of sweets as well â€“ books and sugar have always been my vices.
#+end_marginnote
and headed home with my prize.

I read /A Wizard of Earthsea/ once or twice and loved it, but I've not reread it since. As a kid, I borrowed rest of the then trilogy from the library and found them rather hard going at  (my memory says that I found /The Tombs of Atuan/ a real slog. I got through it, but it took a couple of goes and at least one renewal to get to the end). A few weeks ago though, I went to the [[https://www.soundpost.org.uk/][Sound Post]] 'Modern Fairies' singing weekend and fell into conversation with [[https://terriwindling.com][Terri Windling]] about the books that had shaped me and I told her about my experience with the Earthsea trilogy and I thought maybe I'd been a little too young for them (I think I was eight or nine when I read AWoE, and maybe twelve when I read /The Tombs of Atuan/ and /The Furthest Shore/). I hadn't revisted them since. Terri made me promise to reread them and to let her know what I thought. So that's what I'm doing. Terri, this book report's for you. I owe you a few more and I promise I'll get to them.

By the way, if you've never read /A Wizard of Earthsea,/ there will be spoilers in this article. Read the book before continuing. It shouldn't take you long, and it's well worth the time.

It's not so much what happens in this story as the way it's told that left its impression on me. Earthsea is made of words â€“ all stories are, of course â€“ sung into being by Segoy. Words are power. A wizard spends a large part of his
#+begin_marginnote
The wizards are all men. There are female witches in the story, but at this stage of the tale they're definitely underpowered and untrustworthy compared to the men. Le Guin fixes this later.
#+end_marginnote
education learning the "the Deeds of heroes and the Lays of wisdom" and year under the Master Namer just learning the true names of things in the Old Speech: the language of dragons; the language in which the world was made. In the period when the book is set, there is written language, but I get the feeling that it's very much the preserve of the wise. Songs, orally transmitted, are how the people of the archipelago hold their history and Le Guin's language reflects that. Every sentence seems to have been shaped to be spoken, and beautifully so. I kept stopping and reading passages out because the words were just so... right.

I sometimes wonder who the tale's narrator is telling the story to. It's a question that can break a lot of first person SF and exposes lazy storytelling. If a book that's supposedly the product of a completely different culture or time feels like it's written for an early 21st century reader, it breaks the book for me.
#+begin_marginnote
Sometimes I don't care though. God alone knows why Bertie Wooster is telling the Jeeves stories, or who he's telling them too â€“ I'm just very glad he's chosen to tell them at all.
#+end_marginnote
The language and idiom of /A Wizard of Earthsea/ seem entirely right and consistent. We learn so much about the world as Ged's story is told from things mentioned in passing. We know that this happened a long time ago and it's assumed we already know about /The Deed of Ged/, /The Creation of Ea/ and all the other songs, deeds and festivals that are referred to in passing through the book. At the end we are told that no songs have survived that tell how Ged came to terms with his shadow â€“ the entire book is a footnote in a much larger story that's just out of reach. I'm reminded of the fact that we only have the Norse myths we know because an ancient Icelander worried that readers wouldn't recognize the allusions in the sagas and eddas, so they wrote down the bones of the older stories to help future readers understand. If Le Guin had left Earthsea at this point, all we would know of Earthsea would be the glimpses of it in this story. And what glimpses they are.

You can find echoes /A Wizard of Earthsea/ in so much subsequent fantasy literature. The possibility of a wizard being trapped in another, for instance. Pratchett plays with and develops this in the /Witches/ sequence of Discworld books, for instance. I loved this sentence though: "And no one knows how many of the dolphins that leap in the waters of the Inmost Sea were men once, wise men, who forgot their wisdom and their name in the joy of the restless sea." If I had the power to become a dolphin I wouldn't be keen to return to the body of a fat 51 year old with diabetes and a bunch of aches and pains that I try not to think about. You can keep your wisdom sometimes.

As a kid, I didn't really understand what was going on with Ged and his Shadow. It was easy to see myself in the ever noticed that he didn't have the same colour skin as me). I loved learning and especially /knowing/. It wasn't hard to take my undoubtedly superior intelligence
#+begin_marginnote
Yeah. I know. I must have been insufferable as a kid (and an adult, if I'm honest). First to stick their hand up in every class. Happy to "Well, actually..." at every opportunity.
#+end_marginnote
as analogous to a wizard's power. Then, though, the shape of the story confused me, especially the ending. Ged and his friend sail off the page. The sea becomes land. Ged steps off the boat and confronts the Shadow, addressing it with his own name. And the shadow disappears/merges with Ged. And they all live on to do the Deeds which are sung of them. What? Nine year old me had no /idea/ what was going on there, but the imagery stuck.

Now, of course, it all seems a clearer. Thesis. Antithesis. Synthesis. Ged does a terrible thing in his ignorance  and pride. In shame he runs from it, almost losing his humanity in the process. He is tempted by a dark power, but rejects it. A friend and teacher restores him to himself and tells him that running is the sure road to doom. He turns and chases his Shadow instead. Finally he comes to an acceptance that the Shadow is a part of himself and by giving it his name he reintegrates that part into himself and finally becomes a whole man. There you go â€“ no need to read the book now.

Of course you need to read this book. It's language sings and the places and people it evokes are beautifully drawn. Rereading this after more than 30 years, so much was familiar. I would have said I'd forgotten almost all of it but the bare outline of the story and a few character names, but that stuff clearly went in deep and helped make me myself because as I read, the whole shape of the thing unfolded in my head. It was almost like recognising roads and pathways in a place you holidayed repeatedly as a kid, then didn't return for 20 years. Familiar and surprising at the same time. "Oh yeah, that's where Daniel used to live! And do you remember walking up there to buy ice creams at the village shop? Oh! I'd forgotten this view!"

Right... onwards to /The Tombs of Atuan./
** DONE /Service Model/, by Adrian Tchaikovsky :sf:audiobook:
CLOSED: [2025-08-21 Thu 21:08]
:PROPERTIES:
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :work '((author . "Adrian Tchaikovsky") (title . "Service Model") (type . "book"))
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :cover '((s . "https://covers.openlibrary.org/b/olid/OL59424202M-S.jpg") (m . "https://covers.openlibrary.org/b/olid/OL59424202M-M.jpg") (l . "https://covers.openlibrary.org/b/olid/OL59424202M-L.jpg") (caption .  "<cite>Service Model</cite> by Adrian Tchaikovsky"))
:EXPORT_HUGO_BUNDLE: adrian-tchaikovski-service-model
:EXPORT_FILE_NAME: index
:END:

#+begin_description
A robot valet kills its master for no apparent reason, then heads off on a /Pilgrim's Progress/ to understand his malfunction.
#+end_description

I'm very late to Tchaikovsky's work and picked this up mostly because of an Audible recommendation. A very good recommendation it was too.

Charles is a robotic valet, and one morning, completely out of the blue, he slits his master's throat in lieu of shaving him and (eventually) sets off on a pilgrimage to find out why. The world Charles exists in isâ€¦ broken and his journey to enlightenment is longer and stranger than he ever expected.

Charles is very definitely /not/ human and his motivations are not exactly what you and I might think of as motivations. He has a task list. He is programmed to work through it. That is all.

He doesn't want anything. He can't feel anything. Not fear, hope, surprise, disappointment. And he's okay with that. Well, he would be if "being okay with something" were something he could do.

Because of Charles' inhuman viewpoint, part of the pleasure of the book is working out what's going on that Charles is incapable of understanding.

It's been a long time since I read /Pilgrim's Progress/, but it's definitely the work that /Service Model/ reminds me of. Charles, despite murdering his master, is an innocent abroad, travelling through a series of encounters that he doesn't necessarily understand in an effort to clear his task list.

It's also bloody funny in a dry, despairing kind of way.

{{{newthought(I listened to the audiobook,)}}} read by the author, which I can recommend highly. Tchaikovsky's a great narrator with just the right level of emotional detachment, but the jokes still land beautifully. A very smooth listen.
** TODO Rivers of London, by Ben Aaronovitch :sf:fantasy:
:PROPERTIES:
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :work '((type . book) (title . "Rivers of London") (author . "Ben Aaronovitch"))
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :cover '((s . "https://covers.openlibrary.org/b/olid/OL26814272M-S.jpg") (m . "https://covers.openlibrary.org/b/olid/OL26814272M-M.jpg") (l . "https://covers.openlibrary.org/b/olid/OL26814272M-L.jpg"))
:EXPORT_HUGO_BUNDLE: ben-aaronovitch-rivers-of-london
:EXPORT_FILE_NAME: index
:END:

One of these  fine days I'll actually write a book report on this one! As it is, I'm mostly fiddling with it to check that I'm styling things right. And making this paragraph longer and longer and longer and filling it up with gibberish until the summary as a whole is taller than the thumbnail wants to go.

But, for now, you'll have to make do with placeholder text.

* Posts

** DONE My Virtual Gig-Like Thing
:PROPERTIES:
:export_hugo_slug: virtual-gig-like-thing
:export_date: 2020-04-08T00:00:00
:EXPORT_FILE_NAME: virtual-gig-like-thing
:ID:       C2642DFD-B4E8-44DB-B576-BED6A8C96223
:END:

On Thursday the 9th of April at 7pm UK time, I'm streaming my first attempt
at a  full folk club style gig from my study to my
Twitch stream and I would  love for you to be there.

#+hugo: more

*** Schedule
:PROPERTIES:
:ID:       6769254B-F1F3-46DF-814F-63D96F985D7C
:END:

It all kicks off at 7pm, UK time with a kind of Q&A session and
introduction to Twitch for newcomers. I'm particurly planning to help
other independent musicians reach their audience through the platform.
#+begin_marginnote
Recent deals with [[https://soundcloud.com][SoundCloud]] have made it /much/ easier for experienced
performers to access the means to get paid on Twitch, and it seems to be
the most transparent platform for getting paid.
#+end_marginnote
@@


Then, I plan to follow the Royal Traditions/Singing Together format of two
forty minute sets of folk material with a 10 minute refreshment and raffle
break in the middle.

After the folk club concert I'll be jumping onto [[https://twitch.tv/sings/download/][Twitch Sings]] to round out
the evening singing implausible songs with friends from that community and
any folky friends who've managed to get themselves up on Twitch by then. I'm
hoping it'll be a lot of fun.


*** Ticket Prices
:PROPERTIES:
:ID:       0E43DD7E-5512-435C-B7C4-73910B049C75
:END:
It's the internet! It won't cost you a penny to watch me perform. However,
right now, daft stuff like this is my only potential source of income, so
I would be deeply grateful if you could either [[https://ko-fi.com/pdcawley]["Buy me a coffee"]] via Ko-Fi
or [[https://twitch.tv/signup][sign up]] for a free Twitch account and subscribe to my channel.

*** Free money for your favourites!
:PROPERTIES:
:ID:       AFDB4ED1-8FAB-461B-816A-CD0BF60D7CC2
:END:
If you are an Amazon Prime subscriber and you don't yet have a Twitch
Subscription, there's a wonderful thing you can do that means that Amazon
will give me (or any other streamer you enjoy) some money and it won't
cost you a penny. [[https://twitch.amazon.com/prime][Sign up]] for Twitch Prime, which is just like a regular
twitch account, but you can subscribe to one channel for free each month.
The streamer gets paid by Twitch as if you'd signed up for a regular
subscription, but you don't get charged a penny because you're already
paying Amazon for your Prime account. The only difference between a Prime
subscription and a regular one on Twitch is that you can't set up a Prime
sub to renew. If you would like to keep making regular payments to the
streamer of your choice, you need to remember to resubscribe every month.

*** One off tips
:PROPERTIES:
:ID:       95E39426-BE56-4078-9BF5-E7B2BE229683
:END:
A Ko-Fi coffee comes in at Â£3, but if you want to tip me or any other
twitch performer with an arbitrary amount, then Twitch Bits are your
friend. You buy 'em from [[https://bits.twitch.tv/][Twitch]] and can then use them as a virtual
currency. For the performer, 100 bits is equivalent to $1, but they will
cost you more than that to buy, because Twitch are (understandably, it's
not a cheap platform to run!) going to have to take a cut somewhere. By
loading it on the cost of bits to the giver, they make things really
transparent. It's not like the weird alchemy where you pay a music
streaming site 69p for a track or whatever and, unbeknownst to you unless
you really dig into it, the artist sees maybe 6p of that.

Other performers have other ways for you to support them, whether it be
public amazon wishlist, paypal tip jar, patreon page or some other service
I've not heard of yet. In some ways, it's never been easier for you to
support the work of artists you love.


** DONE Asshole Free Devil's Advocacy :philosophy:blether:
:PROPERTIES:
:export_file_name: devils-advocacy-without-asshattery
:export_hugo_slug: devils-advocacy-without-tears
:export_date: 2018-10-25
:ID:       B96DE889-2A35-4276-B716-EB558186DB55
:END:


So, you want to play Devil's Advocate, but you're afraid you might come across as a bit (or a lot) of an asshole? Here's some suggestions for how to avoid that.

#+hugo: more

*** Maybe don't?
:PROPERTIES:
:ID:       DFD8CB3D-98AB-414B-8766-B64DBC5E1D04
:END:

Seriously, why does the Devil need an advocate? If you want to play DA because you think the position you want to argue has some merit, then argue the position honestly and own it. If it doesn't survive the discussion (or is shouted down), then "Ah right, I hadn't thought of that, you're right" or words to that effect and file that position in your memory as a bad one (along with the skeleton of /why/ it's bad). Nothing wrong with holding strong opinions, the thing that's bad is holding onto them if they're shown to be bad. If the group you're talking with just shouts you down and doesn't convince you that your position is a bad one, maybe find a different group? Or agree with them to steer clear of that topic.

What's really intellectually dishonest is to say "I was only playing Devil's Advocate!" after an idea has been shot down. I'm sure your intentions are entirely honorable, but what if they weren't? Say you genuinely held that the best thing to do with the children of the poor was to turn them into cheap and delicious meals for the richest in society. Say you advanced this position to your friends and were utterly appalled by the idea. Then maybe you'd try to distance yourself from it by saying "Whoah! Guys!
#+begin_marginnote
I know. But the kind of people who make this move in an argument are usually the kind of people who'd address a mixed group of folk as "guys".
#+end_marginnote
I was only playing Devil's Advocate!"

When I hear someone playing that card, how am I supposed to distinguish between the well-meaning "There is this argument I've come across that I'm not sure I agree with, but it maybe has some merit and I don't know how I'd argue convincingly against it" types and the assholes who were flying a kite? Maybe the non-assholes will have friends who'll tell me that "They might seem like a bit of an arse, but they're not really." I've been that guy, and I don't want to be him again. Why is it okay for me to load the work of explaining that I'm not dickhead onto my friends rather than just not acting like a dickhead in the first place? Eventually, friends get tired. Eventually they'll shift to "Yeah, I know he seems like an ass, and he kind of is, but..." and then one day, they won't be your friends any more.

{{{newthought(Before you introduce the idea)}}} you want to play Devil's Advocate for, say something like "D'you mind if I play Devil's Advocate for a moment?" And when the group tells you "Yes, we do mind. Why help the devil?" listen to them. If it's genuinely that you've heard some argument that on the face of it seems repugnant, but you can't find a hole in it, then say as much: "What's wrong with this idea? Clearly feeding poor babies to the 1% is utterly repellant, but I can't find an effective counterargument."

Don't keep doing it, mind, or you'll start looking like the kite flying asshole again.

** DONE Adding a generic oembed handler for Hugo :hugo:
:PROPERTIES:
:export_hugo_slug: oembed-for-hugo
:export_file_name: oembed-for-hugo
:export_date: 2020-05-12
:ID:       950F43FF-3632-48D9-B768-02CC5154A220
:END:
If you're at all like me, you have content on a bunch of different sites (Instagram, Youtube, Flickr, Soundcloud, Bandcamp...) and, especially for multimedia content, it's great to be able to link to 'live' versions of that content. Of course, all those sites will let you 'share' content and usually have an 'embed' option that hands you a bunch of HTML that you can paste into your blog entry. But screw that! I'm a programmer for whom laziness is one of the cardinal virtues -- if it's at all possible, I prefer to let the computer do the work for me.
#+begin_marginnote
If nothing else, once I've got the programming right, it's less likely to screw up than me
#+end_marginnote

Hugo[fn:1] sort of supports this out of the box with its ~youtube~, ~instagram~, ~vimeo~ etc. built in shortcodes. The thing is, they're not lazy enough -- you have to dig into each URL to extract a content ID and pass that in to ~{{%/* youtube kb-Aq6S4QZQ */%}}~ or whatever. Which would be kind of fine, if you weren't used to the way sites like Facebook, Twitter, Tumblr and so on work. With those sites, you enter a URL and they disappear off behind the scenes and fill in a fancy preview of the page you linked to. Why can't Hugo do that?

#+hugo: more

Well, it can. It just takes a little work.[fn:2] The ~question~ to ask is how do all those user friendly sites do there thing? Twitter and Facebook, being the walled garden behemoths that they are do it by dictating two different microformats
#+begin_marginnote
Of bloody course!
#+end_marginnote
that live in a page's ~HEAD~ section. The microformat approach has a good deal to be said for it: In theory, you can just make a ~HEAD~ request to the URL you're interested in, parse out the microformat of your choice and build your own media card. I've not worked out how to do this yet though. However, before Twitter and FB started throwing their weight around, there was an open standard that lots of sites support, it's /really/ easy to use. It's called [[https://oembed.com/][oembed]] and it's great. The idea is that it too is discoverable via a ~HEAD~ request to your media page. You look for something matching src_html{<link rel="alternate" type="application/json+oembed" href="..." ...>}, make a JSON request to the ~href~ url and paste in the contents of the ~html~ key in the object you get back. The catch, of course, is that you still end up having to parse the document's HEAD.

The cool thing about ~oembed~, though, is that you /can/ discover its endpoints that way,
#+begin_marginnote
Though, I'm seeing fewer and fewer oembed links cropping up in sites that I /know/ support the protocol
#+end_marginnote
 but there's also a big list of known endpoints on the [[https://oembed.com/][Oembed homepage]], which is also available as a big old JSON object if you want to go the full programmatic route. There are JavaScript libraries available that will walk your webpage and the JSON object and replace all your links with chunks of embedded content, that that's what I used to use on this site. But... that's not how I currently roll at Just A Summary. There are currently no ~<script>~ tags to be found on here and I plan to keep it that way. So I wrote a Hugo shortcode. Here it is:

#+name: Initial embed shortcode
#+caption: Initial embed shortcode
#+begin_src go-html-template
{{ $url := (.Get 0) }}
{{- range $.Site.Data.embed }}
  {{- if le 1 ( findRE .pattern $url | len ) }}
    {{- with (getJSON .endpoint "?" (querify "format" "json" "url" $url)) }}
      {{ .html | safeHTML }}
    {{ end }}
  {{ end }}
{{ end }}
#+end_src

We use it like: ~{{</* embed "https://youtub.be/kb-Aq6S4QZQ" */>}}~, which displays like this:

@@hugo:{{< embed "https://youtu.be/kb-Aq6S4QZQ" />}}@@

{{{newthought("But how does it work?")}}} I hear you ask? It works in conjunction with some per-site data entries that I've added to the directory ~data/embed~ in this site's base directory. You might have guessed that the data entries are maps with two entries, a ~pattern~ and an ~endpoint~. If the URL argument matches the ~.pattern~, then we make a ~getJSON~ request to ~.endpoint~ with a sanitised version of the URL argument tacked on as our query string and inserting the JSON response's ~.html~ entry.
#+begin_marginnote
It's rather tricky to implement oembed for on a strictly static site, but I love the simplicity of it. I have a few thoughts about that though. Watch this space.
#+end_marginnote

I made the data files by taking the big JSON object from https://oembed.com/providers.json and massaging the supplied patterns into regular expressions. In theory, I could write a script to do the conversion for me, but I'm only really interested in four providers for this site, so I just did it by hand. So the entry for [[https://instagram.com/][Instagram]]:

#+caption: The https://oembed.com/providers.json entry for Instagram
#+name: 521EC4E0-5CE6-4667-9558-16262848DD6D
#+begin_src json
{
    "provider_name": "Instagram",
    "provider_url": "https:\/\/instagram.com",
    "endpoints": [
        {
            "schemes": [
                "http:\/\/instagram.com\/*\/p\/*,",
                "http:\/\/www.instagram.com\/*\/p\/*,",
                "https:\/\/instagram.com\/*\/p\/*,",
                "https:\/\/www.instagram.com\/*\/p\/*,",
                "http:\/\/instagram.com\/p\/*",
                "http:\/\/instagr.am\/p\/*",
                "http:\/\/www.instagram.com\/p\/*",
                "http:\/\/www.instagr.am\/p\/*",
                "https:\/\/instagram.com\/p\/*",
                "https:\/\/instagr.am\/p\/*",
                "https:\/\/www.instagram.com\/p\/*",
                "https:\/\/www.instagr.am\/p\/*",
                "http:\/\/instagram.com\/tv\/*",
                "http:\/\/instagr.am\/tv\/*",
                "http:\/\/www.instagram.com\/tv\/*",
                "http:\/\/www.instagr.am\/tv\/*",
                "https:\/\/instagram.com\/tv\/*",
                "https:\/\/instagr.am\/tv\/*",
                "https:\/\/www.instagram.com\/tv\/*",
                "https:\/\/www.instagr.am\/tv\/*"
            ],
            "url": "https:\/\/api.instagram.com\/oembed",
            "formats": [
                "json"
            ]
        }
    ]
}
#+end_src

becomes

#+name: instagram.yaml
#+caption: ~./data/embed/instagram.yaml~
#+begin_src yaml
endpoint: "https://api.instagram.com/oembed/"
pattern: "^https?://(www\\.)?instagr(\\.am|am\\.com)/((.*/)?p/|tv/)"
#+end_src

Collapsing all those ~scheme~ entries down to a single regular expression was a slight pain to do by hand, and I'm not /entirely/ sure the regular expression will match exactly what the schemes match, but it's not broken on any of the Instagram links I've thrown at it so far, so that's good enough for me.

{{{newthought(This isn't the shortcode's final form)}}} -- it's not as robust as I'd like it to be in the face of a missing or temporarily down oembed endpoint, so it would be good to have some kind of fallback in case an endpoint changes or goes away. Also, there are some sites that have their own methods for embedding previews, which don't support oembed
#+begin_marginnote
All those IndieWeb sites that use ~h-entry~ and ~h-card~ microformats to make the webpage machine parseable, for instance.
#+end_marginnote
and it would be great to get at those somehow. I suspect I will end up with a shortcode which is essentially a big case statement dispatching to different partials which will handle the real rendering. Again... watch this space


** DONE Â«tap tapÂ» is this thing on? :indieweb:
CLOSED: [2022-04-12 Tue 16:26]
:PROPERTIES:
:export_file_name: 20220412-is-this-thing-on
:export_hugo_slug: is-this-thing-still-on
:END:

#+begin_description
In which Piers attempts to explain why he's not been blogging in years, and makes vague noises about getting back to it again, in the hope that this time his [[https://indieweb.org/][IndieWeb]] inspired enthusiasm will last longer than a couple of weeks.
#+end_description

It's been a while hasn't it? I've been blogging on and (mostly) off since 2004 (at least according to the oldest article on here), and the [[https://indieweb.org/][IndieWeb]] movement reminds me of those heady days before Facebook, Twitter and the other monoliths scooped up all the bloggers.

It was probably Twitter that killed my regular blogging -- before Twitter, if I had something to say, I'd write a blog (or a LiveJournal for more personal stuff) post. Maybe a few days later, someone would reply, or write a blogpost of their own as a reaction and I'd get a pingback. These days, when I blog, my posts sit in splendid isolation, which wasn't really a thing back in Blogging's heyday. Spam killed my will to support comments and the growing complexity of blogging software was a real turn off. {{{marginnote(And I speak as someone who was the maintainer of [[https://typosphere.org/][Typo]] for a few years.)}}}

I burned out.

I ran this site on Typo, but most of the work I was doing on it was implementing features I didn't need which made the code slower and harder to understand, so I stepped back just as Twitter started its rise.

I've made a few abortive returns to blogging since, prompted by the rise of static site generation engines
#+begin_marginnote
I'm now using [[https://gohugo.io][Hugo]], [[https://orgmode.org/][org-mode]] and [[https://github.com][Github Actions]] to manage the site, and it's all hosted as a bunch of text files on a Raspberry Pi in one of [[https://mythic-beasts.com/][Mythic Beasts]]' racks somewhere.
#+end_marginnote
and the fact that I like having something to fiddle with. I could have just installed WordPress, but the idea of simply serving up a pile of static files (and no JavaScript!) seems way more sustainable (and secure) to me.
#+begin_marginnote
 Executing code that's exposed to the internet when I could just be serving textfiles is a recipe for pain and suffering.
#+end_marginnote

{{{newthought(Not running code on my server)}}} makes it a bit tricky to be fully engaged in IndieWeb ideal of a /connected/ web of websites using [[https://www.w3.org/TR/webmention/][WebMentions]] to make those interactions visible, but [[https://www.w3.org/TR/webmention/][it can be done]], and I too shall achieve it! One day. Baby steps, eh? I might resort to a Javascript based setup initially, but long term I want to keep the site completely script-free and fast.

*** Other writing

{{{newthought(I've written a few pieces)}}} now for [[https://jonwilks.online/][Jon Wilks]]' new and rather wonderful  [[https://tradfolk.co/][Tradfolk]] website. You can find those (and any future articles) at [[https://tradfolk.co/author/pierscawley/]] if you're interested in my suggestions on how to get started singing without accompaniment and building your repertoire.

I think that's what's got me returning to this site frankly. I'd forgotten how much I enjoyed writing long-ish form stuff rather than 280 character miniatures.

*** Coming up

{{{sc(newthought)}}}I suspect that,{{{sc(/newthought)}}} like every other IndieWeb blogger, I'll have a few upcoming articles detailing how I make things work here, {{{marginnote(Can there be anything more fascinating than tech navel gazing?)}}} but there's a few things in my drafts folder that I want to return to, and probably some discussion of my experiences streaming folk songs every Friday night for the best part of two years now.

Let's revisit this in a couple of months and see if it's still the most recent article on the site, eh?

** DONE We have WebMentions
CLOSED: [2022-04-16 Sat 14:53]
:PROPERTIES:
:export_file_name: we-have-webmentions
:END:

#+begin_description
Taking one more step on the road to full IndieWeb citizenship or whatever it's called, [[file:/][Just A Summary]] now displays webmentions.
#+end_description

After much fiddling with [[https://n8n.io/][N8N]], [[https://webmention.io/][webmention.io]], and the usual combination of [[https://gohugo.io][Hugo]]'s powerful, yet inscrutable templating language and my tenuous understanding of CSS, we're now /displaying/ our webmentions. We've been directing them to webmention.io for years now, but scratching my head over what to do with them.

The way it works at the moment is I run a task every few hours that checks webmention.io, merges the results with the stuff we already know about and commits the updated data files to Github, which triggers a github action that rebuilds the site. This isâ€¦ inefficient. My next step is to either expose the n8n workflow via a webhook, or work out how to retain some information from the previous run and use that to ensure we only fetch any mentions that've arrived since the last time we checked. But that's work for another day. Right now I'm calling what I have a win, merging this branch to main and basking in the warm glow of taking one more step down the IndieWeb road.

** DONE Keep it Simple, But Where's The Fun In That? :indieweb:webmentions:
CLOSED: [2022-04-24 Sun 16:30]
:PROPERTIES:
:export_file_name: 20220423-keep-it-simple-but-where-s-the-fun-in-that
:export_hugo_slug: not-so-simple
:END:

#+begin_description
The beauty of using a static site generator to build your website is supposed to be that it's all delightfully simple. Simple markdown formatted files go in at one end and a slim, fast and easy to serve website comes out the other end. All that remains is to upload those files to the appropriate directory on your server and all is well.

But never underestimate the ability of a long time Emacs user to complicate things.
#+end_description

The beauty of using a static site generator to build your website is supposed to be that it's all delightfully simple. Simple markdown formatted files go in at one end and a slim, fast and easy to serve website comes out the other end. All that remains is to upload those files to the appropriate directory on your server and all is well.

But never underestimate the ability of a long time Emacs user to complicate things. For instance, markdown is all well and good, but I've been doing most of my writing in [[https://orgmode.org/][Org Mode]][fn:3] so I really want to stay in Org mode to write these blog posts. [[https://gohugo.io/][Hugo]] understands =.org= files, so I could just lean on that, but the way Hugo treats org files seems slightly out of whack with what I think of as the Org way and I'd end up having to stick with the subset of org syntax that Hugo know. So I use [[https://ox-hugo.scripter.co][ox-hugo]], there's a bit of configuration needed to make it work the way I like, but I prefer to change software to accommodate me rather than change me to accommodate software
#+begin_marginnote
I'd go so far as to say it's a point of pride.
#+end_marginnote

I've had all that set up for a while. As I say, a tad fiddly at first, but once it's in place, it just works.

{{{newthought(Exceptâ€¦)}}} =ox-hugo= works by generating =.md= files from an org source, which are then used to generate the site, and I had things set up to autogenerate the html whenever I commited to the main branch of the blog repo, and the git server hook based system I was using only worked if those exported files were in repo.

That's the sort of thing that makes me itch, because there were two files for any given article:

- =all-posts.org= :: the org file in which I write all my articles
- =article.md= :: the generated file that hugo uses to build the site.

The generated file is an artefact of the build process and simply repeats the info in the org file, which should be our single source of truth. It's not a file that should be left around to be edited willy nilly because it could get out of sync with its source file. It's certainly not the sort of file that should live in the repository.

I didn't worry about this for /ages,/ but it niggled at me. Then one day I read an article about using [[https://github.com/features/actions][Github Actions]] to build an ox-hugo based site by installing emacs and ox-hugo on the VM that does the build step and generating the markdown files during the build by running Emacs


#+begin_marginnote
Yes, Emacs is an editor, but if you do ã€Œsrc_emacs-lisp[:exports code]{emacs allâ€‘posts.org â€‘â€‘batch â€‘l ox-hugo â€‘â€‘eval='(org-hugo-export-wim-to-md t)' â€‘â€‘kill} ã€ it will happily execute any lisp code you care to ask it to.
#+end_marginnote
in batch mode. The  markdown files never exist anywhere that anyone can edit them. So, of course I had to do that. Again, fiddly to set up, and arguably only of philosophical benefit, but worth it, I think.[fn:4]

{{{newthought(I could've left it there,)}}} but the thing I miss about the old, slow, hard to maintain version of this site, is the sense of connection. The old site had comments, and pingback links to other blogs. There was a sense of connectedness that's missing from a collection of articles. I want some of that back.

There is a way. In the time I've been mostly not blogging, some of the folks who kept at it have been cooking up a collection of tools, technologies and standards under the [[https://indieweb.org][IndieWeb]] banner. There's a whole suite of technologies involved, but the piece of the puzzle that I'm interested in right now is the [[https://indieweb.org/WebMention][WebMention]], described as

#+begin_quote
â€¦ an @ mention that works across websites; so that you don't feel immovable from Twitter or Fb
#+begin_cite
[[https://twitter.com/rngala][Roney Ngala]] ([[https://twitter.com/rngala][@rngala]]) on [[https://twitter.com/rngala/status/852354426983591937][Twitter]]
#+end_cite
#+end_quote

Now we're talking! It's a really simple standard too. When you mention, like, comment on, repost, reply to, bookmark or simply publicly interact with an "h-entry"[fn:5] on the IndieWeb, you can send a webmention by sending a small chunk of JSON to the webmention endpoint of the entry you mentioned. Assuming all the content is marked up correctly, /sending/ a webmention is delightfully easy. You can do it with ~curl~, if that's your thing, but I'm in an emacs buffer, so let's use [[https://github.com/pashky/restclient.el][~restclient~]]

We mention [[https://indieweb.org]] in this post, so let's find out its webmention endpoint.

#+begin_src restclient :exports both
HEAD https://indieweb.org
#+end_src

#+results:
#+BEGIN_SRC html
<!-- HEAD https://indieweb.org -->
<!-- HTTP/1.1 200 OK -->
<!-- Date: Thu, 21 Aug 2025 20:55:46 GMT -->
<!-- Content-Type: text/html; charset=UTF-8 -->
<!-- Connection: keep-alive -->
<!-- Server: cloudflare -->
<!-- Link: <https://webmention.io/indiewebcamp/webmention>; rel="webmention" -->
<!-- Cache-Control: no-cache -->
<!-- X-No-Cache: 1 -->
<!-- X-Cache: BYPASS -->
<!-- Cf-Cache-Status: DYNAMIC -->
<!-- Report-To: {"group":"cf-nel","max_age":604800,"endpoints":[{"url":"https://a.nel.cloudflare.com/report/v4?s=AcdDojTYPMSIrmWJHpOrSeRUOgkMOS5R%2BU8A%2FpEtRdGdGILIA0DwvJcCiFhtKp6Q1em%2BPnsMp7E8%2BhMzx4JN65Thuu2UeCM3AibOYQ%3D%3D"}]} -->
<!-- Nel: {"report_to":"cf-nel","success_fraction":0.0,"max_age":604800} -->
<!-- CF-RAY: 972d087bbb33bed7-LHR -->
<!-- alt-svc: h3=":443"; ma=86400 -->
<!-- Request duration: 1.125278s -->
#+END_SRC

We're looking for the ã€Œsrc_html{Link:Â â€¦Â ;Â rel="webmention"}ã€ line. This tells us that to send a webmention targeting https://indieweb.org, we need to post it to https://webmention.io/indiewebcamp/webmention. Which is almost as simple as finding the end point. Here we go:

#+begin_src restclient :exports both
POST https://webmention.io/indiewebcamp/webmention
Content-Type: application/x-www-form-urlencoded

source=https://bofh.org.uk/2022/04/24/not-so-simple&target=https://indieweb.org
#+end_src

#+results:
#+BEGIN_SRC json
{
  "status": "queued",
  "summary": "Webmention was queued for processing",
  "location": "https://webmention.io/indiewebcamp/webmention/oYamc823u4mVmGD3BmPu",
  "source": "https://bofh.org.uk/2022/04/24/not-so-simple",
  "target": "https://indieweb.org"
}
// POST https://webmention.io/indiewebcamp/webmention
// HTTP/1.1 201 Created
// Content-Type: application/json;charset=UTF-8
// Content-Length: 236
// Connection: keep-alive
// Status: 201 Created
// Cache-Control: no-store
// Access-Control-Allow-Origin: *
// Location: https://webmention.io/indiewebcamp/webmention/oYamc823u4mVmGD3BmPu
// X-Content-Type-Options: nosniff
// Date: Thu, 21 Aug 2025 20:56:00 GMT
// X-Powered-By: Phusion Passenger 5.3.1
// Server: nginx/1.14.0 + Phusion Passenger 5.3.1
// Request duration: 0.590250s
#+END_SRC

The job is done, and we get a nice JSON formatted summary of what's going on to boot.

Of course, if a webmention is so simple to send then it's probably a pain in the bum to receive and it isâ€¦ sort of. To receive a webmention request, you need to:

1. Run a web app to handle the request
2. Visit the source link
3. Parse out the microformats associated with the entry, its author and content
4. Figure out how to display the information

Steps 1--3 aren't particularly hard, but they're fiddly to get right and involve making web connections to potentially unsafe sites and I'm using Hugo to generate this site because I don't want to be running potentially insecure code that's exposed to the internet on a server that I own if I can possibly help it. Thankfully, I don't have to. I can take a leaf out of indiweb.org's book and just delegate that part to [[https://webmention.io][webmention.io]]. Webmention.io handles all that icky visiting of foreign websites and parsing out microformats for you and instead presents you with a feed consisting of all the webmention's that've been sent to your site in a variety of formats. I've been consuming their ~.jf2~ formatted feed for a while now. JF2 is a JSON representation of the microformats associated with the webmention's source. Let's grab something from that feed

#+begin_src restclient :exports both
GET https://webmention.io/api/mentions.jf2?per-page=2&page=0&sort-dir=up&target=https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/
#+end_src

#+results:
#+BEGIN_SRC json
{
  "type": "feed",
  "name": "Webmentions",
  "children": [
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "David Gallows",
        "photo": "https://avatars.webmention.io/pbs.twimg.com/e7b750d847ffdcfc174845aadc9196125b83647258a1789bb2b92b493d223e8b.jpg",
        "url": "https://twitter.com/DavidGallows"
      },
      "url": "https://twitter.com/pdcawley/status/1517783526049001472#favorited-by-877428607",
      "published": null,
      "wm-received": "2022-04-23T09:59:17Z",
      "wm-id": 1385464,
      "wm-source": "https://brid.gy/like/twitter/pdcawley/1517783526049001472/877428607",
      "wm-target": "https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/",
      "wm-protocol": "webmention",
      "like-of": "https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/",
      "wm-property": "like-of",
      "wm-private": false
    },
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "David Gallows",
        "photo": "https://avatars.webmention.io/pbs.twimg.com/e7b750d847ffdcfc174845aadc9196125b83647258a1789bb2b92b493d223e8b.jpg",
        "url": "https://twitter.com/DavidGallows"
      },
      "url": "https://twitter.com/DavidGallows/status/1517852498555555840",
      "published": "2022-04-23T13:06:50+00:00",
      "wm-received": "2022-04-23T15:12:04Z",
      "wm-id": 1385681,
      "wm-source": "https://brid.gy/comment/twitter/pdcawley/1517783526049001472/1517852498555555840",
      "wm-target": "https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/",
      "wm-protocol": "webmention",
      "content": {
        "html": "enjoyed reading about it :)\n\nI've been a trackball man since the word go, But have never been able to move away from Qwerty keyboards\n<a class=\"u-mention\" href=\"http://bofh.org.uk/\"></a>\n<a class=\"u-mention\" href=\"https://twitter.com/DrugCrazed\"></a>\n<a class=\"u-mention\" href=\"https://twitter.com/keyboardio\"></a>\n<a class=\"u-mention\" href=\"https://twitter.com/pdcawley\"></a>",
        "text": "enjoyed reading about it :)\n\nI've been a trackball man since the word go, But have never been able to move away from Qwerty keyboards"
      },
      "in-reply-to": "https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/",
      "wm-property": "in-reply-to",
      "wm-private": false
    }
  ]
}
// GET https://webmention.io/api/mentions.jf2?per-page=2&page=0&sort-dir=up&target=https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/
// HTTP/1.1 200 OK
// Content-Type: application/json;charset=UTF-8
// Content-Length: 2075
// Connection: keep-alive
// Status: 200 OK
// Cache-Control: no-store
// Access-Control-Allow-Origin: *
// X-Content-Type-Options: nosniff
// Date: Thu, 21 Aug 2025 20:56:16 GMT
// X-Powered-By: Phusion Passenger 5.3.1
// Server: nginx/1.14.0 + Phusion Passenger 5.3.1
// Request duration: 0.160096s
#+END_SRC

Lot's of lovely structured data. Webmention.io has worked out that one mention was a ~like-of~ [[file:/2013/03/10/in-which-piers-prepares-to-void-the-warranty/][the blog post]], and the other was ~in-reply-to~ it. We get details of the author of the mentioning post and, where appropriate, its content. If I wanted to run more Javascript on here (and I want to run less), I could attach a script which would consume the post's feed and build a display of all of the mentions. It has a certain appeal, just add one script to the site and a dummy ~<div>~ or ~<ul>~ somewhere and I'm laughing. Plenty of sites do just that.

This is not one of those sites.
#+begin_marginnote
Of course, this couldn't possibly because I tried to use the Javascript, couldn't make it work and decided to actually include webmentions in the generated files, that would be foolish!
#+end_marginnote
It's not even the first statically generated site to go down the route of statically generating a post's webmentions. I was mostly inspired by [[https://randomgeekery.org][Brian Wisti]]'s post about [[https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/][consuming the webmention.io API]] (except, of course, I don't use /any/ of his actual code.)

The site's [[https://github.com/pdcawley/bofh.org.uk/][Github repo]] is configured so any commit on the ~main~
#+begin_marginnote
It's 2022 already -- let's stop having 'master' branches, eh?
#+end_marginnote
branch fires off a workflow that builds the site and ships all the files over to the webserver using ~rsync.~ If I take Brian's idea for grabbing all my webmentions {{{marginnote(I set up the ~rel="webmention"~ link /ages/ ago and never quite got around to doing anything with the data)}}} and ignore his warning about splitting it out into Hugo data files and just do it, I can start building the webmentions for posts. Huzzah!

{{{newthought(It started so innocently,)}}} I have a server here that hosts a couple of Docker images and one of them is [[https://n8n.io/][N8N]], a super powered, self-hosted open source replacement for [[https://ifttt.com/][IFTTT]] with all sorts of hooks into other services and a much more powerful Github client than the IFTTT offering. It's a bitâ€¦ JavaScript-y for my tastes, but you can't have everything.

With a bit of fiddling, I had something that grabbed the webmention.io feed for the site every few hours, split it out into multiple files in ~data/mentions~ and updated GitHub. That's what I was celebrating in [[file:post/we-have-webmentions.pre-processed.org][We have WebMentions]]. I've moved on
#+begin_marginnote
A cynical person might well read that as "broken things"
#+end_marginnote
since then, because /of course/ sorting out de-duplication and remembering information between runs of the script is annoyingly fiddly and full of edge cases. Basically, I ended up trying to emulate a proper database. Which is why the latest iteration of webmention handling uses a proper database. I would have used [[https://sqlite.org/][SQLite]], but N8N doesn't have a SQLite node available out of the box. It does have a [[https://postgresql.org/][PostgreSQL]] one though, and recent versions of that have really good JSON support. I'd tell you more, but ~wc-mode~ tells me I'm nearly 2500 words in to this article, I think I'll wrap up for now and promise to give you the gory details in an upcoming article.

** DONE Evolving my streaming setup
CLOSED: [2022-05-10 Tue 17:10]
:PROPERTIES:
:export_file_name: 20220510-evolving-my-streaming-setup
:export_hugo_custom_front_matter: :syndicate true
:export_hugo_custom_front_matter+: :tweet "Will I ever learn to leave well enough alone? I've written up the state of my streaming setup here."
:export_hugo_custom_front_matter+: :syndicated_at '((twitter . "https://twitter.com/pdcawley/status/1524062540522790912"))
:END:

Back when I first started streaming on the internet, I used a Logitech webcam and some lights I had picked up for doing product photography and such for the Loafery and some audio gear I had because, well, recording stuff is just fascinating. It was okay, but even with decent lighting and audio, the webcam was frustrating to control (basically, there /was/ no control), so I picked up a cheap capture card from Amazon  and drafted my Nikon D810{{{marginnote(Absolutely not the camera I would recommend if you're going out to buy a camera for streaming -- it's primary virtue being that it's the camera I already owned. Get something mirrorless if you're heading down this road)}}} as my webcam and the appearance of my streams improved enormously. This worked fine with my slightly aging PC and /Twitch Sings/.
#+hugo: more
Then Twitch pulled the plug on /Sings/ and I started doing my regular Friday night folk streams. At first this involved running OBS and Logic Pro on my aging MacBook Pro and it was sort of okay, until I started having guests and doing Song Swaps -- the MacBook simply wasn't up to the job of running Logic, OBS and Zoom, so for a while I had some unholy lashup, with Zoom and OBS running on the PC, my Mac running Logic, with patch leads between the Mac and PC audio interfaces so I could hear my guests and vice versa. It wasn't pretty.

What saved it was adding an [[https://www.blackmagicdesign.com/uk/products/atemmini][ATEM Mini Pro ISO]] from BlackMagic. Now I could hand off all the capturing, streaming and recording duties to that box and run Logic and Zoom on the Mac and everything just worked (with an utter rats nest of cables on my desk). The ATEM takes HDMI input from up to four sources and lets me switch what gets sent to the stream between them. There's also a monitor preview output that can be switched independently between those four sources, as well as multiview and stream previews. Of course, I quickly used up all four sources, and I don't even have a second camera! The way things are arranged by default is that I have a camera feed, my mac's primary and secondary displays, and the output from a Raspberry Pi. Mac screen 2 is where the zoom window lives, and is connected to the ATEM via an HDMI splitter with the second output feeding a 7-inch field monitor that sits on a teleprompter setup so I can look guests in the eye.{{{marginnote(Best purchase ever! I primarily use it with Zoom or to display the YouTube chat when I'm doing solo streams)}}}
The primary Mac screen is where I set up streams and drive Logic from. It feeds into the ATEM mostly so I can see it in the preview window or full size when I need to without having to have a another screen, but if I ever get a second camera, I'll break mac screen 1 out to its own monitor and dedicate input 2 to that secondary camera. Input 4 is a Raspberry Pi that I use for motion graphics. This used to be a copy of chromium running in kiosk mode to display the [[https://ko-fi.com/pdcawley][Ko-Fi]] stream widget which displays donations as they happen, but I've recently managed to compile OBS studio with a working browser plugin and I'm using that instead now, which should allow me to add more overlays later. The only catch with that is that I've not yet managed to get [[https://bitfocus.io/companion/][Companion]] to compile, {{{marginnote(Companion's a brilliant app for controlling AV gear via a web interface or Stream Deck. I know it works on the Pi because they provide OS images for it.)}}} so I think I'll have to move that onto the Mac.

{{{newthought(This all worked fine)}}} until recently. You see, the thing I love about unaccompanied singing is singing harmonies. And harmonies don't work unless the timing is properly tight. That means I can't sing harmonies with Zoom guests because the speed of light{{{marginnote(and video and audio compression and decompression)}}} screws things up completely. I got around this by harmonising with myself -- either by using a Looper plugin in Logic[fn:6] or just by using Logic's multi-tracking[fn:7] to record multiple layers of a song's chorus. It all works, and works well, but I could never work out how to record harmonies for shanty type refrains.

Consider:
#+begin_verse
Oh the rain it rains all day long
  /Bold Reilly oh, bold Reilly!/
And them Northern winds they blow so strong
  /Bold Reilly oh's gone away/

*Chorus:*
  /Goodbye my sweetheart, goodbye my dear-o/
    /Bold Reilly oh, bold Reilly/
  /Goodbye my darling, goodbye my dear-oh/
    /Bold Reilly oh's gone away/
#+end_verse

Ideally, I want to be layering up harmonies on the /Bold Reilly oh, bold Reilly!/ and /Bold Reilly oh's gone away/ lines within each verse, as well as on the chorus (and potentially on any chorus repeats too). It should be possible to set up Logic's live looping feature to enable this sort of thing, but I could never work out how, and I wasn't ready to switch to Ableton Live (where I couldn't be sure I knew how to make it work either). So I stuck to just harmonising on the chorus and wishing there was a better way.

*** Enter [[https://loopypro.com/][Loopy Pro]]!

I'll write a full review of Loopy Pro one of these days, but suffice it to say, there is now a better way. Loopy Pro is the long awaited successor to Loopy HD, a software looper for iOS. It's been a very long time coming, but by god, does it deliver! As well as being a looper, it's a great replacement for MainStage and (at least for live use) Logic Pro, and it runs on even pretty ancient iPhones and iPads. It's predecessor was remarkably capable, but was 'just' a looper with a configurable number of loops available. Loopy Pro is fully customisable, supporting any number of loops, one shot samples, beat slicing, AUv3 hosting, mix busses, control widgets, faders and dials. There's a deep system of actions and 'follow actions' that allow you to customize its behaviour as well as its appearance, and the audio routing capabilities could embarrass some far more expensive DAW software. It's astonishingly capable.

#+caption: Loopy Pro configured for singing 'shanty' structured chorus songs
[[/ox-hugo/shanty-view.png]]

I've been fiddling with it since it was released, and now have it set up to allow me to sing shanty style songs with harmonies on the refrain as well as stuff like this:

@@hugo:{{< embed "https://youtu.be/hWPmADRfPFQ" />}}@@

so now I'm running Friday night stream audio from the iPad, leaving the Mac to run Zoom. This has all been made /much/ easier since I added a new audio interface: the iConnectivity [[https://www.iconnectivity.com/audio4c][AUDIO4c]] interface is a remarkable bit of kit. Uniquely, as far as I can tell, it can be used as an audio interface simultaneously by my mac and my iPad, and can route audio from the iPad to the mac and vice versa. It's got four inputs and six outputs, which is two more than existing interface. That means I can have my guest and me fed to the ATEM mini on separate channels, as well as giving myself a different headphone mix. And it's only one rack unit high!
#+begin_marginnote
Focusrite "small" interfaces, which are what I've used up to now are all about 1.5U high unless you buy the versions with 8 preamps -- lovely bits of kit, but rather more than I either need or can afford.
#+end_marginnote

The remaining bit of the puzzle is to reliably capture the iPad display. I'm looking for, and so far failing to find, a powered USB-C hub that has a bulletproof iPad HDMI connection and gigabit ethernet, which is much more reliable when it comes to remote control of the ATEM. It's a frustrating search. Everything I've found so far has intermittent HDMI dropouts, which would be annoying enough if it weren't for another 'feature' of iOS and iPadOS.

{{{newthought(It works like this:)}}} on iDevices, you don't have the option to choose which audio interface you want to use, instead the OS autoselects whichever interface was plugged in most recently. Which would be fine (sort of) if it weren't for the fact that an HDMI connection to an audio capable device is treated as a new audio interface. So... if the HDMI connection was reliable, getting prepped for a stream would just involve unplugging the audio interface from the hub, connecting the HDMI and reconnecting to the AUDIO4c. But then the HDMI drops and comes back, and suddenly /it/ is the most recently connected interface and the stream's audio is buggered.

If you know of an iPad friendly USB-C hub that has rock solid HDMI, then I'd love to hear about it because my search is getting really frustrating. Right now I'm working around it by disconnecting the audio, screen sharing to the Mac and reconnecting the audio, but even with a dual screen mac set up, screen sharing takes over both screens{{{marginnote(Wellâ€¦ it takes over one screen and fades the other to black. Thanks Apple!)}}} and the whole thing has a bunch of latency that you don't really want -- it's surprising how little latency will start making audio software in particular seem seriously out of sync. I can correct for that when editing, but not so much on a live stream.

Butâ€¦ once I have reliable HDMI from the iPad I run into another problem. Where do I plug it in? Suddenly four inputs on the ATEM aren't really enough.

Time to start saving up for an ATEM Mini Extreme ISO, which is the extra-wide version of the ATEM Mini Pro ISO, complete with 8 HDMI inputs, 2 HDMI outputs, 2 USB-C connections, a 3.5mm audio jack output (so I can monitor the audio going to the stream rather than just looking at the VU meters on the multiview display) and something called a 'Super Source', which would definitely simplify the business of setting up the split screen view when I have a Zoom guest.
#+begin_marginnote
Because of restrictions in the way the ATEM Mini Pro ISO works, I have to sit to one side of the shot because I can only adjust the scale, crop and position of one video source at a time. The Super Source deals with all that.
#+end_marginnote

The extreme version appears to fix pretty much everything that I find slightly annoying about the Mini, which is brilliant, but could be brillianter. Ah well, a boy can dream.

If you're interested in seeing what all this technology ends up looking like on stream, then I stream at 8pm UK time every Friday night on my [[https://youtube.com/c/PiersCawley][YouTube channel]]. Maybe pop by, and if you like what you see and hear, don't forget to like and subscribe.


** DONE Quick site update
CLOSED: [2022-04-28 Thu 13:01]
:PROPERTIES:
:export_file_name: 20220428-quick-site-update
:export_hugo_custom_front_matter: :syndicate true
:export_hugo_custom_front_matter+: :tweet "I've been doing a bit of gardening on my blog and hopefully setting up auto tweeting too."
:export_hugo_custom_front_matter+: :syndicated_at '((twitter . "https://twitter.com/pdcawley/status/1519655434818408448?s=20&t=JN0DWp5MSMU_IoGk-NnyvA"))
:END:
I'll get back to the gory details of my webmention catcher later, but I've been doing a bit of site gardening. Hopefully this means that our index page is looking much nicer, and things are a bit more parseable by IndieWeb tools.

Also, I hope, I've added some gadgetry that means that [[https://brid.gy][brid.gy]] will automatically tweet a link to this page once I've posted it.

** DONE We Deserve Better
CLOSED: [2014-01-11 Sat 11:01]
:PROPERTIES:
:export_hugo_slug: we-deserve-better-than-this
:export_file_name: 3408_we-deserve-better-than-this
:END:

{{{newthought(One hundred years ago)}}}, we got caught up in a really stupid war. Warâ€™s never what youâ€™d call a good idea, but the first world war is the benchmark of stupidity (unless youâ€™re Michael Gove, but heâ€™s fast becoming the new benchmark of stupidity).

Something strange happened at the end of the war. In 1914, only around 30% of the adult population had the vote. By February 1918, a general election was years overdue. The Russians had killed the Tsar and were embracing communism; the womenâ€™s suffrage movement was threatening to start up again; and millions of returning soldiers â€” men used to violence by now â€” would have no say in how they would be governed.

#+hugo: more

Parliament read the tea leaves and passed the [[http://en.wikipedia.org/wiki/Representation_of_the_People_Act_1918][Representation of the People Act]], extended the franchise to all men over 21 and many women over 30. This tripled the size of the electorate, 43% of which was now female (if theyâ€™d allowed younger women the Vote, then women would have had a clear majority because the war had killed so many men. Voting ages were equalised in 1928).

In the election, not much changed. The Tories won the most seats with a new class of MP, mostly coming from trade and commerce. Labourâ€™s share of the vote  increased dramatically, but the nature of the electoral system meant they only won 57 seats (fewer then Sinn FÃ©in, who basically won Ireland). The Liberals came third, in the popular vote (second in seats, first past the post really sucks) but Lloyd George remained prime minister promising a land â€œfit for heroesâ€.

He didnâ€™t deliver. The Irish had to fight for their independence and won it  in 1921 (ooh look, another stupid war) and in the 1922 election Labour took over from the Liberals as the second party British politics.

Without the first world war, I wonder how long it would have been before parliament was shamed into extending the franchise to all adults. The expanded electorate may not have got the government it deserved, but the Vote was won.

*** Time passesâ€¦

Seventy years ago, the next big war ended. This time the returning soldiery werenâ€™t going to be fobbed off with fine words and broken promises. Young men came home from defeating fascism in Europe and saw a sitting government still dominated by the party that had blundered into the war in the first place, still promising more of the same. They heard the Labourâ€™s promises of full employment, a National Heath Service, a cradle to grave welfare state and a compelling vision of the future. And they voted Labour. Oh, how they voted Labour.

Labour won the kind of majority that politicians dream about and went straight to work. Attleeâ€™s government nationalised roughly 20% of the economy; built social housing and encouraged the growth of new towns; introduced national insurance, unemployment benefit and the family allowance; expanded on the universal free education introduced with the Education Act of 1944; and created our National Health Service and what came to be known as the â€œPostwar Consensusâ€.

In five years.

In the face of austerity that made our current conditions seem like the lap of luxury.

They didnâ€™t just deliver homes, health and education. They found money for the Arts Council too. Because once youâ€™ve dealt with the worst that physical poverty can bring, shouldnâ€™t you look to do something about poverty of aspiration too?

Few revolutions are so successful. No others have achieved so much without violence. A generation came back from war, said to itself, â€œWe deserve better than thisâ€ and /did something about it/. If youâ€™ve got a grandparent living who voted in that election, go and thank them. Stopping Hitler was a towering achievement, but our grandparents managed to surpass even that.

*** Never knowingly not evil

The Tories /hated/ it. Every time theyâ€™ve had power since theyâ€™ve chipped away at the Postwar Consensus. Theyâ€™ve had to be sneaky about it though. Once youâ€™ve won the right to fall ill without fearing bankruptcy; once your children are guaranteed a decent education; once you have a roof over your head that isnâ€™t two pay cheques away from being taken awayâ€¦ Well, you get attached to such things.

The 1944 education act was a Tory act, and rather than replace the old system, it /added/ state schools to the mix. The rich were able to opt out and keep their children in the public school system. The public schools and their associated â€˜old boyâ€™ networks survived. Etonians donâ€™t just learn Latin and Greek and the art of fagging; they learn that glib smoothness, the art of masking base and selfish motives behind the a veneer of affability. They learn to help their friends and the Devil take the hindmost.

The thing about villains is, they think theyâ€™re heroes. They think thereâ€™s nothing nobler than helping a chum. They think the world is just. If youâ€™re blessed with the kind of money that Cameron and Osborne inherited youâ€™re going to convince yourself that you somehow deserve your wealth. And if you deserve your wealth, then itâ€™s a small step to thinking that the poor deserve their poverty.

If the world is as it is because everyone deserves their station, then the welfare state is going to seem like the next best thing to evil. The state wants to take some of your money and use it to pay some loserâ€™s rent? It wants to give a drunk a liver transplant? Disgusting! If those people /really/ cared about keeping their home, theyâ€™d get a decent job â€” itâ€™s not hard, just have a word with a friend. And the drunk has only himself to blame. Theyâ€™ve made their bed and they should lie in it.

The real trick though, is convincing those who really are a pay cheque or two from disaster (which is pretty much anyone with a mortgage or in private rented accommodation when you stop and think about it) that the enemy is the poor bastard on benefits. Not the landlord who banks their housing benefit. Not the employer who doesnâ€™t pay a living wage; who lets the taxpayer top up their employeesâ€™ pay packets. And certainly not the government which wonâ€™t let local authorities build new social housing to help reduce housing costs (which would pay for itself in short order).

This government has that down pat. Theyâ€™ve used a financial crisis â€” one whose seeds were sown when Thatcher and Reagan deregulated the markets and fertilised by every bloody government since (there are no innocents in this fiasco) â€” as the excuse and are dismantling what was so hard won by our grandparents. A government that promised â€œNo top down reorganisations of the NHSâ€ is gutting it. The poor are being forced out of rich areas by the benefits cap and the bedroom tax. The young areâ€¦ oh god, the youngâ€¦ the coalition seems to read /[[http://en.wikipedia.org/wiki/A_modest_proposal][A Modest Proposal]]/ as sound policy. When I went to university, my fees were fully paid (Thatcher had frozen maintenance grants, not that Iâ€™dâ€™ve got one after means testing). My step-grandson is looking at a /minimum/ debt of Â£27,000 â€” assuming he can live for nothing. If youâ€™ve got the cash to get your kid the best education money can buy, you donâ€™t want some bright lass from the local comprehensive competing with them for the plum jobs. Pull up the ladder Jack!

It doesnâ€™t have to be like this. Ask yourself how it is that, in 1945, when the country was on the bones of its arse with precious few lines of credit and an industrial base battered by years of bombing we built a welfare state and a national health service that have lasted for seventy years? Ask how we could, at the same time, find the money to subsidise the Royal Opera House and Sadlers Wells and many other arts organisations? Ask how we could afford, as a country, to support our university students so they could spend their time concentrating on their degrees and the life of the university and not miring themselves in debt?

Ask how we can afford /not/ to do those things now.

There is no excuse for what our government is doing to the poorest among us. Or for what itâ€™s doing to the middle classes come to that. An underclass is handy thing. They keep those on lower middle incomes so bloody scared of falling into poverty that theyâ€™ll put up with gross abuse just so they can hang on to what they have. Some guard their little portion with such jealousy that they will not just tolerate the abuse of the poor, they will be baying for blood.

It pains me to say this, but not everything the coalition has done is evil. And I donâ€™t just mean Equal Marriage. Even Michael â€œStopped Clockâ€ Goveâ€™s been right about something â€” the emphasis on learning to code rather than merely drive Powerpoint and Microsoft Word is a good thing. The gov.uk initiative is good news â€” anything which reduces the influence of KPMG, Capita, G4S and their cronies (and which employs so many of  my more technical friends) canâ€™t be bad. But a â€˜good in partsâ€™ government is still intolerable.

Thereâ€™s an election due in 2015. 2015, the 70th anniversary of the Attlee revolution. Itâ€™s time to do it again. Vote. Vote progressive. Vote independent or green. Hold your nose and vote Liberal or Labour. Join a fucking party and work to change their outlook. Vote pragmatic. But, whatever you do, vote. /Especially/ if youâ€™re young. Politicians only care about keeping the people who vote happy â€” if you donâ€™t vote, theyâ€™ll ignore you. If it makes some other part of their constituency happy, theyâ€™ll shit on you from great height (though I think that may backfire yet â€” the thing about grandparents is, they tend to like their grandchildren and donâ€™t like seeing them get the shitty end of the stick)

You could listen to Russell Brand and not vote â€™cos itâ€™s â€œirrelevantâ€ â€” thereâ€™s a revolution coming! You could. But youâ€™d be an idiot and youâ€™d be waiting a long time. Thereâ€™s been one progressive revolution that actually stuck in this country, and that was achieved by voting.

Demand the nationalisation of public goods; the Post Office, Rail, Water, Gas, Electricity. Encourage small businesses and /making/ stuff. Build new public housing. Demand real transparency in markets and government. Fuck landlords. Fuck rentiers.

Change the world. Our grandparents did it seventy years ago. We deserve better. Letâ€™s take a leaf out of their book and do it again.


** DONE Travelling hopefully
CLOSED: [2005-12-06 Tue 03:47]
:PROPERTIES:
:export_file_name: 2005-12-06-travelling-hopefully
:END:

I wonder if the ground state of the photographer is 'dissatisfied'. When
I bought a D100 two years ago I loved it. But it didn't take long for
disenchantment to set in; the frame buffer was too small, I couldn't use
old (and wonderful) manual focus lenses on it, digital noise was horrid
at high speeds, white balance was dodgy and it didn't feel as good in
the hand as my F100.

Some problems could be alleviated by shooting in RAW mode and
'developing' the images with Photoshop, but for all Photoshop's
undoubted excellence, this is awfully labour intensive.

So, when I went to EuroOSCON this year, I left the digital camera at
home, taking the F100 instead. Amsterdam has an excellent pro lab which
did dev and scan, so I managed to have several of my
[[http://flickr.com/photos/pdcawley/sets/1211132/][photos]] online
before the conference was over.

While we were there, Apple announced
[[http://www.apple.com/aperture/][Aperture]], their new pro
photographers' workflow tool. Like [[http://x180.net/][James Duncan
Davidson]], the official photographer, I was excited by the
announcement. According to the information on the website, it addressed
most of what pissed us off about other tools for managing photos. I
think James placed his order that day.

Then, at the beginning of November, Nikon announced a replacement for
the D100: the [[http://www.dpreview.com/articles/nikond200/][D200]]. As
with Aperture, its list of features seemed to have been specifically
written to address all my annoyances with the D100.

I ordered a D200 couple of weeks ago, and Aperture last night. Right now
I'm in an excited state. Hopefully, once the kit arrives I'll manage to
stay here for a while. Until the next shiny new thing comes along...


** DONE Reading Turing
CLOSED: [2013-03-17 Sun 12:49]
:PROPERTIES:
:export_file_name: 20130317-reading-turing
:END:

Some things never disappoint. And reading Alan Turing is one of those
things. In an earlier post I told an incorrect anecdote about Turing,
and Russ Cox pointed me at proof, in Turing's own words, that I was
wrong. I don't know why it's taken me so long, but I finally got around
to reading his
[[http://www.vordenker.de/downloads/turing-vorlesung.pdf][ /Lecture to the London Mathematical Society on 20 February 1947]]./

Wow.

#+hugo: more

Seriously. Wow. He's talking about programming the [[http://en.wikipedia.org/wiki/Automatic_Computing_Engine][ACE]], the
[[http://en.wikipedia.org/wiki/Pilot_ACE]['pilot']] version of which didn't run its first program until 1950. And the
[[http://en.wikipedia.org/wiki/Manchester_Small-Scale_Experimental_Machine][Manchester 'Baby']], the first stored program electronic computer, was more than a year away from running its first program. It sounds like it might be dreadfully speclative and either handwavy or as out there and daft as the usual crop of 'futurologist' type predictions.

As you can probably guess from the fact that I'm bothering to write this
up, it was nothing of the sort. I suggest you nip off and read it for
yourself. It won't take you long and it's well worth your time. Then
come back here and find out if the same things struck you that struck
me.

{{{newthought(Here's the sentence that brought me up short like a slap:)}}}

#+begin_quote
Computers always spend just as long writing numbers down and deciding
what to do next as they do in actual multiplications, and it is just the
same with the ACE.
#+end_quote

I got to the end of the sentence before it clicked that back then a
computer was a human being performing a computation. What we think of
today as 'a computer' was what Turing called 'the ACE' and back then it
certainly deserved that definite article.

Then I read it again and recognised the deep truth of it. Back in
Turing's day, the ACE was planned to have a memory store made up of 5
foot tubes full of mercury acting as an acoustic delay line. Each tube
could hold 1K bits and an acoustic pulse took 1 millisecond to get from
one end of a tube to the other, so the average access time for a single
bit of memory was around 500 microseconds. When it was finally built, it
was the fastest computer in the world, running at the mighty speed of
1MHz. Nowadays we think that a cache miss that costs 200 processor
cycles is bad news and our compilers and processors are designed to do
everything in their power to avoid such disasters. In Turing's day there
were no caches, every time something was fetched from memory it cost 500
cycles. (Well, in 1947 that would be 500 cycles + a year and a half
before there was a computer to fetch the memory from in the first
place).

Curiously, the gold standard of high performance memory in Turing's day
was the same circuit as you'll find in high speed SRAM today - the
bistable flip flop - but done with valves and hope rather than by
etching an arcane pattern on a bit of silicon.

{{{newthought(Turing seems to have invented the idea of the subroutine.)}}} Admittedly
it's implicit in his implementation of a Universal Turing machine in On
Computable Numbers..., but it's explicitly described here. And, rather
wonderfully, the pipedream of extensive code reuse is there in the
computer science literature right from the start:

#+begin_quote
The instructions for the job would therefore consist of a considerable
number taken off the shelf together with a few made up specially for the
job in question.

#+end_quote

There are several moments when reading the paper where I found myself
thinking "Hang on, he means that literally rather than figuratively
doesn't he?" and this is one of them. When your code is embodied in
punched Hollerith cards, a library is just that. Row upon row of shelves
carefully indexed with reusable code stacked on them like so many books.

Elsewhere he says:

#+begin_quote
It will be seen that the possibilities as to what one may do are
immense. One of our difficulties will be the maintainence of an
appropriate discipline, so that we do not lose track of what we are
doing. /We shall need a number of efficient librarian types to keep us
in order./

#+end_quote

That's my emphasis, and ain't /that/ the truth? I'm not sure that Turing
would have foreseen that the nearest thing we have to 'a number of
efficient librarian types' would turn out to be Google's computers
though. One wonders whether he'd be horrified or delighted.

*** Descrimination
:PROPERTIES:
:CUSTOM_ID: descrimination
:END:
Here he is, having painstakingly explained how the use of loops can
reduce the size of a program:

#+begin_quote
It looks however as if we were in danger of getting stuck in this cycle
and unable to get out. The solution of this difficulty involves another
tactical idea, that of 'descrimination'. ie. of deciding what to do next
partly according to the results of the machine itself instead of
according to data available to the programmer.

#+end_quote

And there we have the nub of what makes computing so powerful and
unpredictable. The behaviour of any program worth writing isn't
necessarily what you expect because it's making decisions based on
things you didn't already know (if you already knew them, you wouldn't
have to compute them in the first place). This is why I'm optimistic
about AI in the long run. I think that given that the behaviour of a
single neuron is understandable and simulatable then, eventually we'll
manage to connect up enough virtual neurons and sensors that the
emergent behaviour of those simulated neurons is as near to a 'real'
consciousness as makes no odds. I'm far less convinced that we're ever
going to be able to upload our brains to silicon (or whatever the
preferred computing substrate is by then). Whether we'll able to
communicate with such a consciousness is another question entirely,
mind.

*** Job Security Code
:PROPERTIES:
:CUSTOM_ID: job-security-code
:END:

#+begin_quote
The masters are liable to get replaced because as soon as any technique
becomes at all stereotyped it become possible to devise a ssystem of
instruction tables which will enable the electronic computer to do it
for itself. It may happen however that the masters will refuse to do
this. They may be unwilling ot let their jobs be stolen from them in
this way. In that case they would surround the whole of their work with
mystery and make excuses, couched in well chosen gibberish, whenever any
dangerous suggestions were made

#+end_quote

Oh, did Turing nail it here. 1947 and he's already foreseen 'job
security' code. I've seen this kind of behaviour all the time and it
drives me up the wall. What the peddlars of well chosen gibberish always
fail to see that, if you get it right, the computer ends up doing the
/boring/ parts of your work for you. And your time is then free to be
spent on more interesting areas of the problem domain. Software is never
finished, it's always in a process of becoming. There's a never ending
supply of new problems and a small talent pool of people able to solve
them; if you're worth what you're paid today then you'll be worth it
again tomorrow, no matter how much you've delegated today's work to the
computer. And tomorrow's work will be more interesting too.

Automating the shitwork is what computers are /for./ It's why I hate the
thought of being stuck writing code with an editor that I can't program.
Why I love Perl projects like Moose and Moo. Why I'll spend half a day
trawling [[http://metacpan.org/][metacpan.org]] looking to see if the
work has already been done (or mostly done - an 80/20 solution gets me
to 'interesting' so much quicker).

Job security code makes me so bloody angry. There are precious few of us
developers and so much work to be done. And we piss our time away on
drudgery when we simply don't have to. We have at our fingertips the
most powerful and flexible tool that humanity has ever built, and we use
it like a slide rule. Programming is hard. It demands creativity and
discipline. It demands the ability to dig down until we really
understand the problem domain and what our users and customers are
trying to do and to communicate the tradeoffs that are there to be
made - users don't necessarily understand what's hard, but they're even
less likely to understand what's easy. But its very difficulty is what
makes it so rewarding. It's hard to beat the satisfaction of seeing a
way to simplify a pile of repetitive code, or a neat way to carve a
clean bit of testable behaviour off a ball of mud. Sure, the insight
might entail a bunch of niggly code clean up to get things working the
new way, but that's the kind of drudgery I can live with. What I can't
stand is the equivalent of washing the bloody floor. Again. And again.
And again. I'd rather be arguing with misogynists - at least there I
might have a chance of changing something.

I'm not scared that I'm going to program myself out of a job. I'm more
worried that I'm never going to be able to retire because as a society
and a profession we're doing such a monumentally piss poor job of
educating the next generation of programmers and some of us seem to be
doing a bang up job of being unthinkingly hostile to the 50% of the
talent pool who are blessed with two X chromosomes. But that's probably
a rant for another day.


** DONE Big Data and Singing Crowds
CLOSED: [2013-03-17 Sun 10:37]
:PROPERTIES:
:export_file_name: 20130317-big-data-and-singing-crowds
:END:

#+begin_description
I watched the rugby yesterday. England vs Wales at Cardiff Arms Pack. It was a great game of rugby - England were comprehensively outthought by a Welsh side with more experience where it counts, but by gum, they went down fighting to the very end. It's going to be an interesting few years in the run up to the next World Cup.

While the game was going on, I found myself wondering why the crowd's singing sounded so very good.

#+end_description

{{{newthought(I watched the rugby yesterday.)}}} England vs Wales at Cardiff Arms Pack. It was a great game of rugby - England were comprehensively outthought by a Welsh side with more experience where it counts, but by gum, they went down fighting to the very end. It's going to be an interesting few years in the run up to the next World Cup.

While the game was going on, I found myself wondering why the crowd's singing sounded so very good. It's not a particularly Welsh thing
(though /Cwm Rhonda/, /Bread of Heaven/ and the whole Welsh crowd's
repertoire are have fabulous tunes). The Twickenham crowd getting behind
/Swing Low, Sweet Chariot/ sound pretty special too, even if I wish they
still sang /Jerusalem/ occasionally. How come a crowd of thousands,
singing entirely ad lib with no carefully learned arrangements or
conductor can sound so tight?

After all, if you took, say, 30 people and asked 'em to sing a song they
all know, it would sound ropey as hell (unless they were a choir in
disguise and had already practiced). Three or four together might sound
good because, with that few of you, it's much easier to /listen/ to your
fellow singers and adapt, but 30's too many for that and without some
kind of conductor or leader, things aren't likely to sound all that
great.

I think it's a statistical thing. Once you get above a certain number of
singers, the fact that everyone's going to sing a bum note now and
again, or indeed be completely out of tune and time with everyone else,
the song is going to start to make itself heard. Because, though
everyone is wrong in a different way, everyone is right the same way. So
the wrongs will start to cancel themselves out and be drowned by the
'organised' signal that is the song. And all those voices, reinforcing
each other make a mighty noise.

That's how big data works too. Once you have sufficient data (and for
some signals sufficient is going to be /massive/) then the still small
voices of whichever fraction of that data is saying the same thing will
start to be amplified by where the noise is dissipated.

Just ask an astrophotographer. I have a colleague who takes rather fine
photographs of deep space objects that are, to the naked eye nothing
more than slightly fuzzy patches of space, only visible on the darkest
of nights but which, through the magic of stacked imaging can produce
images of stunning depth and clarity.

If you've ever taken photographs with a digital camera at the kind of
high ISO settings that Mike used to take this, you'll be used to seeing
horrible noisy images. But it turns out that, by leveraging the nature
of the noise involved and the wonder of statistics, great photographs
like this can be pulled out of noisy data. It works like this:

Any given pixel in a digital photograph is made up of three different
componants:

- Real light from the scene in front of the camera
- Systematic error which is the same in every image
- Thermal (usually) noise

The job of an astrophotographer is to work out some way of extracting
the signal at the expense of the noise. And to do that, they have one
massive advantage compared to the landscape or portrait photographer.
The stars and nebulae may be a very very long way away. They may be very
dim. But they don't move. Once you've corrected for the motion of the
earth, if you point your scope at the horsehead nebula today it's going
to look the same as it did yesterday and the day before that. Obviously,
things do change, but, from the distance we're looking, the change only
happens on multi-hundred year timescales. This constancy makes the
astrophotgraphers task, if not easy, at least possible.

So... the stars (like the tune of Cwm Rhonda) are unchanging, but the
noise is different with every exposure (that's why it's called noise
after all). Even if, on any given exposure the noise is as strong as the
signal, by taking lots and lots of exposures and then averaging them,
the noise will get smeared away to black (or very dark grey) and the
stars will emerge from the gloom. Sorry. The stars and the systematic
error will emerge from the gloom. So, all that remains to do is to take
a photograph of the systematic error and take that away from the image.

Huh? How does one take a photograph of systematic error? You do it by
photographing a grey sheet. Or, because it's probably easier, by
throwing your telescope completely out of focus so what you see is to
all intents and purposes a grey sheet and taking a photograph (or lots
of photographs - you've still got noise to contend with...) and
subtracting the resulting error map from your stack of photographs and
bingo, you're left with an image that's mostly signal. All that remains
is to mess with the levels and curves and possibly to stack in a few
false colour images grabbed from the infra red or the hydrogen alpha
line where there's lots of detail and you're on your way to a cracking
photograph.

Obviously, it's not as easy as that - telescope mounts aren't perfect,
they drift, camera error changes over time. It's bloody cold outside on
a clear night. Sodium street lights play merry hell with the sky. And so
on. But if you persevere, you end up with final images like the one
above. That sort of thing's not for me, but I'm very glad there are folk
like Mike taking advantage of every clear night to help illuminate the
awesome weirdness of our universe.

Noisy data is a pain, but, we're starting to realise that, if you have
enough data and computing power, you can pull some amazing signals out
of it. Whether that's the sound of thousands of Welsh rugby fans
combining to sound like the voice of God; an improbably clear photograph
of something that happened thousands of years ago a very long way away;
your email client getting the spam/ham classification guess right 99
times out of 100; or Google tracking flu epidemics by analysing
searches, if you have enough data and the smarts to use it, you can do
some amazing things.

Some of them are even worth doing.

** DONE General purpose computing is the /best!/
CLOSED: [2022-05-12 Thu 13:21]
:PROPERTIES:
:export_file_name: 20220512-general-purpose-computing-is-the-best
:export_hugo_custom_front_matter: :syndicate true
:export_hugo_custom_front_matter+: :tweet "I added a Raspberry Pi to my streaming rig on spec, and of course now it's indispensible"
:END:

#+begin_description
Once I'd added the Mac Mini to the rack, there was a space in the bracket it was mounted on that was designed to hold one or two Raspberry Pis. I had a Pi sitting about, so of course I added it to the rig thinking "I'll work out what to do with that later."

It's proved invaluableâ€¦
#+end_description

Sometimes folk ask why there's a [[https://raspberrypi.org/][Raspberry Pi]] in the rack case that holds my streaming rig and I admit that the primary reason is that I had one kicking about the place, and the rack unit that holds my M1 Mac Mini is designed to hold a couple of Pis in the space that isn't holding the Mac, so I might as well attach it. I had the feeling it would come in handy.

It turns out, I was right. It runs OBS to handle motion graphics, and Companion to control the ATEM Mini from a streamdeck. In the future I plan to use it as a router so the gear in the rack can live on its own private network with the Pi handling the connection to the outside world either via a network cable or (hopefully not) wifi or a tethered phone.

The latest "Oh, of course! It can do that too!" job it's taken on is pretending to be an Apple TV, so I can mirror my iPad's screen to it without mucking up the Mac's display.

Once again, I'm reminded that computers can be anything you can program them to be... sometimes all at once. The Pi 4 is a mindbogglingly capable bit of kit. I've bought USB hubs{{{marginnote(USB Hubs that don't work!)}}} that cost more and do less than my Pi.

There's a Pi 3 plugged in somewhere{{{marginnote(I think I know where it is, but I'm not entirely sure)}}} that runs [[https://pi-hole.net][Pi Hole]] and helps eliminate intrusive ads from my web experience. It has sufficient spare power that, once I get around to it, I plan to hook up a cheap workhorse laser printer to it and configure it to work as a print server, which should let me retire the crappy unreliable bubblejet printer that only prints when you stand over it with a big stick and is always demanding the blood of innocents{{{marginnote(The printer calls it ink, but have you seen the price of that stuff?)}}} before it'll deign to even try to print something.

About the only thing wrong with them (at the moment) is that they're almost permanently out of stock everywhere. I watch [[https://rpilocator.com/][rpilocator]] and it's clear that people do get stock, but they sell out almost immediately. A chum who works for Raspberry Pi says that they are shipping lots and lots of boards, but the demand stays sky high. Which is a nice problem to have for them, I suppose.
** DONE Migrating to Mastodon
CLOSED: [2022-11-20 Sun 13:59]
:PROPERTIES:
:export_file_name: 20221120-migrating-to-mastodon
:END:

Twitter, eh? Elon bloody Musk!

In the happier timeline, Elton John bought Twitter and it became even more fabulous with every passing day. In the far more depressing timeline we find ourselves living in, Elon seems to be determined to tank the company and fuck the community.

So I've buggered off to Mastodon. At the time of writing, you'll find me at [[https://mendeddrum.org/@pdcawley][@pdcawley@mendeddrum.org]] and, you might even be reading a version of this via Mastodon rather than directly on the site.
#+hugo: more
** DONE More Mastodon fiddling
CLOSED: [2022-11-20 Sun 22:32]
:PROPERTIES:
:export_file_name: 20221120-more-mastodon-fiddling
:END:

There's a certain frustrating joy in fiddling with the details of a thing so as to improve the formatting of the new thing you've just added to your site, and discovering that a side effect of the change is that a couple of niggles that you'd not quite got to the bottom of on the site itself are fixed in passing.

I /think/ I've got the crossposting to Mastodon looking less awful, and I /know/ I've got [[https://bofh.org.uk/][my front page]] looking better. Isn't that lovely?
#+hugo: more
** DONE Impermanence matters
CLOSED: [2023-06-06 Tue 10:43]
:PROPERTIES:
:export_file_name: 20230606-impermanence
:END:


#+begin_description
Cool URLs don't change they say, and that's true. You'll always find my upcoming livestreams at [[https://youtube.com/pierscawley/live]], along with maybe one or two of the previous ones to catch up with. What you /won't/ find is the full three year archive of streams. Here's whyâ€¦
#+end_description

Back when lockdown started, for all we were both classed as 'critically vulnerable', we did pretty well. We had each other for company, the house is paid for, we have some private outdoor space, Doncaster Market remained open and I'd got a 25kg bag of flour. Life wasâ€¦ tolerable.

Except, as any musician will tell you, making music needs company. At least it does if you catch the magic that happens when a group of people are together making something beautiful. Which is why I started singing folk songs to the internet[fn:8] every Friday night.[fn:9]  At first, I just sang into the dark to the two or three people who showed up in the text chat {{{marginnote(Thank you all of you! You were awesome.)}}} but I was still missing harmonies. So I worked out how to use Logic for live sound and did on the fly multitracking of chorus harmonies and that was great. Recently, I've switched to using [[https://apps.apple.com/gb/app/loopy-pro-looper-daw-sampler/id1492670451][Loopy Pro]] on my iPad[fn:10] and it's been great -- I can sing harmonies on far more songs now and I've started experimenting with fancier arrangements too.[fn:11]

{{{newthought(A key realisation came)}}} after a late night conversation with [[https://johnspiers.co.uk/][Squeezy John]] [Spiers] on Twitter about how a YouTube archive of performances can become a millstone around an artist's neck. After all, if someone can catch a performance online from a couple of years ago, why would they pay to watch you doing it again? I don't think most people think this way, but the life of a professional musician is marginal enough that it doesn't take many to have an effect. So I started making the catch-up videos private after a week. {{{marginnote(Or whenever I got round to it, if I'm honest)}}}

It was incredibly liberating. I stopped worrying too much about repeating myself every week -- I always open with the same song, I usually close with one of about three songs, there's a couple of staples that people seem to miss if I don't sing them and if I fuck something up, it's gone in a week and I can concentrate on doing better next time. My audience seem to be fine with it. If I do something particularly well, or something funny happens like my cat bringing the backdrop down on me

@@hugo:{{< embed "https://youtu.be/kbeFRIqSUZg" />}}@@

then I have the original video files, so I can edit and upload a high quality clip that I'm happy to leave available forever.

And it's closer to the experience of music in person, too. Live music is a magical transient thing that lasts as long as the song and then it's gone. Recordings are souvenirs, they can be delightful, but they simply can't be the same as being in the moment.

It's gone. I might sing it again next week, but just as you can't cross the same river twice, that performance will be different. And that's brilliant.

{{{newthought(I'll tell you what is permanent:)}}} the repeating Friday night entry in my diary that reads â€˜Folk Stream.â€™ It doesn't matter whether I'm streaming for 2 people and no tips or a busy room and Â£100+ in [[https://ko-fi.com/pdcawley][Ko-fi's hat]], singing to the internet never fails to lift my mood. It's like I've made an appointment with joy.
** PUBLISHED Panning Overdubs in Loopy Pro
CLOSED: [2024-01-13 Sat 18:03]
:PROPERTIES:
:export_file_name: 20240113-panning-overdubs-in-loopy-pro
:END:

#+begin_description
A quick introduction to adjusting the panning of overdubs in Loopy Pro clips, including a link to a miRACK configuration and instructions on how to use it in your own Loopy Pro configurations
#+end_description

It's common practice in music production that, when you're layering your vocals with harmonies or doubles, you pan everything but the lead vocal around the stereo field. That gives a sense of physical separation between the voices and it feels more realistic -- or artificial, if that's what you're going for.

With loopers though, you'll more usually have your overdubs all in the same place, which is fine at the local open mic, where the front of house PA is often mono anyway, but for streamers like me, it feels a little limiting, so I've been working on a way to get that effect.

This is still a work in progress, but enough people expressed an interest when I showed this off in a [[https://www.youtube.com/live/uaP4np4WoAY?si=zPoXvCthRjsDUKEn]["How Do You Loop?"]] chat with John Paul Music UK here.

*** Quickstart

If you don't want the gory details of how the pandomiser works, here's how to add it to your Loopy Pro and get going quickly:

**** Set up miRACK in your project
+ Install [[https://apps.apple.com/gb/app/mirack/id1468259834][miRACK]] from the App store. It's a full-featured modular synthesizer simulator, and it's capable of far more and weirder things than we're making it do here. Check out the examples.

+ Grab the pandomizer bundle from [[/files/pandomiser.zip][my website]] and unzip with the Files app on your iDevice. Copy pandomiser.mrk to your miRACK folder so the plugin can find it.

+ Open the mixer, tap the âŠ• button and choose 'Add MIDI' and choose the miRack 'MIDI FX' option

+ Open the miRACK interface and tap on the four squares icon in the top left, choose 'Open Existing' and load ~pandomiser.mrk~.


**** Set Up Loopy's Audio Routing
I'm a pure vocal looper, so I'm going to assume you have a single audio input for your vocals that's routed to all Loopy's colours. If you've got seperate inputs for your voice and other instruments and not everything is routed to all the colours, you might have to add multiple panning busses, but what follows should give you enough information to get started. This setup also assumes that you don't want to affect the panning of your live audio, only where it gets placed in your loops and oneshots.

+ Add a send to your audio input, choose 'new bus' when prompted, then long press on the send and choose 'After All Effects'
+ Tap 'Destinations' in the new bus and turn off the hardware output channels. Tap the 'all' button to turn on all the Color Destinations.
+ Tap 'Destinations' on your audio input and 'none' to turn off all the Color Destinations

Now your input audio is going to your loops via this new bus, which means we can mess with its balance setting and it won't affect the live sound going to your speakers. We can do /anything/ here, and it won't be heard until the clip it's recorded on gets played out. Use this power responsibly. All we're going to do here is mess with the 'balance' setting.

Let's go.
+ Choose 'Control Settings' from the hamburger menu in the top right of Loopy's screen, then choose 'Default' from the Current Project setting.
+ Tap 'Add New Binding' and choose 'Adjust Parameter' from the *Bus Actions* section. Choose your new bus as the target, and make 'Balance' the parameter.
+ Change *Controller Input Start* to 1%. This avoids the problem that 0-127 doesn't have a central value. If you don't change this, then the bus's balance will get reset to 1 and, if you're anything like me, it will drive you up the wall.

Test everything is working by opening the mixer and bringing up the keyboard in the miRACK window then holding down C4. You should see your panning bus's balance jumping to a new random value, then resetting to the centre each time you press and release C4.

*** Basic Pandomiser use
Here's one simple way of ensuring that all your overdubs are placed at different points in the stereo field using a couple of follow actions.

+ Open *Clip Settings* from main menu, scroll down the settings sheet and choose *Follow Actions*
+ Add an action to *Begin Overdub,* choose *Send MIDI Message* with your miRACK as the target. Send a note, C4 on channel 1 with velocity (*Value* in the Loopy UI) 127 (those all the defaults for sending a note, by the way).
+ Go back to Follow Actions and tap the 'Reorder' button, now press and hold the follow action you just added and drag the new action down to *Finish Overdub*.
+ Open the new action and drag the *Value* slider down to zero.

Now, whenever you overdub a clip, as soon as your overdubbing starts, Loopy will 'hold down' C4 and the pandomiser will set the recording balance to a new random value. Once overdubbing stops, Loopy will 'release' the key and the balance will return to the centre.

*** Complicating things

In my Loopy setup, I don't want to change the balance of every overdub of every clip. There might be a couple of clips that will be overdubbed for each verse of the song, and I want the pan to remain the same for each overdub associated with the verse. So I can set the first clip to send the ~noteOn~ message when I start overdubbing and set the second to send a ~noteOff~ when I finish.[fn:13] You might only want to mess with the panning for certain colours, or even for specific clips, or you might want to set up widgets to record with or without messing with the panning. All you have to do is send C4 to miRACK when you want to randomise the balance, and release C4 when you want it reset to the centre. Have fun.


*** How does it all work?

A modular synthesizer like miRACK thinks in terms of voltages, and those voltages can mean different things. We use a midi trigger input module that we've configured to send +10V whenever C4 is held and we connect that to the *Gate* input of a Sample & Hold (S&H) module, which we're using as a source of randomness. Whenever the modules *Gate* voltage goes high, the module 'samples' the voltage at its input, and sets its output voltage to the same until the next time it detects a rising edge. If there's nothing connected to the input though, it /samples/ an internal noise generator and outputs that voltage. I've configured the module to so that its noise source is a white noise generator a range of Â±5V, and we can think of that as ranging from a hard left pan at -5V through the centre at 0V and on to a hard right pan at +5V.

 The output of the S&H module is now jumping to a new random value every time we press C4, but we really want to output 0V when C4 isn't pressed, so we feed its output into the input of another staple of a modular setup, a Voltage Controlled Amplifier (VCA). We've set this VCA up at unity gain, which means that, when it sees 10V at its Control Voltage (CV) input, it outputs, it sends 100% of its input voltage to its output, and when it sees 0V CV, it sends 0% of its input. So, if we connect the C4 trigger to the VCA's CV input, we've turned it into a gate -- whenever C4 is held, the VCA sends the random voltage from S&H, otherwise it sends 0V.

Now we just need to convert that into something MIDI understands, an unsigned value between 0 and 127. The *MIDI CC Output* module can do some of this for us, but it's expecting a voltage in the range 0--10V, and right now we've got something in the range of Â±5V. So we feed the signal from the VCA into the A input of a *CONST ADD MULT* module, set the constant to 5V, and feed the associated A+B output to one of our CC outputs that we've configured to send CC8 to our host app. Job jobbed!

*** Next Steps
I think the next version of this will allow me to sequence balance for the first few steps, so it might go: hard left, hard right, mid left, mid right, then random pans until the system is reset. I have ideas about how to implement this too, but if you beat me too it, please let me know!

I'll also be making a YouTube video walking you through it (think of this as a draft script for that video).
** PUBLISHED A Guest's Guide to Zoom Song Swaps
CLOSED: [2024-03-04 Mon 08:51]
:PROPERTIES:
:export_file_name: 20240225-a-guest-s-guide-to-zoom-song-swaps
:END:

This is intended as a quick guide for anyone who comes on as a Friday night Song Swap guest, but anyone who's thinking of using Zoom (or doing their own streams) to share music with folk might find it useful, so I'm making it public.

#+hugo: more

*** Publicity material
I'm absolutely terrible at marketing, but it will definitely help me do at least /some/ if you can provide me with some or all of the following:


**** A photo of you that you don't hate
If you've got a standard headshot or publicity photo, that's great. I'll use that to make the YouTube preview card.

If you don't, here's a few tips for taking your own. These are basic guidelines, not rules. You can ignore all of them and still get a great photo, but if you follow them, you should at least get a decent one.

***** Your phone is fine
Seriously, I would have killed for something the quality of even my iPhone SE back when I first started doing digital photography.

***** Try to enjoy yourself
If you don't like having your photo taken, it can show and you'll end up with another photo you don't like, so try this. For the duration of the shoot, pretend you're playing the part of someone who actually likes having their photo taken. Weirdly, that will almost certainly make the shoot go faster because you'll get a good shot nice and early and you can stop pretending.

***** Get a friend to take the photo
It's just easier. You can use a tripod or a selfie stick, but another human being's your best choice. If you've got a friend who's an experienced photographer, then for heaven's sake ask them and ignore the rest of this list -- be guided by them. Or book a session with a professional if you have the time, money and desire.

***** Use a big light
/Big/ light sources are the most forgiving and flattering ones. I like a nice big north facing window, or bright overcast days. It's not exciting or dramatic light, but that's fine.

***** It's not a firing squad
You know the typical passport photo shot? The one where you look like you've been lined up against a wall, standing square to the camera and looking nervous. Don't do that.

Here's a pretty foolproof lighting/posing idea:

1. Stand facing the biggest window you can find at a time when the sun isn't shining directly through it.
2. Turn about 45Â° to the left or right
3. Look across at your friend with the camera who's standing at 90Â° to the window light.
4. Your friend will, of course, take an otherwise fabulous photograph of you with your eyes closed, so repeat the last step until they manage a shot you like.
5. *CHECK YOUR BACKGROUND!*
   Make sure there's no dead flowers apparently growing out of your ears, an embarrasing cat licking its arse, or a pile of washing in the shot.

   Ideally you'll have a nice smooth out of focus thing going on there (portrait mode, if your phone has it can help), but if you can't manage that, shoot for something that's not too busy. You can't go far wrong with a bookshelf, but stand as far away from it as you can so it's not tack sharp and distracting.

***** Portrait or square format, please
Bear in mind that I'm going to be putting your photo into a square frame in the YouTube title card, so a wide image probably won't work too well.

**** Some links
Got a website? Bandcamp? YouTube channel? Tell me about them and I'll link to them in the event description and during the show.

**** A short biography
When I make the YouTube event for a song swap, I write something about my guests. I'll write something anyway, but it really helps if I've got something from you to base it on. After all, I know what I think about you, and I like you or I'd not have asked you to be my guest, but unless you /tell/ me, I don't know what you think is important about yourself. A short bio can really help there.

**** [Optional] Some talking points
A song swap isn't some kind of forensic interview process; it's supposed to be an informal chat interspersed with songs. If there's something you really want to talk about, please let me know. The same goes if there's anything you want me to steer clear of. It's fine if the conversation gets dark -- folk music's full of murders and misogyny after all -- but it's really not fine if it gets uncomfortable for you.

*** Tech
Zoom isn't my favourite piece of software and its default settings are definitely slanted towards business meetings rather than helping musicians sound good. The most important thing you can do in your Zoom settings is to turn on 'Original Sound For Musicians', which should show up in the top left of your screen. It's off by default, so click it and turn it on. If it doesn't show, you'll need to dig into Zoom's audio settings and check the box to make it available.

There's a catch: turning on original sound disables /all/ of Zoom's audio processing, including the echo cancellation magic, so it's really best if you can use a pair of headphones or earbuds rather than speakers to hear me. Or you can just remember to turn original sound on when you start singing and off again when we start chatting. Headphones are easier though.

If your laptop or phone's built in camera and microphone are all you have, don't worry, we can work with that. They're not the best, but they are optimised for someone sitting within reach of the keyboard and making human noises from their mouth hole. You'll look and sound fine.

If you've got money to spend and you want to look and sound better on stream then I have a few suggestions, but this is an area where there's no right answers, so do shop around and talk to anyone you know who you reckon looks good on your Zoom calls.

Prioritize your spending on gear. In general (and especially for musicians) sound is more important than lighting, which is more important than camera quality. A pin sharp, beautifully lit video of a muddy sounding performer is much harder to watch than a blurry, crystal clear sounding performer singing in a murky cave.


**** Some audio suggestions
If you're an unaccompanied singer, this is pretty easy because we don't have any problems getting your sound balanced and into Zoom. If you're an instrumentalist, or a band, things get a little more fun, so let's break it down based on the number of mics you'll need.

Bear in mind that there are entire books written on this subject; I'm barely scratching the surface here. If you're serious about getting good sound for streaming and/or recording, it's worth doing your own research. If all else fails, for your upcoming song swap, buy some of the gear recommended here from a reputable mail order site and rely on the 30 day, no questions asked returns policy they all have because that's a legal requirement in the UK. But MAKE SURE that when you know what you /really/ want, you buy from the same supplier.

***** One mic wonders
If the sound you make in the room is the sound you're happy with (unaccompanied singers, acoustic guitarists, acoustic bands) then it's just a matter of choosing between a USB mic and an XLR mic with an audio interface. Unless you're in a particularly noisy environment, I'd recommend some kind of condenser mic. The Blue Yeti has been the standard starter USB mic for years and you could do far worse than do that yourself. However, I would definitely recommend going down the slightly more expensive XLR mic and audio interface route as it's significantly more flexible and upgradeable.

You'll want a cardioid pattern large diaphragm condenser microphone (I love my Aston Spirit which looks and sounds great, but it's a multi-pattern mic and nearly Â£300 new). Brands like Rode, Aston and SE Electronics make great mics, and honestly, pretty much anything that comes up on an Amazon search for 'large diaphragm condenser microphone XLR' will still sound better than your laptop or webcam's microphone. You'll use a balanced XLR cable to connect that to your interface (a cheap cable's fine, more expensive ones with Neutrik brand connectors and the like might prove more durable and/or reassuring.)

With a single mic setup you only /need/ a really basic audio interface. Something like the Focusrite Scarlett Solo or 2i2 or any cheap class compliant USB audio interface will do the trick so long has it has phantom power available. Just plug your interface in, connect the mic, turn on 48v/phantom power and tweak the gain until, at your loudest you're not quite going into the red on the meters, select the interface in Zoom, turn on direct monitoring and you're good.

***** Fun with multiple inputs
If you're a band, or a guitarist where you want to adjust the balance between your voice and your guitar, you're going to need something a little more sophisticated. How much more sophisticated is up to you, of course and I'm a little out of my depth here, but I've got a few suggestions anyway. Don't hesitate to chat to any live sound engineers of your acquaintance -- buy the sound engineer at your local open mic a drink and quiz them, for instance.

The thing to remember here is that Zoom is pretty crap when it comes to audio handling -- it doesn't know anything about pro audio gear, it just expects to receive a mono mix on the first channel of the audio device you select (or a stereo mix on channels 1&2 if you turn stereo on in the audio settings), so you'll need to do the mixing yourself, either with a standalone mixer, the facilities of your audio interface or some other software on your computer.

I'm going to ignore the software option, but investigate software like Loopback on the Mac and Voicemeeter on Windows. Using your audio interface can be more or less easy, depending on what capabilities the interface has, of course. Modern interfaces are generally more capable in this area. I've not actually tried it, but something like the Zoom AMS-24 looks like it would be ideal for a guitarist (put it in 'streaming' mode and turn off loopback).

Once you get past a couple of input channels, you're going to have to go down the mixer route. You can either get a dumb mixer with at least as many inputs as you have instruments and mics, sort out your stereo mix and feed that into a simple two channel audio interface, which will make Zoom happy. That's fine if you're primarily interested in live performance, but if you want to do any recording, you'd be better off with a mixer that can also work as a multi-channel audio interface so you can record your vocals and instruments in separate tracks. Something like the Roland GigCasters or the RodeCaster II, for instance. I think Mackie do something in this space too, but I've not used any myself, but I do know there are plenty of options.

If your guitar's got a built in mic or pickup, just plug it into your mixer with a balanced cable, otherwise, you'll need to mic it up too. There's whole books written on mic placement, but it's generally accepted that a good starting point for micing an acoustic guitar is to point the mic at the place where the neck meets the body rather than at the sound hole, maybe a foot or so away. Again, if you know anyone with any audio engineering experience, then talk to them not me.

Once you've got your mixer, you'll need mics. Generally you'll be close miking things to allow you to mix the different sound sources (if you get lots of bleed between mics, then you have fewer options when it comes to mixing). In /theory/ you use a condenser mic for all these things, just put them close to your mouth or mic, turn the gain down and rely on the inverse square law to give you some separation. In practice, it's more common to grab a dynamic microphone or two and use them. The canonical mic for the job is probably the Shure SM58, which is built like a tank and looks exactly like you think a stage microphone should look. The SM57 is well regarded as an instrument mic too, and there's plenty of knock-offs of both. I have an SE Electronics V7, that I use for open mics which sounds pretty good too.

It /really/ helps to have someone else fiddling with the knobs to get your sound dialled in, because they're not hearing the sound in your head. With decent headphones on, they're primarily hearing the sound that's going through the mixer, so they can have a better chance of getting pre-amp gain dialed in, EQing your voice an instruments so they don't overlap too much and balancing your levels nicely. If /at all/ possible, get some help here.

EQing is a dark art that I'm only vaguely aware of, and mostly don't have to worry about anyway as an unaccompanied singer. I mostly just leave things flat and hope. There's plenty of advice to be found on YouTube or sites like Sound On Sound, so I recommend investigating those.

**** Lighting Suggestions

Again, there are entire books on this, and there's no end of gear you can buy if really fall down the rabbit hole. Elly Lucas made a great [[https://youtu.be/fYYzN2E8eX4]['Visual Content Level Up Tutorial']] that's a great starting point.

Seriously. Just watch that. I was going to write more, but she covers pretty everything I was going to say.

**** Cameras

If at all possible, don't use the webcam in your laptop. Investigate ways to use your phone as a webcam. Certainly that's possible if you're in Apple World -- Zoom can treat your iPhone as a webcam and the camera in your phone is substantially better than almost any webcam you can find. If you've got a mirrorless or dSLR camera, more recent ones often have software that lets you use them as a webcam -- check your manufacturers website. If they can't be used directly as a webcam, check whether they have what's referred to as a 'clean HDMI' output and look at getting a cheap and cheerful usb HDMI capture card (or spend rather more on something like the Elgato Camlink. I went with the cheap and cheerful option and it's fine).

Stick your camera or phone on a good solid tripod, wobbly cameras are really distracting. And level is great. You don't want people wondering why the things on your shelves aren't sliding off. Plain backgrounds make this less critical.

If you're shooting for a solo video, you probably want to frame things so you're slightly off centre in the frame. However, it makes life much easier for me setting up the Song Swap if you frame yourself in the middle of the shot. One of these days I might fix things so that's not necessary, but for now centred is best.



**** Set dressing

Plain walls are great. If you can arrange to hang something like a duvet behind you, that acts as quick and dirty audio treatment of your room. I have a duvet and a rug hanging behind me as a background and it definitely helps with the sound. Getting some distance between you and your background helps blur it a little and make it less distracting.

The advice on making your own headshot applies here as well.

*** What to expect
The aim of a song swap is to have a good old natter and sing a bunch of songs and to enjoy ourselves while we do it. It's not an interview, if only because I'm a terrible gobshite with a tendency to go off on tangents. Don't hesitate to tell me to shut up. I try to rein myself in, but every time I watch a show back I think "Yeah, you could have shut up a bit more there Piers."

If you're the sort who likes a set list, I'd suggest planning to cover as much material as you'd get through in a forty minute folk club set with maybe a couple of encore pieces. Nobody's run out of material yet.

It's a song swap tradition that the first question I ask a new guest is to ask them to talk about their first encounter with Martin Carthy, whether in person or recorded. Chris Manners memorably [[https://youtu.be/_wjZAKqdZdg][described first hearing Martin singing /The Bedmaking/ on the John Peel show]] playing a guitar 'hard enough to drive rivets through concrete walls' and rearranging his entire world. My first encounter was at the Soles and 'Eels folk club in Northampton. Everyone had hyped the gig up beforehand like it was the Second Coming and I bloody /hated/ it. Martin was great, as usual, I just wasn't in the right place to realise that. We're not about gatekeeping here though, so if you don't know who I'm talking about, let me know and I'll probably ask you how you came to discover you were a musician.


**** Payment
The show is supported by people chucking money in the virtual hat at [[https://ko-fi.com/pdcawley]]. On the following Monday, I tot up the total takings and send you half through the magic of Paypal.

** DONE Fiddling with structural templates in ~Org-mode~
CLOSED: [2025-08-27 Wed 21:59]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 20250827-fiddling-with-structural-templates-in-org-mode
:EXPORT_FILE_NAME: index
:END:

 #+begin_description
I spent a few hours reducing a small annoyance related to the way I use Emacs to maintain its literate configuration file by incrementally implementing slightly better processes until I reached the point where it was Good Enough to spend several more hours writing it up for the blog.

Not an elevator pitch for Emacs.
 #+end_description

I've been dealing with some enduring niggles in my literate Emacs configuration, and have just landed [[https://github.com/pdcawley/dotemacs/commit/dbc316bfca27a37319b5316ea1281ccbebd526aa][Commit dbc316b]], and I thought I'd write about it here because it's an example of what keeps me on Emacs more than thirty five years after I first started using it.

Back when I started, Emacs was merely a text editor that felt easier to use than =vi=, but these days, it's all that and more. I don't live in Emacs quite as much as I used to; I don't hang on USENET or IRC any more, and I check my email as little as possible, so I've not got around to configuring Emacs for that again.
#+begin_marginnote
Back in the day, it all went through the behemoth that is GNUS, but I lost that version of my =.emacs= file several computers and ISPs ago.
#+end_marginnote

These days, what I like about Emacs is it's malleability. It's not uniquely malleable, either. Vim and Neovim diehards will no doubt have tales to tell about their setups, but Emacs is my editor. There are  others like it, but this is mine.

I've been seduced by the Literate Programming idea of maintaining my [[https://github.com/pdcawley/dotemacs][=~/.emacs=]]
#+begin_marginnote
Emacs used to keep its config in a file in your home directory called =.emacs=, then it moved to =\~/.emacs.d/init.el=, which made it a little easier to break a big config out into multiple files. These days, Emacs looks first in =${XDG_CONFIG_HOME}/emacs=, which defaults to =\~/.config/emacs= and that's where my config files live today.
#+end_marginnote
file in a single =org-mode= file, which gets 'tangled' into =early-init.el= and =init.el=, which are the files that Emacs actually loads.

One feature of Org mode's literate programming support that I rather like and take advantage of is the ability to write things out of order and assemble them correctly using =noweb=. The idea is that ~src~ blocks can be named, and then referenced from other source blocks. For instance, you might have:

#+begin_example
,#+begin_src emacs-lisp
#+end_example
#+begin_src emacs-lisp
(dolist (template `(("t" "Task with annotation" entry
                     (file ,pdc/org-inbox-file)
                     "* %?\n:PROPERTIES:\n:created: %U\n:END:\n\n%i\n\n~ %a"
                     :prepend t)
                    <<capture-templates>>
                   ))
    (add-to-list 'org-capture-templates template t
                 (lambda (a b) (equal (car a) (car b)))))
#+end_src
#+begin_example
,#+end_src
#+end_example

which will eventually be tangled as a ~dolist~ that adds /all/ your capture templates to ~org-capture-templates~.

That ~<<capture-templates>>~ is what makes the magic happen. When we tangle =README.org=, the exporter gathers up the contents of any source blocks associated with the tag and replaces ~<<capture-templates>>~ with them
#+begin_marginnote
It applies some heuristics as well, which is why that ~dolist~ isn't indented exactly how it would be without the noweb reference, but you can read the docs to find out more.
#+end_marginnote

So, elsewhere in my =README.org=, I can keep capture templates related to a particular app close to the rest of the configuration of that app, where it makes sense to me. For example, in the section where I configure my blogging tools, I do this:

#+begin_example
,#+begin_src emacs-lisp :tangle nil :noweb-ref capture-templates
#+end_example
#+begin_src emacs-lisp
("b" "bofh.org.uk post" entry
 (file+headline ,(pdc-site-posts-file "bofh") "Posts")
 (function +org-hugo-new-subtree-post-capture-template))
#+end_src
#+begin_example
,#+end_src
#+end_example

Notice the header arguments. ~:tangle nil~ tells the exporter not to simply write the code out at the current position, and ~:noweb-ref capture-templates~ tells the exporter to instead write it out wherever it sees ~<<capture-templates>>~ in a source block.

We have to be careful to ensure that the including code gets run when and where all the values variables and functions used in the included fragment are in scope, which can be fiddly, but it's definitely doable.

{{{newthought(Which brings me to what I actually want to write about!)}}} I don't type all that ~#+begin_src â€¦~ stuff out by hand every time. Because doing that is simply asking for errors. Instead, I take advantage of an org feature called structure templates, so I have:

#+begin_example
,#+begin_src emacs-lisp :tangle nil :noweb-ref org-structure-templates
#+end_example
#+begin_src emacs-lisp
(add-to-list 'org-structure-template-alist <<org-structure-templates>>)
'("el" . "src emacs-lisp")
'("ett" . "src emacs-lisp :tangle nil :noweb-ref")
#+end_src
#+begin_example
,#+end_src
#+end_example

And, until slightly before I wrote this, I'd type =<el= at the beginning of a line, hit TAB and org would expand that to

#+begin_example
,#+begin_src emacs-lisp

,#+end_src
#+end_example

And =<ett= would expand to

#+begin_example
,#+begin_src emacs-lisp :tangle nil :noweb-ref

,#+end_src
#+end_example

Then I'd fill in the correct ~:noweb-ref~ and the appropriate code.

It was fine.

Well, it was better than typing it all by hand, but as soon as I'd expanded a template, I'd immediately hit =C-c '= to edit the code block in a separate buffer that was in the correct mode to edit Emacs Lisp (or whatever language the source block was for).

Eventually, I got annoyed enough by the repetition to work out how to make that happen automatically. Normally, I'd expect to add a function to a hook variable somewhere, but that doesn't quite work here. Time to break out the Swiss Army Knife that is ~advice-add~.

Here's my first take:

#+begin_src emacs-lisp
(defun +org-insert-structure-template/after-advice (&rest _)
  (when (derived-mode-p 'org-mode)
    (org-edit-special)))
(advice-add 'tempo-insert-template :after #'+org-insert-structure-template/after-advice)
(advice-add 'org-insert-structure-template #'org-edit-special)
#+end_src

We're adding advice to two different functions here, because there are two different mechanisms for inserting a structure template, either via the =<foo= expansion, or by calling =M-x org-insert-structure-template=, both of which I make use of on different occasions.

{{{newthought(This version lasted a while.)}}} It did 90% of what I wanted after all. Indeed, for most of my structure templates, it does 100% of what I want.

But there's always that one case, isn't there? Take a look at that =ett= template from earlier. Notice that it's missing the value to assign to =:noweb_ref=. In a perfect world, we should fill that in before we start editing the code. Or rely on remembering to do it after the fact. Because we /always/ do that, don't we?

So, this morning, that chunk of code looked a little like this.
#+begin_marginnote
I've had to reconstruct the code from memory, I'm afraid because it never made it into the git repo. You can call me sloppy if you like, but this is personal code written on my own time, so you can fuck off.
#+end_marginnote

#+begin_src emacs-lisp
(defun +org-insert-structure-template/after-advice (&rest _)
  (when (derived-mode-p 'org-mode)
    (let ((datum (org-element-begin datum)))
      (save-excursion
        (goto-char (org-element-begin datum))
        (when (re-search-forward
               "\\(:\\S-+\\)\\s-*$" (pos-eol) t)
          (let ((key (match-string-no-properties 1)))
            (end-of-line)
            (unless (looking-back "\\s-" 1)
              (insert " "))
            (insert (read-from-minibuffer (format "%s: " key)))))))
    (org-edit-special)))

(advice-add 'tempo-insert-template
            :after #'+org-insert-structure-template/after-advice)
(advice-add 'org-insert-structure-template
            :after #'+org-insert-structure-template/after-advice)
#+end_src

Because an org file is Just A Text Fileâ„¢, we could have written this using Emacs' basic buffer editing commands, but we'll take advantage of some of org and =org-babel='s helper functions to make life a little easier and (hopefully) to help me understand what I'm doing and why I'm doing it when I come back to the code later. Named behaviour is great
#+begin_marginnote
/Especially/ in a self-documenting editor like Emacs. If I'm not sure what a particular function in this code does, the documentation, or even the source code, is always a couple of keypresses away.
#+end_marginnote
for helping make code more understandable.

What we do here is save our place in the buffer, jump back to the very beginning of the source block and look at the header arguments. If they end with a property name (=:like-this=), then we deduce that more information is needed, so we use ~read-from-minibuffer~ to ask for it, add the answer to the end of the header arguments, jump back to wherever the template originally left us (by exiting the ~save-excursion~ block) and call ~org-edit-special~ to start editing the file in a dedicated buffer.

{{{newthought(Job jobbed\, no?)}}}

Wellâ€¦ kinda. See, we're filling in the value of =:noweb-ref= using an error prone free text value, rather than presenting a list of known noweb references to choose from. In the case where the unset parameter is =:noweb-ref=, we really want to use ~completing-read~. A quick trawl through the existing code didn't find a function to do what we want, nor did a web search. An org file's Just A Text File though, and ~org-babel-noweb-wrap~ returns a regular expression that will match a noweb reference in the current file
#+begin_marginnote
~<<reference>>~ is the default form for a noweb ref, but the delimiters are overridable. At one point, I was using ~Â«referenceÂ»~ rather than the defaults, so it's handy to have a function that deals with that for us.
#+end_marginnote
so we could save our place, jump to the beginning of the file and find every match for that regular expression and use that to build a ~completing-read~ candidates list. But =<<foo>>= is only a noweb reference if it's in a source block, so we could end up with a bunch of false positives. We want to search through every source block, ignoring the rest of the file. Surely there's already something in existence to let us do that since it's the sort of thing that happens during the process of tangling a file.

A quick =M-x describe-function org babel src block= yields a bunch of interesting functions, including the promising sounding ~org-babel-src-blocks~. The documentation reads:

#+begin_example
Signature
(org-babel-map-src-blocks FILE &rest BODY)

Documentation
Evaluate BODY forms on each source-block in FILE.

â€¦
#+end_example

It goes on to explain that the body is evaluated with some useful variables set. The one we're interested in is ~body~, which is a "string holding the body of the code block". Sorted.

With that, and other helper functions, we can write:

#+begin_src emacs-lisp
(defun +org-babel-noweb-refs ()
  "Find all the noweb refs in the current buffer."
  (require 's)
  (require 'dash)
  (let ((match-exp (org-babel-noweb-wrap))
        result)
    (org-babel-map-src-blocks nil
      (let ((plain-body (substring-no-properties body)))
        (setq result
              (-concat
               result
               (-map (-partial #'s-replace "(.*)\\'" "")
                     (-map #'second
                           (s-match-strings-all
                            match-exp
                            plain-body)))))))
    (-sort #'string< result)))
#+end_src

It's a bit unsubtle, but it's quick enough and accurate enough for my purposes. Then we can rewrite the relevant bit of our advice function along these lines:

#+begin_src emacs-lisp
(if (re-search-forward "\\(:\\S-+\\)\\s-*$" (pos-eol) t)
    (let* (arg (match-string-no-properties 1))
      (value
       (cond ((string= arg ":noweb-ref")
              (completing-read ":noweb-ref: "
                               (+org-babel-noweb-refs)))
             (t (read-from-minibuffer (concat arg ": "))))))
  (end-of-line)
  (unless (looking-back "\\s-" 1)
    (insert " "))
  (insert-value))

#+end_src

Note the use of ~cond~ here even though we could use a single ~if~. I'm making it easier to special case behaviour for header arguments other than =:noweb-ref=. I'm probably not gonna need it, but it's easy enough to be kind to the future me who /does/ need it.

{{{newthought(I'm sure your editor of preference)}}} can do something like this. If it can't, then why on earth do you put up with it? I know Emacs though, and it it's taken me longer to write about this whole process of eliminating a bump in my road than it did to implement the necessary functions and advice in the first place. I didn't even have to restart Emacs, and it remained usable throughout the process
#+begin_marginnote
The code was actually written within a source block
#+end_marginnote
but it got smoother and smoother with every step.

I'm not the first person to point out how powerful Just A Text File can be, especially if you've also got a huge pile of functions at your disposal to manipulate that file in useful ways and with mode specific semantics. Provided, of course, you've got decent tools to search through that pile. Emacs is just such a pile of useful functions and is a great tool for sifting through it. Give it a go, why don't you.

Take the time to look at how you use your editor. I'm sure some point of friction will come to mind. Then work out how to write some code that will make things a bit smoother. You're not looking for perfect here, you're looking for /better./ The remaining roughness will no doubt niggle at you enough for you to take another pass at sanding it down one day, but for now luxuriate in the fact you've made life a little better for yourself.

I'd suggest that, if you keep doing that as part of your practice, you'll eventually have your tools working exactly how you want them to. But I've been an Emacs user since 1988 and I've yet to reach that point. But it's about the journey, not the destination, isn't it?
** DONE Fetching webmentions again. With Emacs this time! :webmentions:indieweb:
CLOSED: [2025-09-07 Sun 17:17]
:PROPERTIES:
:EXPORT_HUGO_SLUG: fetching-webmentions-again-with-emacs
:EXPORT_HUGO_BUNDLE: 20250907-fetching-webmentions-again-with-emacs
:EXPORT_FILE_NAME: index
:END:

#+begin_description
I've reinstated webmention processing here and have semi-automated it with a pile of Emacs Lisp and a =Makefile=, so I thought I'd write up some of the gory details.

Part 1 ofâ€¦ some?
#+end_description

You might have noticed, if you're a regular visitor that webmentions have started showing up on the site again. I turned them off a while ago, {{{marginnote(I turned off the home server that was handling the web hook calls from Webmention.io, planning to quickly move it and spin it up again. Ask me how that's going.)}}} but [[https://aaronparecki.com][Aaron Parecki]]'s invaluable [[https://webmention.io][Webmention.io]] service has still been gathering them for me, so I've turned them back on. But in the mean time, I mislaid the code I was using to populate the necessary Hugo data files from Webmention. Exploratory code ahoy.

*** Start by faking it

I'm heavily indebted to [[https://masto.hackers.town/@randomgeek][Brian Wisti]] for his post, [[https://randomgeekery.org/post/2020/11/using-the-webmention.io-api/][Using the Webmention.io API]] as the starting point to my explorations, but since I can't be doing with Python, I used emacs.

I started with my very minor fork of [[https://github.com/pdcawley/restclient.el][=restclient=]]

#+name: wm-token
#+begin_src emacs-lisp :exports none
(setq restclient-response-body-only t)
(getenv "WM_API_TOKEN")
#+end_src

#+begin_highlight
#+name: last5
#+begin_src restclient :var token=wm-token()
# Grab the most recent 5 webmentions of bofh.org.uk
GET https://webmention.io/api/mentions.jf2?domain=bofh.org.uk&sort-dir=down&per-page=5&token=:token
#+end_src
#+end_highlight

Which produces the following JSON data:
#+begin_details
#+begin_summary

Disclose this for the full wall of JSON

Don't say you weren't warned!
#+end_summary

#+call: last5()

#+results:
#+BEGIN_SRC json
{
  "type": "feed",
  "name": "Webmentions",
  "children": [
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "Mike Spencer",
        "photo": "https://avatars.webmention.io/fsn1.your-objectstorage.com/3ba5a0fdc660c44995fef428a601770fd0fe2619fc1f8c7e70ec7e9e1da66d4b.jpg",
        "url": "https://mastodon.scot/@mikerspencer"
      },
      "url": "https://mendeddrum.org/@pdcawley/115162152891409560#favorited-by-109365771998686190",
      "published": null,
      "wm-received": "2025-09-07T09:35:22Z",
      "wm-id": 1936897,
      "wm-source": "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115162152891409560/109365771998686190",
      "wm-target": "https://bofh.org.uk/note/8/",
      "wm-protocol": "webmention",
      "like-of": "https://bofh.org.uk/note/8/",
      "wm-property": "like-of",
      "wm-private": false
    },
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "Jess Robinson",
        "photo": "https://avatars.webmention.io/fsn1.your-objectstorage.com/a11ee0a58e54873140bf1f1965900378d866fce3fafae79e116b979bea3a8773.jpg",
        "url": "https://fosstodon.org/@castaway"
      },
      "url": "https://mendeddrum.org/@pdcawley/115160370354067277#favorited-by-109562941096076318",
      "published": null,
      "wm-received": "2025-09-07T07:19:01Z",
      "wm-id": 1936873,
      "wm-source": "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115160370354067277/109562941096076318",
      "wm-target": "https://bofh.org.uk/note/7/",
      "wm-protocol": "webmention",
      "like-of": "https://bofh.org.uk/note/7/",
      "wm-property": "like-of",
      "wm-private": false
    },
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "Daniel Kelly Music",
        "photo": "https://avatars.webmention.io/fsn1.your-objectstorage.com/7aa4815cbc1f993c0e2a6df03280dc168f5ad07fecd0313ddfc27eeb02e0b437.png",
        "url": "https://aus.social/@yasslad"
      },
      "url": "https://mendeddrum.org/@pdcawley/115160370354067277#favorited-by-109307830089461078",
      "published": null,
      "wm-received": "2025-09-07T01:31:46Z",
      "wm-id": 1936817,
      "wm-source": "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115160370354067277/109307830089461078",
      "wm-target": "https://bofh.org.uk/note/7/",
      "wm-protocol": "webmention",
      "like-of": "https://bofh.org.uk/note/7/",
      "wm-property": "like-of",
      "wm-private": false
    },
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "Nick Anderson",
        "photo": "https://avatars.webmention.io/fsn1.your-objectstorage.com/856b210b0770a292a4f9e76699c84aa3833f9252716ad3cab58b50a7b57205ee.jpg",
        "url": "https://fosstodon.org/@nickanderson"
      },
      "url": "https://mendeddrum.org/@pdcawley/115107421781297473#favorited-by-109475479621313511",
      "published": null,
      "wm-received": "2025-08-28T21:48:52Z",
      "wm-id": 1934308,
      "wm-source": "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115107421781297473/109475479621313511",
      "wm-target": "https://bofh.org.uk/note/6/",
      "wm-protocol": "webmention",
      "like-of": "https://bofh.org.uk/note/6/",
      "wm-property": "like-of",
      "wm-private": false
    },
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "Nick Anderson",
        "photo": "https://avatars.webmention.io/fsn1.your-objectstorage.com/856b210b0770a292a4f9e76699c84aa3833f9252716ad3cab58b50a7b57205ee.jpg",
        "url": "https://fosstodon.org/@nickanderson"
      },
      "url": "https://fosstodon.org/@nickanderson/115108589417986943",
      "published": "2025-08-28T21:48:05+00:00",
      "wm-received": "2025-08-28T21:48:51Z",
      "wm-id": 1934307,
      "wm-source": "https://brid.gy/comment/mastodon/@pdcawley@mendeddrum.org/115107421781297473/115108589456284711",
      "wm-target": "https://bofh.org.uk/note/6/",
      "wm-protocol": "webmention",
      "content": {
        "html": "<p><span class=\"h-card\"><a href=\"https://mendeddrum.org/@pdcawley\" class=\"u-url\">@<span>pdcawley</span></a></span> I was gonna say, that looks like a source block within a source block which means there's another src block to make it render. Nice</p>",
        "text": "@pdcawley I was gonna say, that looks like a source block within a source block which means there's another src block to make it render. Nice"
      },
      "in-reply-to": "https://bofh.org.uk/note/6/",
      "wm-property": "in-reply-to",
      "wm-private": false
    }
  ]
}
#+END_SRC
#+end_details

The essential shape is something like this:

#+BEGIN_SRC json
{ "type": "feed",
  "name": "Webmentions",
  "children": [
    { "wm-target": "https://bofh.org.uk/note/8/",
      "wm-property": "like-of",
      ... },
    { "wm-target": "https://bofh.org.uk/note/8/",
      "wm-property": "in-reply-to",
      ... },
    ... }]}
#+END_SRC

Restclient is great for interactively exploring a RESTful API, but it's not so great for slicing and dicing the data in a Emacs-y way. I could sit down and learn =jq= again, but I know Lisp, dammit, so after a frustrating hour or so trying to wrap my head around the default ~url-retrieve~ interfaces, I went and grabbed the [[https://github.com/tkf/emacs-request][=emacs-request=]] package instead because I found its API more comprehensible.

Because ~request~ is a function where ~restclient~ is more like an application running in Emacs, it's way more useful for automating things. Here's more or less the same request as above done in Lisp.

#+name: request-mentions
#+begin_src emacs-lisp :var wm-api-token=wm-token()
(let (response)
  (request
    "https://webmention.io/api/mentions.jf2"
    :params `(("domain" . "bofh.org.uk")
              ("token" . ,wm-api-token)
              ("per-page" . "5")
              ("sort-dir" . "down"))
    :parser 'json-parse-buffer
    :sync t
    :success (cl-function
              (lambda (&key data &allow-other-keys)
                (setq response data))))
  response)
#+end_src

The code is obviously fiddlier, but it's also programmable and, because we set an arbitrary ~:parser~ function, it's trivial to convert the returned JSON into a native Emacs lisp hash table
#+begin_marginnote
It's not hard to generate an old school alist either, but that was annoyingly hard to serialise back to JSON, so I went with the default types because they seem to just work.
#+end_marginnote
which looks a bit like this:

#+begin_details

#+begin_summary
A wall of Lisp
#+end_summary

#+call: request-mentions() :results pp

#+results:
#+begin_example
#s(hash-table test equal data
              ("type" "feed" "name" "Webmentions" "children"
               [#s(hash-table test equal data
                              ("type" "entry" "author"
                               #s(hash-table test equal data
                                             ("type" "card" "name"
                                              "Mike Spencer" "photo"
                                              "https://avatars.webmention.io/fsn1.your-objectstorage.com/3ba5a0fdc660c44995fef428a601770fd0fe2619fc1f8c7e70ec7e9e1da66d4b.jpg"
                                              "url"
                                              "https://mastodon.scot/@mikerspencer"))
                               "url"
                               "https://mendeddrum.org/@pdcawley/115162152891409560#favorited-by-109365771998686190"
                               "published" :null "wm-received"
                               "2025-09-07T09:35:22Z" "wm-id" 1936897
                               "wm-source"
                               "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115162152891409560/109365771998686190"
                               "wm-target" "https://bofh.org.uk/note/8/"
                               "wm-protocol" "webmention" "like-of"
                               "https://bofh.org.uk/note/8/" "wm-property"
                               "like-of" "wm-private" :false))
                  #s(hash-table test equal data
                                ("type" "entry" "author"
                                 #s(hash-table test equal data
                                               ("type" "card" "name"
                                                "Jess Robinson" "photo"
                                                "https://avatars.webmention.io/fsn1.your-objectstorage.com/a11ee0a58e54873140bf1f1965900378d866fce3fafae79e116b979bea3a8773.jpg"
                                                "url"
                                                "https://fosstodon.org/@castaway"))
                                 "url"
                                 "https://mendeddrum.org/@pdcawley/115160370354067277#favorited-by-109562941096076318"
                                 "published" :null "wm-received"
                                 "2025-09-07T07:19:01Z" "wm-id" 1936873
                                 "wm-source"
                                 "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115160370354067277/109562941096076318"
                                 "wm-target" "https://bofh.org.uk/note/7/"
                                 "wm-protocol" "webmention" "like-of"
                                 "https://bofh.org.uk/note/7/" "wm-property"
                                 "like-of" "wm-private" :false))
                  #s(hash-table test equal data
                                ("type" "entry" "author"
                                 #s(hash-table test equal data
                                               ("type" "card" "name"
                                                "Daniel Kelly Music" "photo"
                                                "https://avatars.webmention.io/fsn1.your-objectstorage.com/7aa4815cbc1f993c0e2a6df03280dc168f5ad07fecd0313ddfc27eeb02e0b437.png"
                                                "url"
                                                "https://aus.social/@yasslad"))
                                 "url"
                                 "https://mendeddrum.org/@pdcawley/115160370354067277#favorited-by-109307830089461078"
                                 "published" :null "wm-received"
                                 "2025-09-07T01:31:46Z" "wm-id" 1936817
                                 "wm-source"
                                 "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115160370354067277/109307830089461078"
                                 "wm-target" "https://bofh.org.uk/note/7/"
                                 "wm-protocol" "webmention" "like-of"
                                 "https://bofh.org.uk/note/7/" "wm-property"
                                 "like-of" "wm-private" :false))
                  #s(hash-table test equal data
                                ("type" "entry" "author"
                                 #s(hash-table test equal data
                                               ("type" "card" "name"
                                                "Nick Anderson" "photo"
                                                "https://avatars.webmention.io/fsn1.your-objectstorage.com/856b210b0770a292a4f9e76699c84aa3833f9252716ad3cab58b50a7b57205ee.jpg"
                                                "url"
                                                "https://fosstodon.org/@nickanderson"))
                                 "url"
                                 "https://mendeddrum.org/@pdcawley/115107421781297473#favorited-by-109475479621313511"
                                 "published" :null "wm-received"
                                 "2025-08-28T21:48:52Z" "wm-id" 1934308
                                 "wm-source"
                                 "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115107421781297473/109475479621313511"
                                 "wm-target" "https://bofh.org.uk/note/6/"
                                 "wm-protocol" "webmention" "like-of"
                                 "https://bofh.org.uk/note/6/" "wm-property"
                                 "like-of" "wm-private" :false))
                  #s(hash-table test equal data
                                ("type" "entry" "author"
                                 #s(hash-table test equal data
                                               ("type" "card" "name"
                                                "Nick Anderson" "photo"
                                                "https://avatars.webmention.io/fsn1.your-objectstorage.com/856b210b0770a292a4f9e76699c84aa3833f9252716ad3cab58b50a7b57205ee.jpg"
                                                "url"
                                                "https://fosstodon.org/@nickanderson"))
                                 "url"
                                 "https://fosstodon.org/@nickanderson/115108589417986943"
                                 "published" "2025-08-28T21:48:05+00:00"
                                 "wm-received" "2025-08-28T21:48:51Z" "wm-id"
                                 1934307 "wm-source"
                                 "https://brid.gy/comment/mastodon/@pdcawley@mendeddrum.org/115107421781297473/115108589456284711"
                                 "wm-target" "https://bofh.org.uk/note/6/"
                                 "wm-protocol" "webmention" "content"
                                 #s(hash-table test equal data
                                               ("html"
                                                "<p><span class=\"h-card\"><a href=\"https://mendeddrum.org/@pdcawley\" class=\"u-url\">@<span>pdcawley</span></a></span> I was gonna say, that looks like a source block within a source block which means there's another src block to make it render. Nice</p>"
                                                "text"
                                                "@pdcawley I was gonna say, that looks like a source block within a source block which means there's another src block to make it render. Nice"))
                                 "in-reply-to" "https://bofh.org.uk/note/6/"
                                 "wm-property" "in-reply-to" "wm-private"
                                 :false))]))
#+end_example

#+end_details

Verbose as hell, but something we can work with. Here's a simplified alist representation which might be a little easier to understand.

#+begin_src emacs-lisp
'((type . "feed")
  (name . "Webmentions")
  (children
   . [((wm-property . "like-of")
       (wm-target . "https://bofh.org.uk/note/8/")
       ...)
      ((wm-property . "in-reply-to")
       (wm-target . "https://bofh.org.uk/note/8/")
       ...)]))
#+end_src

The interesting stuff lives under the ="children"= key, which we can get with ~(gethash "children" data)~.

To get all the webmentions for our domain, the Webmention API allows for pagination. We can ask for pages of, say 100 entries and if we get 100 entries back, append the result to our running collection of entries and request the next page. Once we get a result with fewer than 100 entries, we know we're done and we can massage the data into a shape that Hugo can cope with

*** Then turn what we learn into a commands

Now we know what the data coming from Webmention.io looks like, and how we can page through it, let's write a function, ~wm--fetch-all~ to do that for us.

#+transclude: [[file:./support-code/webmentions.el::wm--fetch-all]] :lines 1-38 :src emacs-lisp

The ~(while more? ...)~ loop keeps requesting more data until it gets a short response, at which point ~more?~ becomes false and we return the accumulated ~all-entries~ vector


*** And relax

We now have a handy list of all the webmentions relating to our site. The next step is to massage it into a data structure that will suit Hugo and export it as JSON files in the site's =data= directory. Which is a topic for another blog post, I think. If only because I'm reasonably sure that the data structure I'm currently using isn't great.

I'll hack it about a bit and report back.

* Notes :@note:
:PROPERTIES:
:EXPORT_HUGO_SECTION: /note
:END:
** DONE [2025-08-21 Thu 22:23]
ocnCLOSED: [2025-08-21 Thu 22:27]
:PROPERTIES:
:export_file_name: 1
:END:
I'm working on adding short notes without titles to the blog.

Basically something that maps neatly to Mastodon toots or Bluesky skeets. The chief difficulty will likely be styling them in a fashion that's consistent with the rest of the blog, but still compact

** DONE [2025-08-22 Fri 23:12]
CLOSED: [2025-08-24 Sun 11:42]
:PROPERTIES:
:export_file_name: 2
:END:

Notes appear to be working.
I have the horrible feeling that the CSS I'm using to style things is about as inelegant as it's possible to be, but things to seem to be looking okay in a decent array of viewport sizes. I'll call that a win.

** DONE [2025-08-24 Sun 11:38]
CLOSED: [2025-08-24 Sun 11:42]
:PROPERTIES:
:export_file_name: 3
:END:
I feel like I'm in a maze of twisty SCSS files and am getting very confuzzled. However, the layout's mostly working except in a narrow viewport, when the timestamp on a note happily fits in the left margin, but the timestamp on a post is truncated to the left because the font size doesn't seem to reduce as much. As far as I can tell, they're both the same size according to the stylesheet.

Ho humâ€¦ mostly working is better than not working. Check out the book cover thumbnails!

** DONE [2025-08-28 Thu 08:39]
CLOSED: [2025-08-28 Thu 08:39]
:PROPERTIES:
:export_file_name: 4
:END:
I confess that the blog is implying that it works with webmentions, but the infrastructure I used to display them isn't working at the moment. Fixing it's on the long TODO list that I might never get around to. However, the service that catches any webmentions is still in operation, so I'm not keen to remove it entirely.

Maybe I need to bump fixing things up the priority list.

** DONE [2025-08-28 Thu 08:59] :noteToSelf:
CLOSED: [2025-08-28 Thu 09:00]
:PROPERTIES:
:export_file_name: 5
:END:
I really should get around to replacing bloody GitHub.

God help me if I end up self-hosting my own instance of some code forge, but AI bollocks can fuck right off. I keep hoping that people are going to wake up and realise it's the very worst kind of emperor's new clothes bullshit, but they're taking their own sweet time about it.

** DONE [2025-08-28 Thu 17:30]
CLOSED: [2025-08-28 Thu 17:33]
:PROPERTIES:
:export_file_name: 6
:END:

This is absolutely what a sane person might write in their blog, isn't it?

#+begin_example
,#+begin_example
,,#+begin_src emacs-lisp :tangle nil :noweb-ref bibble
,#+end_example
,#+begin_src emacs-lisp
#+end_example
#+begin_src emacs-lisp
(setq some-variable 'some-value)
#+end_src
#+begin_example
,#+end_src
,#+begin_example
,,#+end_src
,#+end_example
#+end_example

And then doing this to their CSS to make it work

#+begin_src css
.highlight+.highlight {
    margin-top: 0;
}
#+end_src

I'm going to hell, aren't I?

{{{newthought(For bonus points\,)}}} see if you can work out what's /actually/ written in the source file for this note.
** DONE [2025-09-07 Sun 02:09]
CLOSED: [2025-09-07 Sun 02:11]
:PROPERTIES:
:export_file_name: 7
:END:
I /think/ I have webmentions displaying correctly again. However, we're updating everything manually again at the moment, at least until I get a webhook up and running again, so it might take a while for your replies, reposts &c. to show up on the site.

Still, it does appear to be working again.

** DONE [2025-09-07 Sun 09:19]
CLOSED: [2025-09-07 Sun 09:22]
:PROPERTIES:
:export_file_name: 8
:END:
Yay! Kicking it old school with a =Makefile= to automate building and deploying this site. I don't know if I can entrust it to a cron job yet because the deployment involves ssh, and I'm a bit fuzzy on the workings of key management in such circumstances
* Footnotes
:PROPERTIES:
:ID:       43822ABC-ED28-4066-82D3-040188E7A6E6
:END:
[fn:14] If you change anything in your setup, pedals, audio interface, looping software, monitoring, or anything that might conceivably affect the latency, expect to spend a little while getting dialled back in with the new setup. Remarkably tiny changes in latency can make a difference to the tightness of your loops, so don't be afraid to go back to the old 1,2,3,4 for a while.

[fn:13] I don't actually do that, because I have a slightly more complex setup that supports multiple song structures with the same set of clips. I'll explain all that later.
[fn:12] Real Tempest machines have a gorgeously weighted 'spinner' -- a free spinning rotary encoder with enough resolution that there still multiple 'steps' per tube segment. It meant that your blaster had a lovely fluid movement with very direct control. Basically, Tempest is pretty damned close to perfect on its original hardware and if you ever get the chance to play on a well maintained machine, you should grab it!


[fn:11] Check out @@hugo:{{< embed "https://youtu.be/hWPmADRfPFQ" />}}@@ for an example.

[fn:10] And a fancy dual-USB audio interface that means I can capture Loopy's audio really cleanly. Check out the [[https://www.amazon.co.uk/iConnectivity-AUDIO4c-Interface-Streaming-Performance/dp/B092L7TXL1?crid=2DB9Z9YW1UMFK&keywords=iconnectivity+audio4c&qid=1686042094&sprefix=iconnectivity+audio4c%2Caps%2C107&sr=8-5&linkCode=ll1&tag=justasummary-21&linkId=7d14e0bff14f201073ea18059f5abde5&language=en_GB&ref_=as_li_ss_tl][iConnectivity AUDIO4c]] (affiliate link) if that's a thing you might need. There are other dual-USB audio interfaces that are probably at least as good, but this is the one I've got experience of using.

[fn:9] I tried a few of the Zoom singarounds that sprang up, but for reasons I can't quite put my finger on, I found them far more stressful than just singing to the camer and interacting with an audience in text chat. The audio only Clubhouse ballad sessions that I started were way less stressy for me too.
[fn:8] Catch me every Friday night at [[https://youtube.com/pierscawley/live]] from 8pm UK Time.

[fn:7] Logic isn't really set up to do live sound, but MainStage, which is, can't do multi track recording and playback and I couldn't work out how to configure its looper to emulate that. So I just used Logic.

[fn:6] I used the delightfully named [[https://www.expert-sleepers.co.uk/augustusloop.html][Augustus Loop]] from Expert Sleepers combined with a Lua script I wrote to make it behave more or less the way I wanted it to. Kind of fiddly to set up, but repaid the effort. There's still a few things that AL can do that I can't do with Loopy Pro, but as I write those are due in the next big Loopy patch.

[fn:1] [[https://gohugo.io][Hugo]] is the static site generator I use to build this blog. Another example of letting the computer do all the fiddly repetitive bits. In this case, to handle all the fiddly bits of writing full HTML pages, building index pages and the rest.

[fn:2] It's also annoyingly temperamental at the moment; I'm working on that though.

[fn:3]  @@html:<dfn><code>org-mode</code></dfn>@@ is an Emacs outliner that grew into a calendar/outliner/spreadsheet/document processor/literate programming tool/dessert wax/floor topping.

It's what I used to use [[https://bofh.org.uk/2019/02/25/baking-with-emacs/][to manage my bakery]], and it's amazing.

Like Emacs itself, it's almost infinitely flexible, which makes it incredibly hard to get started with. There's oodles of org configurations out there to crib from and all of them are a mixture of the useful and irrelevant, because it turns out that people have different opinions about how they want to organise their writing and/or life. My config is very much under construction.

[fn:4] The Github Actions based build process is also substantially more reliable than the hand rolled server hook I was using. There's something to be said assembling your build pipeline from a bunch of stuff that lots of other people use (and maintain). Also, it reduces the number of moving parts on the Raspberry Pi that's serving these pages, which is no bad thing.

[fn:5] An @@html:<dfn>@@h-entry@@html:</dfn>@@ is something that a web user might want to mention. At present, all the h-entries on this site are articles, but other people use them to mark up photos, videos, notes, calendar entries or anything else that makes sense to think of as an entry in a collection of stuff. If you'll look at this page in your browser's inspector, you'll see that the content is wrapped in ~<article class="h-entry" â€¦>â€¦</article>~ tags. Other tags within that block are are marked with other classes (so the title has ~p-name~ and the body has ~e-content~), according to the definition of the [[http://microformats.org/wiki/h-entry][h-entry microformat]]. By marking my site up with these micropformats, life becomes much easier for any IndieWeb tools to extract appropriate information from the site.

* COMMENT Local Variables :ARCHIVE:
# Local Variables:
# org-log-done: 'time
# eval: (org-transclusion-mode)
# End:
