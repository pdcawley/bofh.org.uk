#+hugo_base_dir: .
#+export_hugo_weight: auto
#+startup: inlineimages
#+startup: show3levels
#+startup: logdrawer
#+startup: logdone
#+options: d:t
#+property: header-args:sql :session reporter :exports result :colnames yes :engine postgresql :results replace table
#+property: header-args: :exports code
#+hugo_paired_shortcodes: %table %marginnote %newthought
#+macro: newthought @@hugo:{{% newthought %}}@@$1@@hugo:{{% /newthought %}}@@
#+macro: marginnote (eval (concat "@@hugo:{{% marginnote %}}@@" (mapconcat 'identity (remove nil (list $1 $2 $3 $4 $5 $6 $7 $8 $9)) ", ") "@@hugo:{{% /marginnote %}}@@"))
#+macro: sc @@hugo:{{% $1 %}}@@
#+macro: <sc @@hugo:{{< $1 >}}@@
#+seq_todo: TODO(t) DRAFT(d) REVISING(r!) | DONE(D!) PUBLISHED(p!) CANCELLED(x@)

* Pages
:PROPERTIES:
:export_hugo_section: /page/
:export_hugo_custom_front_matter: :hiddenFromFeed true :nocomment true :nodate true :nopaging true :noread true
:END:
** DONE Site details
CLOSED: [2025-08-14 Thu 12:08]
:PROPERTIES:
:EXPORT_FILE_NAME: colophon
:EXPORT_HUGO_SLUG: colophon
:export_hugo_aliases: /colophon
:END:

#+begin_description
An overview of how the /Just A Summary/ sausage is made.
#+end_description

I built /Just A Summary/ with the [[https://gohugo.io/][Hugo]] static site generator. The marvellous [[https://mythic-beasts.com/][Mythic Beasts]] host it on one of their [[https://raspberry.com/][Raspberry Pis]].

The theme is a much messed with version of the [[https://github.com/edwardtufte/tufte-css][Tufte CSS]] theme for Hugo. The most recently maintained version of which is available at [[https://github.com/loikein/hugo-tufte]]
#+begin_marginnote
Many /many/ thanks to loikein for taking that on!
#+end_marginnote

In theory, we are fully [[https://indieweb.org/][IndieWeb]] enabled. In practice, I tend to let that stuff rust and then come back to it in fits and starts.

** DONE Joining Twitch as a viewer
:PROPERTIES:
:EXPORT_FILE_NAME: twitch-viewing
:export_hugo_slug: twitch-viewing
:EXPORT_DATE: 2022-03-24
:END:

#+begin_description
How to join Twitch
#+end_description

  There are multiple platforms available where you can watch and interact with people sharing music;  how to play their favourite video game; tips on sewing makeshift surgical masks; and a bewildering panoply of other stuff. If you're after carefully edited, scripted and polished stuff, then [[https://youtube.com][YouTube]] and [[https://vimeo.com/][Vimeo]] are the websites for you. If you're after something a little more loose and interactive, where you can ask questions and give immediate feedback and the like, then [[https://twitch.tv/][Twitch.tv]] could easily be Your Place.


*** Just watching anonymously
   You /can/ treat Twitch as just another TV channel -- find something that interests you and just watch. But, if you're anything like I was when I first started watching people playing [[https://dwarffortresswiki.org/][Dwarf Fortress]] to pick up tips on how to avoid killing all my dwarfs quite so quickly, you will end up wanting to ask questions. You might fancy chucking them the digital equivalent of a few coins, or paying a subscription to support their work. To do that, you're going to need a Twitch account.

A word to the wise; once you set up the account, Twitch will suggest (in manner that seems to imply that there is no alternative) that you download their desktop app. You don't need to do this. I have the Twitch app on my mobile devices, but on a desktop system, everything works brilliantly from the browser and I suggest you stick with that.

**** Signing up with Amazon Prime

   If you're an Amazon Prime subscriber, subscribe via [[https://twitch.amazon.com/prime][twitch.amazon.com/prime]] and Amazon will let you subscribe to one favoured Twitch streamer for free. You don't pay a penny, but they get paid as if you'd taken out a basic subscription. The only catch is that these subscriptions do not autorenew. You have to resubscribe every month, or subscribe to someone else if you feel like spreading the love.[fn:1]

**** Signing up without Amazon Prime

    No Amazon Prime? No matter, [[https://twitch.tv/signup][twitch.tv/signup]] is the place to go. It's a pretty straightforward free account. You can make a dedicated Twitch account (which would be my choice) or you can just login with Facebook.


*** Using your account

   Once you have an account, you can start to participate in the chat associated with the channels you're watching. You can follow people and get notifications when they come on line (I confess, I turn the notifications off, but my default page when I go to Twitch is [[https://twitch.tv/following/live][twitch.tv/following/live]], which shows me which of my favourites are online at the moment.

   Now you've got an account, there's nothing to stop you streaming yourself; if you are, in any way, a singer, I can't recommend downloading [[https://twitch.tv/sings/download][Twitch Sings]] and having a play. Lots of great karaoke tunes to have a crack at, join in with other singers and share duet seeds so they can join in with you, and if you fancy going live, there's a big friendly button down in the bottom left hand corner that will get you online with nothing extra to download. Find out if you enjoy yourself before fiddling with all the extra software.

   But you don't /have/ to stream; I was on Twitch for the best part of a year, just occasionally hanging in streamers' chats and passing the time of day before I bit the bullet and started to stream myself. Some corners of the site have rather more assholes per square inch than others (popular shooty bang games, I'm looking at you) but if you're like me and enjoy the crafty and artistic areas, you're going to find some really lovely communities to join. Just have a great time!

** DONE Wishlist
:PROPERTIES:
:EXPORT_FILE_NAME: wishlist
:export_date: 2024-08-01
:export_hugo_url: /wishlist
:export_hugo_aliases: /pages/about/wishlist /wish
:export_hugo_auto_set_lastmod: t
:END:

#+begin_description
Things Piers would quite like as birthday or Christmas presents
#+end_description

I used to keep an Amazon wishlist, but they only let you add things that can be bought from them. Screw that. Here's a list of things I'd really like.

I've broken the list into thematic areas and (roughly) into order of desirability in each of the sections (though not so much in the courses section).

*** Music and Streaming

This is the horribly expensive section. Sorry.

**** [[https://www.eastwoodsoundandvision.com/video/rode-rodecaster-video][RØDECaster Video]]

I've been running my YouTube streams with an ATEM Mini Pro ISO and it's great, but a tad fiddly for some of the things I want to do. The RØDECaster Video supports all the extra stuff I'd /like/ to do and it's audio features in particular are a substantial improvement.

I don't /need/ one of these -- my Mini Pro has been doing excellent service since I bought it -- but I really /want/ one.

**** +[[https://shop.funky-junk.com/shop/recording/microphones/condenser/solid-state/ear-trumpet-labs-myrtle-condenser-microphone/][Ear Trumpet Labs Myrtle]] Microphone+


ETL microphones look fantastic and are designed for the kind of music Emily and I make. In the US bluegrass and americana scene they're almost the de facto choice for small ensembles doing the old school 'bunch of performers around a single mic' style of performing.

I have one of these now. It gives me joy every time I use it. Sometimes, things really do bring joy.

*** A course of some description

There's so much to learn, isn't there?

**** Photography
I realise I'm never likely to set up my own darkroom, but I'd love to learn to use one so I can hire one occasionally. The Art House in Wakefield has a [[https://the-arthouse.org.uk/workshops/darkroom-printing-taster-session/][Taster Session]], as well as a [[https://the-arthouse.org.uk/darkroom-one-to-one/][Darkroom One-to-One]] option that looks very tempting, and Wakefield's close enough to Doncaster that their [[https://the-arthouse.org.uk/maker-spaces/darkroom/][Darkroom membership]] looks pretty handy too.

Not quite a traditional darkroom process, but I'd also love to learn [[https://highlandprintstudio.co.uk/classes/photopolymer-gravure/][Photogravure]], which is a cunning technique for printing photos on an etching press to gorgeous effect.

**** Music

Maddy Prior runs courses for singers at [[https://stonesbarn.co.uk][Stones Barn]] and there's always something on her list that looks tempting. Right now, the [[https://www.tickettailor.com/events/stonesbarn/1430214][Interpretation Work For Traditional Singers]] with Nancy Kerr joining Maddy in November looks rather tasty.

The singing courses at [[https://www.halswaymanor.org.uk/][Halsway Manor]] look great too, and Halsway's a lovely place.

**** Cookery

I've enjoyed [[https://rivercottage.net][River Cottage]] pig related courses, and could fancy one of their fermentation or curing and smoking courses.

I like to think I know what I'm doing with a knife, but a [[https://www.rutlandcookeryschool.co.uk/courses/knife-skills-full-day.html][Knife Skills]] course would go down well too.

**** Crafts

The Kitchen Knife making courses at [[https://craftcourses.com/]] look great.

*** Kitchen-y and Foodie Things
**** A meal in a fancy restaurant
I say "fancy," but mostly I mean "somewhere you love." The most important part of any meal is the company, after all. I'm more than happy to travel ludicrous distances for a memorable meal, with the caveat that the place needs to be wheelchair accessible for Gill.

**** [[https://michaelmayknives.com/product/chefs-knife-yorkshire-oak/][A Chef's Knife]] by Michael May

Michael May's a Sheffield knife maker who makes gorgeous knives. I have one of his pocket knives and it's always with me. He recently started making a range of kitchen knives as well, and they're spectacular. Any of his [[https://michaelmayknives.com/product-category/kitchen/][kitchen knives]] would be a delightful thing to have, but I'm an absolute sucker for a chef's knife.

Even if you're not thinking of buying one of these for me, check out the rest of the site and try to resist buying one for yourself -- you never know when you'll need a pocket knife that /really/ cuts.

**** [[https://www.amazon.co.uk/T-1-Kitchen-Sharpener-Version-Patented/dp/B0CNKQK9NV/][A Tormek T-1]] Kitchen Knife Sharpener

I'm not denying that this is complete overkill, but I do like a sharp knife, and I would be honour bound to sharpen any kitchen knife you brought to me for the foreseeable future.

**** Almost anything from [[https://souschef.co.uk][Sous Chef]]
I'm a sucker for a good cookbook. The chocolate and sweets collection is amazing, and I wouldn't say no to a [[https://www.souschef.co.uk/products/microplane-gourmet-extra-coarse-grater][Microplane coarse cheese grater]].

**** Almost anything from [[https://chocolarder.com/][Chocolarder]]
When we lived in Cornwall, we met Mike, the founder of Chocolarder back when he was making small amounts of chocolate in his garden shed and selling them at farmers' markets. I was a sucker for pretty much everything he made, but his [[https://www.chocolarder.com/shop/sea-salt-caramel-truffles/][Sea Salt Caramel Truffles]] were amazing. They still are. It's a little harder to impulse buy stuff from them now we're living up country again.

*** Stationery

There's something about a good pen and the paper to use it on. Lots of lovely stuff at [[https://cultpens.com][Cult Pens]], including:

**** [[https://cultpens.com/products/kaweco-liliput-fireblue-fountain-pen][Kaweco Liliput Fireblue Fountain Pen]]

The perfect fountain pen doesn't exist, but these are gorgeous and I'd love to have one in the pen loop of my pocket notebook. A fine nib, please -- I'll be using this with a small pocket notebook and writing small.

**** +[[https://cultpens.com/products/opus-88-mini-pocket-pen-fountain-pen-check][Opus 88 Mini]]+
Another pocket fountain pen option. Fine nib, please.

Got myself one. It's lovely, if a little chunkier than I expected.

****  [[https://cultpens.com/products/pilot-parallel-pen][Pilot Parallel Pen]]
Because sometimes, I just want to muck about with a really wide italic type nib

**** Rhodia [[https://cultpens.com/products/rhodia-rhodiarama-softcover-notebook-a5][Notebooks]] and [[https://cultpens.com/collections/rhodia-dotpad-notepads][Pads]]
Just the nicest paper for writing on with ink pens.

**** [[https://cultpens.com/collections/fountain-pen-ink][Ink]]
I'm still searching for the perfect sepia ink. Something that looks like it was written 200 years ago and has dried to the perfect dark brown. I have the horrible feeling that the only way to achieve that look is with some [[https://cultpens.com/products/kwz-iron-gall-ink-60ml][iron/gall]] concoction that's then been left for a long time so the original colour vanishes to be replaced by the permanent colour that comes from the iron/gall reaction. Any colour but green, really.

** DONE Tamlyn.co.uk
:PROPERTIES:
:export_hugo_slug: about/tamlyn-co-uk
:EXPORT_FILE_NAME: tamlyn-co-uk
:END:

#+begin_description
The domain tamlyn.co.uk is not for sale.
#+end_description

Hi, you ended up here because you visited tamlyn.co.uk, which is a domain my wife and I have been using for private email since 1998, but which we've never bothered setting up a website for.

It's possible that you were looking for the UK arm of [[https://tamlyn.com][Tamlyn.com]], which appears to be building supplies manufacturer based in Texas. If so, you should head on over to their UK site, [[https://tamlyn.uk][tamlyn.uk]].

By the way, if you're in Texas, maybe consider supporting the work of [[https://linktr.ee/lambda_legal][Lambda Legal]], [[https://outyouth.org][Out Youth]], [[https://www.myresourcecenter.org/community/lgbtq-youth-programs/][Resource Centre]] and other organisations working for LGBTQIA+ kids in the state.

** DONE About Piers
:PROPERTIES:
:export_hugo_slug: about
:EXPORT_FILE_NAME: about
:EXPORT_DATE: 2003-01-01
:export_hugo_aliases: /about
:END:

#+begin_description
A subjective description of Piers and their many virtues
#+end_description

*** Baker
I used to be a programmer. I was good at it, but I kind of grew to hate it as a means of making a living, so when RSI came calling and made it near-impossible to type for more than about half an hour before I had to take a 45 minute break, I got properly serious about breadmaking. So since Christmas 2017 I've been baking sourdough bread for money as [[https://loafery.co.uk][The Loafery]]. It's not (remotely) as lucrative as programming was, but it's infinitely more satisfying. And tasty.

Sadly COVID has done for the bakery, so I'm back to baking occasionally at home. My sleep pattern is delighted by this.

*** Programmer
I was a Perl programmer for well over 10 years, spent a few years as a Ruby programmer before returning to the Perl fold. These days, what little code I write is usually in some sort of Lisp.

*** [[http://flickr.com/photos/pdcawley/sets/807230][Photographer]]
Discovering that you are good at something is wonderful. I was working in Amsterdam on one of my first programming gigs and commuting back to England most weekends. One day, passing through duty free, I bought myself a cheapish Nikon SLR, loaded it up with black and white film and was almost immediately hooked. Through the simple expedient of burning lots and lots of film and ruthless editing of contact sheets, I got better at it.

Of the images in the portfolio linked to, only one was taken with that first camera; see if you can guess which one it is.

*** Singer
Singing is comfort food for my soul. Singing is something to be shared. And, because I sing traditional songs, I don’t have to worry about licensing issues if I want to distribute any recordings I make.

Traditional songs — free software for the soul.

Pretentious? Moi?

*** Cook

Mmm… Chinese food.

*** All round geek

Look: I have a weblog; I’ve had the same email address since 1996; I’ve never met the majority of my friends in person; I ran my bakery with Emacs; I’d rather spend an evening hacking on the laptop than watching TV. What else could I be?


* Posts
:PROPERTIES:
:export_hugo_section: post/
:END:

** Book Reports                                            :@book-report:
:PROPERTIES:
:export_hugo_custom_front_matter: :series "Book Reports"
:export_hugo_section: /book
:ID:       AE556F3E-BD2C-46E6-BE13-AD819A39EE6D
:END:

*** DONE Picks and Shovels, by Cory Doctorow
CLOSED: [2025-09-08 Mon 10:34]
:PROPERTIES:
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :work '((author . "Cory Doctorow") (title . "Picks and Shovels") (type . "Picks and Shovels"))
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :cover '((s . "https://covers.openlibrary.org/b/olid/OL57554724M-S.jpg") (m . "https://covers.openlibrary.org/b/olid/OL57554724M-M.jpg") (l . "https://covers.openlibrary.org/b/olid/OL57554724M-L.jpg"))
:EXPORT_HUGO_BUNDLE: cory-doctorow-picks-and-shovels
:EXPORT_FILE_NAME: index
:END:

#+begin_description
Cory Doctorow has an axe to grind.

Cory /always/ has an axe to grind, of course, but since the upshot of that is books like Picks and Shovels, then I'm okay with that.

This is the third Marty Hench thriller and it's a cracking read
#+end_description

[[https://craphound.com/][Cory Doctorow]] has an axe to grind.

This is, of course, nothing new. Cory's anger at The Way Things Are, and his revolutionary zeal to bring the whole towering edifice of modern capitalism tumbling down is what makes him Cory, and what makes his books so good to read.

This is the third of his Marty Hench techno thrillers, but chronologically the earliest. Marty's just out of accountancy school after his MIT degree was derailed because he discovered personal computers. He moves to Silicon Valley because of course he does and falls in with a punky crowd and does what he can to help three religious women liberate themselves and their customers from a deeply dodgy totalitarian company that's locking decent churchgoing folk across the country into an abusive pyramid scheme of a computer system.

He fails, of course.

@@hugo:{{%newthought %}}@@I could quibble@@hugo:{{% /newthought %}}@@ about some of the computer history/dates, but that would be to miss the point. I can't help noticing the occasional flub because that's the kind of geek I am, but I'm learning not to let it spoil my enjoyment of something.

Oh yeah—and thank god for this—Cory's got /way/ better at writing sex scenes over the years. I still shudder at the memory of some of the stuff in /Makers/,
#+begin_marginnote
Great book with some /skincrawlingly/ bad sex scenes. I can't even put my finger on why, I'm afraid.
#+end_marginnote
but he finds a decent balance here. The age gap thing is still there though. It seems to be a /thing/ for him. Not that I'm one to throw stones, being married to someone nineteen years older than me.


@@hugo:{{%newthought %}}@@Wil Wheaton just gets better and better@@hugo:{{% /newthought %}}@@ as an audio book narrator. He really gets inside Marty on this one. Frankly, I can't imagine ever reading Cory on paper so long as Wil's doing such a bang up job of narrating his books.

*** DONE A Wizard of Earthsea
:PROPERTIES:
:EXPORT_FILE_NAME: a-wizard-of-earthsea
:export_hugo_slug: a-wizard-of-earthsea
:export_date: 2019-05-30
:export_hugo_aliases: /2019/05/30/a-wizard-of-earthsea/
:ID:       DB913EAC-FB57-44B7-9645-DBD26957CE72
:END:
This was the first.

Before I read Tolkien at the suggestion of the wonderful Miss Reese, my teacher for my last year of primary school; before I pulled Diana Wynne Jones, Alan Garner, Susan Cooper and others from the shelves of Bawtry's small, but enchanting branch library; before Anne McCaffrey's DragonSong found me in my school library and set a fire in my imagination. Before all that, I read /A Wizard of Earthsea/ and it stuck with me.

#+hugo: more

I remember one Saturday with 50p in my pocket from singing for a couple of weddings at St George's church in Doncaster (25p for each wedding, paid cash in hand on the day. It always felt like a bonus after singing Bach's /Jesu Joy of Man's Desiring/ in the side chapel as the register was signed in the vestry and Magnus Black, the choir and organmaster, brought that beautiful tune dancing with such delicacy from in instrument that would shake the walls later as the happy couple left the church to Vidor's toccata and fugue).
#+begin_marginnote
That was if we were lucky. It was usually Mendelssohn – not bad, Magnus was far too good an organist for it to sound dull, but not a patch on Vidor.
#+end_marginnote
I was never one for saving, I'm still not, so I was straight round to Donny's nearest thing to a bookshop, the WH Smith in the Arndale in search of something to read. A voracious reader, I'd gone through all the /Swallows and Amazons/ and /Narnia/ books and I needed more. The cover of the second Puffin edition, with its white youth and bizzare half man half hawk fascinated me, so I handed over my 50p
#+begin_marginnote
The bibliography I found tells me that it probably cost 35p, so I no doubt bought a load of sweets as well – books and sugar have always been my vices.
#+end_marginnote
and headed home with my prize.

I read /A Wizard of Earthsea/ once or twice and loved it, but I've not reread it since. As a kid, I borrowed rest of the then trilogy from the library and found them rather hard going at  (my memory says that I found /The Tombs of Atuan/ a real slog. I got through it, but it took a couple of goes and at least one renewal to get to the end). A few weeks ago though, I went to the [[https://www.soundpost.org.uk/][Sound Post]] 'Modern Fairies' singing weekend and fell into conversation with [[https://terriwindling.com][Terri Windling]] about the books that had shaped me and I told her about my experience with the Earthsea trilogy and I thought maybe I'd been a little too young for them (I think I was eight or nine when I read AWoE, and maybe twelve when I read /The Tombs of Atuan/ and /The Furthest Shore/). I hadn't revisted them since. Terri made me promise to reread them and to let her know what I thought. So that's what I'm doing. Terri, this book report's for you. I owe you a few more and I promise I'll get to them.

By the way, if you've never read /A Wizard of Earthsea,/ there will be spoilers in this article. Read the book before continuing. It shouldn't take you long, and it's well worth the time.

It's not so much what happens in this story as the way it's told that left its impression on me. Earthsea is made of words – all stories are, of course – sung into being by Segoy. Words are power. A wizard spends a large part of his
#+begin_marginnote
The wizards are all men. There are female witches in the story, but at this stage of the tale they're definitely underpowered and untrustworthy compared to the men. Le Guin fixes this later.
#+end_marginnote
education learning the "the Deeds of heroes and the Lays of wisdom" and year under the Master Namer just learning the true names of things in the Old Speech: the language of dragons; the language in which the world was made. In the period when the book is set, there is written language, but I get the feeling that it's very much the preserve of the wise. Songs, orally transmitted, are how the people of the archipelago hold their history and Le Guin's language reflects that. Every sentence seems to have been shaped to be spoken, and beautifully so. I kept stopping and reading passages out because the words were just so... right.

I sometimes wonder who the tale's narrator is telling the story to. It's a question that can break a lot of first person SF and exposes lazy storytelling. If a book that's supposedly the product of a completely different culture or time feels like it's written for an early 21st century reader, it breaks the book for me.
#+begin_marginnote
Sometimes I don't care though. God alone knows why Bertie Wooster is telling the Jeeves stories, or who he's telling them too – I'm just very glad he's chosen to tell them at all.
#+end_marginnote
The language and idiom of /A Wizard of Earthsea/ seem entirely right and consistent. We learn so much about the world as Ged's story is told from things mentioned in passing. We know that this happened a long time ago and it's assumed we already know about /The Deed of Ged/, /The Creation of Ea/ and all the other songs, deeds and festivals that are referred to in passing through the book. At the end we are told that no songs have survived that tell how Ged came to terms with his shadow – the entire book is a footnote in a much larger story that's just out of reach. I'm reminded of the fact that we only have the Norse myths we know because an ancient Icelander worried that readers wouldn't recognize the allusions in the sagas and eddas, so they wrote down the bones of the older stories to help future readers understand. If Le Guin had left Earthsea at this point, all we would know of Earthsea would be the glimpses of it in this story. And what glimpses they are.

You can find echoes /A Wizard of Earthsea/ in so much subsequent fantasy literature. The possibility of a wizard being trapped in another, for instance. Pratchett plays with and develops this in the /Witches/ sequence of Discworld books, for instance. I loved this sentence though: "And no one knows how many of the dolphins that leap in the waters of the Inmost Sea were men once, wise men, who forgot their wisdom and their name in the joy of the restless sea." If I had the power to become a dolphin I wouldn't be keen to return to the body of a fat 51 year old with diabetes and a bunch of aches and pains that I try not to think about. You can keep your wisdom sometimes.

As a kid, I didn't really understand what was going on with Ged and his Shadow. It was easy to see myself in the ever noticed that he didn't have the same colour skin as me). I loved learning and especially /knowing/. It wasn't hard to take my undoubtedly superior intelligence
#+begin_marginnote
Yeah. I know. I must have been insufferable as a kid (and an adult, if I'm honest). First to stick their hand up in every class. Happy to "Well, actually..." at every opportunity.
#+end_marginnote
as analogous to a wizard's power. Then, though, the shape of the story confused me, especially the ending. Ged and his friend sail off the page. The sea becomes land. Ged steps off the boat and confronts the Shadow, addressing it with his own name. And the shadow disappears/merges with Ged. And they all live on to do the Deeds which are sung of them. What? Nine year old me had no /idea/ what was going on there, but the imagery stuck.

Now, of course, it all seems a clearer. Thesis. Antithesis. Synthesis. Ged does a terrible thing in his ignorance  and pride. In shame he runs from it, almost losing his humanity in the process. He is tempted by a dark power, but rejects it. A friend and teacher restores him to himself and tells him that running is the sure road to doom. He turns and chases his Shadow instead. Finally he comes to an acceptance that the Shadow is a part of himself and by giving it his name he reintegrates that part into himself and finally becomes a whole man. There you go – no need to read the book now.

Of course you need to read this book. It's language sings and the places and people it evokes are beautifully drawn. Rereading this after more than 30 years, so much was familiar. I would have said I'd forgotten almost all of it but the bare outline of the story and a few character names, but that stuff clearly went in deep and helped make me myself because as I read, the whole shape of the thing unfolded in my head. It was almost like recognising roads and pathways in a place you holidayed repeatedly as a kid, then didn't return for 20 years. Familiar and surprising at the same time. "Oh yeah, that's where Daniel used to live! And do you remember walking up there to buy ice creams at the village shop? Oh! I'd forgotten this view!"

Right... onwards to /The Tombs of Atuan./
*** DONE /Service Model/, by Adrian Tchaikovsky :sf:audiobook:
CLOSED: [2025-08-21 Thu 21:08]
:PROPERTIES:
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :work '((author . "Adrian Tchaikovsky") (title . "Service Model") (type . "book"))
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :cover '((s . "https://covers.openlibrary.org/b/olid/OL59424202M-S.jpg") (m . "https://covers.openlibrary.org/b/olid/OL59424202M-M.jpg") (l . "https://covers.openlibrary.org/b/olid/OL59424202M-L.jpg") (caption .  "<cite>Service Model</cite> by Adrian Tchaikovsky"))
:EXPORT_HUGO_BUNDLE: adrian-tchaikovski-service-model
:EXPORT_FILE_NAME: index
:END:

#+begin_description
A robot valet kills its master for no apparent reason, then heads off on a /Pilgrim's Progress/ to understand his malfunction.
#+end_description

I'm very late to Tchaikovsky's work and picked this up mostly because of an Audible recommendation. A very good recommendation it was too.

Charles is a robotic valet, and one morning, completely out of the blue, he slits his master's throat in lieu of shaving him and (eventually) sets off on a pilgrimage to find out why. The world Charles exists in is… broken and his journey to enlightenment is longer and stranger than he ever expected.

Charles is very definitely /not/ human and his motivations are not exactly what you and I might think of as motivations. He has a task list. He is programmed to work through it. That is all.

He doesn't want anything. He can't feel anything. Not fear, hope, surprise, disappointment. And he's okay with that. Well, he would be if "being okay with something" were something he could do.

Because of Charles' inhuman viewpoint, part of the pleasure of the book is working out what's going on that Charles is incapable of understanding.

It's been a long time since I read /Pilgrim's Progress/, but it's definitely the work that /Service Model/ reminds me of. Charles, despite murdering his master, is an innocent abroad, travelling through a series of encounters that he doesn't necessarily understand in an effort to clear his task list.

It's also bloody funny in a dry, despairing kind of way.

{{{newthought(I listened to the audiobook,)}}} read by the author, which I can recommend highly. Tchaikovsky's a great narrator with just the right level of emotional detachment, but the jokes still land beautifully. A very smooth listen.
*** TODO Captain Vorpatril's Alliance, by Lois McMaster Bujold
:PROPERTIES:
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :work '((author . "Lois McMaster Bujold") (title . "Captain Vorpatril's Alliance") (type . "Captain Vorpatril's Alliance"))
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :cover '((s . "https://covers.openlibrary.org/b/olid/OL25361837M-S.jpg") (m . "https://covers.openlibrary.org/b/olid/OL25361837M-M.jpg") (l . "https://covers.openlibrary.org/b/olid/OL25361837M-L.jpg"))
:EXPORT_HUGO_BUNDLE: lois-mcmaster-bujold-captain-vorpatril-s-alliance
:EXPORT_FILE_NAME: index
:END:

Continues the family saga

*** TODO Programming Ruby: The pragmatic programmers' guide, by Dave Thomas
:PROPERTIES:
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :work '((author . "Dave Thomas") (title . "Programming Ruby: The pragmatic programmers' guide") (type . "Programming Ruby: The pragmatic programmers' guide"))
:EXPORT_HUGO_BUNDLE: dave-thomas-programming-ruby-the-pragmatic-programmers-guide
:EXPORT_FILE_NAME: index
:END:
** Bakehouse Diary :@bakehouse-diary:
:PROPERTIES:
:export_hugo_custom_front_matter: :series "Bakehouse Diary"
:ID:       1704207D-154F-4BA2-A7AA-35585A21295E
:END:

*** Bakehouse Diary
:PROPERTIES:
:export_file_name: back-to-the-bakehouse
:export_date: [2018-02-01 Thu]
:export_hugo_custom_front_matter: :description "Back to the bakehouse" :series "Bakehouse Diary"
:ID:       A734F151-393D-4609-A408-8942FE197BBB
:END:

I know! It's been a while. But we're in! I have baked, and it was
good. There's still a ton of stuff to do (plumbing, mostly) but the
really important bits of kit are all in place and looking good.

We celebrated getting in by turning one of the decks up as high as it
would go and making lots of pizzas and a few loaves of bread.

#+attr_html: :width 100%
#+caption: An early pizza
[[file:./back-to-the-bakehouse/margherita-pizza.jpg]]

#+hugo: more

**** The story so far…
:PROPERTIES:
:ID:       9B5B244B-A654-4254-BCEA-9CE31C600321
:END:

In my [[file:/2016/11/11/taking-stock/][last entry]] (over a year ago, argh! Gill is /much/ better) the
oven and all my kit were still in my garage, up on blocks waiting for
Dad to build an A-frame so we could winch it up and assemble it. Which
happened, and we managed to get one section of oven up onto the base.
And there we stopped because the fully assembled oven is very tall, and
the A-frame isn't tall enough to accommodate a fully assembled oven +
the winch + space for the straps (and my garage roof isn't high enough
to accommodate a sufficently tall A-frame). Still, it allowed us to
start in on prEocess of breaking the heads of very old brass
machine screws and generally failing to get the oven beds out where
they could be cleaned. This was frustrating, but it's not like I was
unused to frustration.

Meanwhile, the bakehouse site moved again. We had thought it would be
a relatively easy (and thus cheap) matter to run the necessary 3-phase
power to the space, but it turns out there wasn't quite enough power
going to the building to support what we needed. That would mean a new
substation and some very expensive cable laying. So it wasn't going to
fly. Luckily, there is also an old cafe in the yard. And it already has 3
phase, and enough 3 phase at that. So we set about making that into a
bakehouse. A lick of paint; some new flooring; wider, taller doorways
so we could get the oven in. Minor stuff like that.

By now we're up to late spring of 2017. I'd given up on trying to
renovate the decks myself, so I got onto Martin Passey at [[http://becketts.co.uk/][Becketts]] and
arranged for them to sort out the electrics and replace the rusty
steel beds with ceramic ones instead, which are generally reckoned to
be the best choice if you want to make 'hearth' breads on the oven
floor. We just needed to work out how to get the oven from Doncaster
to Heywood.

Guess what? It wasn't straightforward.

When we picked up my oven from the Isle of Wight, we'd got it into a
large Luton bodied van with a tail lift, and it was kind of fine. I
suppose I could have hired another one, roped in a few volunteers and
driven it over myself, but the fact that we'd partially assembled the
oven was going to make that rather trickier than it could have been.
Disassembling it was going to be tricky too - after we got the straps
out from the top decks when we'd assembled it, we discovered we'd been
very lucky indeed, and the strap had /very/ nearly broken.

The best option was to get a flatbed truck with a Hiab or similar
hydraulic crane which would make short work of getting the oven up
onto the truck and off to be fettled. But the access (up a 10 foot
wide back lane) proved daunting. All the haulage companies I talked to
took one look at it and backed away, muttering darkly and making the
sign of the cross. "Get a bunch of strong Polish lads to carry it down
the alley and stick it on the back of a truck" was the best (but very
unofficial) suggestion. Not ideal.

So now it's July and I'm chatting to a fellow guest at my brother's
silver wedding anniversary about my shipping woes. "You want to talk
to Dan!" he said.

"Dan?"

"Yeah, [[http://www.danpunchard.co.uk/][Dan Punchard]]. He's great, he's moved a couple of lathes for me
with some really tight access."

"Thanks!"

My informant was not wrong. Dan was brilliant. We exchanged a few
emails and photos of the access and /bang/ the oven was off into the
tender loving care of Becketts for its electrical fettling and new
floors. And soon the money was flowing out of my savings as I bought a
new spiral mixer, wire cooling baskets, steel work table, scales (both
electronic for weighing ingredients into the mixer and a balance
scale, which is /still/ the fastest way of scaling dough when you
divide it), lots of [[https://www.bakerybits.co.uk/bakery-equipment/proving-baskets-and-cloths/wicker-baskets/heavy-duty.html][bannetons]] (probably not enough) from Bakery Bits,
workwear, flour, wire shelving, and a bewildering amount of janitorial
bits and bobs from [[https://nisbets.co.uk/][Nisbets]]. Fettling the oven wasn't exactly cheap,
but wow, do those baskets add up!

**** It's arrived, and it fits
:PROPERTIES:
:ID:       AD747BAF-5C59-4456-B10E-EC021530372C
:END:

On the 8th of December last year I sent mail Martin some mail with the
subject "It's arrived, and it fits!" and over the next couple of weeks
the rest of the stuff I needed to bake arrived and, on the 20th of
December, I fired up the mixer for batch of 16 loaves and what proved
to be far too many pizza doughballs.

On Friday 21st of December, I pulled my first loaves out of my ~40
year old oven, and /damn/, but they were good.

#+attr_html: :width 100%
#+caption: The first loaf
[[file:./back-to-the-bakehouse/first-loaf.jpg]]

**** What next?
:PROPERTIES:
:ID:       6006477E-9259-4548-BE06-AA284C35787B
:END:

Of course, no enterprise like this is ever finished, here's a
selection from my to do list.


***** Plumbing
:PROPERTIES:
:ID:       C3EF1AE5-0633-4355-9A9E-AADC63202AC2
:END:
A bigger sink! Water near the scale so I'm not carrying buckets
back and forth! A handwash basin!

***** Qualifications
:PROPERTIES:
:ID:       D2940478-569D-4A68-8A85-A3FB832E0DD7
:END:
Environmental Health Officers do like you to have a certificate
to show you're not a complete moron when it comes to hygiene.
Breadmaking is relatively low risk because everything gets so
very hot during the cooking process, but even so.

***** Refrigeration
:PROPERTIES:
:ID:       7C336767-BFD8-4C6F-AB3F-379D615EF2CF
:END:
Right now everything's at the ambient temperature, which can mean
staying in the bake house until the early hours in order to get
the loaves into the oven when they're perfectly proved. A better
approach would be to stick the dough into a retarder (big
fridge, racked for standard bakers' sheet pans) and bake them
first thing in the morning after a decent night's sleep. I have a
retarder, but transport is annoyingly tricky because it's 2m
tall, and should ideally be transported vertically too.

***** Fitness
:PROPERTIES:
:ID:       0599F968-72F3-467F-B4A8-5ADE5EBC6548
:END:
Right now, I can just about cope with two bakes a week, but if
I'm going to actually make money at this, I'm going to need to be
able to manage more. Hopefully, as I bake it'll improve my
fitness, so as demand grows I'll be able to meet it.

***** Marketing
:PROPERTIES:
:ID:       584A5EC0-B1AA-425F-80E1-071BE00980FD
:END:
Oh boy, do I suck at marketing? Still, the product is good and
there's nobody else in the local area making this sort of bread,
so I have a few advantages. I still haven't made a Loafery
website though. At least I have the loafery.co.uk domain.

***** Online ordering
:PROPERTIES:
:ID:       FD89D3AC-84C8-4884-B2B4-FA445111D76D
:END:
If I can get people ordering online, I can use that to produce
production schedules, and generally have a better idea of how
much to make on each bake day, which help minimise any wasted
bread. With two bakes done this year, I've sold every loaf - I'd
like to keep that up.

**** In the next bakehouse diary...
:PROPERTIES:
:ID:       6B4B05DF-007B-4559-ACFE-BB21BCEADA42
:END:
I'll talk about how a bake goes and the process of developing an
initial range of products, sourcing flour and other ingredients
and hopefully some news about online ordering.




*** DONE Running a bakery on Emacs and PostgreSQL
:PROPERTIES:
:EXPORT_FILE_NAME: baking-with-emacs
:export_hugo_slug: baking-with-emacs
:export_hugo_custom_front_matter: :series "Bakehouse diary"
:export_date: 2019-02-25
:ID:       92F8529F-9830-4DE4-8E26-61B606BAF48B
:END:

Just over a year ago now, I finally opened the bakery I'd been dreaming of for years. It's been a big change in my life, from spending all my time sat in front of a computer, to spending most of it making actual stuff. And stuff that makes people happy, at that. It's been a huge change, but I can't think of a single job change that's ever made me as happy as this one.

#+hugo: more

One of the big changes that came with going pro was that suddenly I was having to work out how much stuff I needed to mix to fill the orders I needed. On the face of it, this is really simple, just work out how much dough you need, then work out what quantities to mix to make that much dough. Easy. You can do it with a pencil and paper. Or, in traditional bakers' fashion, by scrawling with your finger on a floured work bench.

And that's how I coped for a few weeks early on. But I kept making mistakes, which makes for an inconsistent product (bread is very forgiving, you have to work quite hard to make something that isn't bread, but consistency /matters/). I needed to automate.

I'd been on one of Bread Matters' "Baking for a Living" courses and as part of the course materials had received a copy of a spreadsheet that could be used to go from a list of orders to a list of ingredients to mix alongside accurate costings and other useful bits and bobs. It was great and certainly opened my eyes to the possibilities for automation of this part of the job.

And then I tried to add a new recipe.

Spreadsheets aren't my favourite computational model so maybe it was just my lack of experience with them, but adding a new recipe was like pulling teeth; lots of tedious copying, pasting and repetition of formulae. It just seemed wrong, especially as the underlying computations were so straightforward (ish). There had to be a better way.

The key insight is that a bakery formula is so cliched that it can be represented as data. Here's the formula for seedy malt loaves:

| recipe           | ingredient       | quantity |
|------------------+------------------+----------|
| Small Seedy Malt | Seedy malt dough | .61 kg   |
| Large Seedy Malt | Seedy malt dough | .92 kg   |

Of course, that's not the full set of formulae, because it doesn't tell you how to make 'Seedy malt dough', but that's just another formula, which consists of flour, water, starter, salt and a multiseed 'soaker', where the starter and the soaker are the results of other formulae, which are (finally) made from basic ingredients.
#+begin_marginnote
With a certain amount of handwaving to deal with the fact that a starter is strictly made with flour, water and starter.
#+end_marginnote
I did consider reaching for the object oriented hammer at this point, but thought that I might be able to do everything I needed without leaving SQL. It was relatively straightforward to move the shape of the calculations in the Bread Matters spreadsheet into my database schema, the only real sticking point being the recursive nature of the formulae, but it turns out that recursive queries are a thing in modern SQL, albeit a little tricky to get absolutely right
#+begin_marginnote
A few bakes went a little weird before I finally got things sorted.
#+end_marginnote
first time.
If you're curious about the details of the schema, you can find it in my [[https://github.com/pdcawley/bakehouse][github repo]] for the bakery.
#+begin_marginnote
 And several of you seem to be, so I wrote [[file:/2019/03/04/recursive-sql-recipes/][another post]] with a bit more detail and some sample code.
#+end_marginnote
@@

So now, a few days before a bake, I'd setup my ~production_order~ table with the orders for the bake, and run a query on the ~production_list~ view to find out what I needed to mix when. And all was great. Well, sort of. I had to add a bit extra onto the quantities in the initial starter mix to allow for the bits that get stuck to the bowl and lost to the final dough, and it was all very well until I wanted to bake two days in a row (a bake is a two day process from mixing the starters on a Wednesday evening, through mixing, fermenting and shaping on Thursday to baking the resulting loaves at four on Friday morning). But, vitally, it was much, much easier to add and adjust formulae, and the limitations were no worse than the limitations of the spreadsheet. All was well.

It's the nature of business that you need to keep records. How much got baked? How much sold? Did we clean the floor? Were there any accidents? What sort? How do we prevent them next time? The list is endless. It all needs to be recorded, for both legal and pragmatic reasons. So I started a day book. This is just an .org file
#+begin_marginnote
 Org-mode is an amazing emacs package that's a sort of outliner/task manager/publishing tool/spreadsheet/diary/literate programming environment. It's bewilderingly capable, and is probably the primary driver of the emacs renaissance as people are coming to the editor for org-mode, and porting the rest of their environment - hence the rise of ~evil-mode~, the emacs vim emulation layer.
#+end_marginnote
Every day I come into the bakery, I run ~org-capture~ and I get a template for the day's entry in the daybook, which I fill in as the day goes on.

One of the features of org-mode is ~org-babel~, a literate programming environment, which lets me write something like:

#+name: 07CEE761-D52F-4A44-B4C6-4F6284D947BB
#+begin_src org
,#+begin_src sql
SELECT ingredient, quantity
  FROM bakehouse.production_list
 WHERE work_date = 'today';
,#+end_src
#+end_src

and then, with the cursor somewhere in the code block, hit ~C-c C-c~ whereupon Emacs will run that SQL against the bakery database and populate a table like:

| ingredient  | quantity |
|-------------+----------|
| Old starter |      1.3 |
| Water       |     2.08 |
| White flour |      2.6 |
| ...         |      ... |

If that were all org-mode did to assist, it'd be awesome enough, but the queries I make are a little more complex than that, the current version of the database understands about dates and can cope with overlapping bakes, but all that makes the queries a little more complex. Org-mode helps with that too, because I can file away snippets of code in a 'library of babel' and just reference them from the daybook. And I can set arbitrary variables at any point in the hierarchy of the document.

So I have a bit of code in my emacs config that tweaks the day's entry in a daybook like so:

#+name: 1A928B6D-FED5-44C5-9AD1-5E50181B0199
#+begin_src emacs-lisp
  (defun pdc//in-bakery-daybook? ()
    "Are we in the bakery daybook?"
    (equal (buffer-name) "CAPTURE-loafery-daybook.org"))

  (defun pdc/set-daybook-entry-properties ()
    "Set the properties we rely on in our boilerplated daybook queries"
    (save-excursion
      (while (not (looking-at "*+ [[:digit:]]\\{4\\}\\(-[[:digit:]]\\{2\\}\\)\\{2\\}"))
        (org-up-element))
      (let ((entry-date (first (s-split " " (org-entry-get (point) "ITEM")))))
        (org-entry-put
         (point)
         "header-args+"
         (format ":var work_date=\"'%s'\"" entry-date)))
      (org-babel-execute-subtree)))

  (defun pdc/org-capture-before-finalize-daybook-entry ()
    (when (pdc//in-bakery-daybook?)
      (pdc/set-daybook-entry-properties)))

  (add-hook 'org-capture-before-finalize-hook
            #'pdc/org-capture-before-finalize-daybook-entry)
#+end_src

It won't win any code beauty contests, but it does the job of setting a ~work_date~ variable for the day's entry and running any code in the subtree as part of the capture process. The capture template has lines like ~#+call:mixes()~, which call the stored code snippets, that reference the variable set in the current subtree and so make the query for the right day. This means that all I have to do to know what I should be doing when I get into the bakehouse is to run an org-capture and check the resulting entry in my daybook. Provided, that is, that I've added the appropriate rows to the database.

**** Next steps
:PROPERTIES:
:ID:       30E7B083-080A-45CC-AED5-A9D55E210170
:END:

The software isn't done, of course, no software ever is. But it's good enough that it's been managing my mixes without a hitch for the last few months, telling me what to pack for which customer and generally removing the need to work anything out with a pencil and paper. It's nowhere near as mature or capable of commercial production management software, but it fits me. I understand what it does and why, how it does it, the limitations it has and how to work around them. When it becomes annoying enough, I might sit down and work out how to fix it, but I'll do that when I'm in the right frame of mind. My current list of niggles looks something like this:

- Accounting :: The database already knows how to do costings based on raw ingredient costs etc, but I should probably be able to use it to keep my books as well, using ~org-ledger~
- Parametric recipes :: At a certain point, it becomes easier to mix a 'stiff starter' in my mixer than it is to just mix the usual wet starter by hand. This breakpoint comes at around 3kg of flour. Right now, I manage this by looking at the mixes for my starters and, if it looks like a lot, changing the order to use 2-stage versions of the formulae and running the query again. I think it should be possible to automate this through a more sophisticated query, but I need to work that out.
- Better scheduling :: things get weird if a batch of dough would be more than I can mix in a single go. Right now there are other physical limitations that mean that I simply can't make that much bread anyway, but once I get a few more bannetons and racks, this will become a much more pressing issue.
- Order management :: Right now, I manage orders through Postico talking to the database, which is okay, but a little frustrating in places. An autocompleting environment for orders within emacs would be a much neater way to manage things.

**** Putting the personal in personal computing
:PROPERTIES:
:ID:       EB0497C2-51A6-4452-8CEE-E587BE2AA695
:END:
Computers are amazing. They are versatile tools even if you don't know how to program them, because there's almost always an app for what you want, or something close enough that you cant work around its infelicities. It's quite remarkable the things that folks can do with their kit with no programming skill at all.

But... learn to program, and a whole other vista of possibility opens up to you. With good programmable tooling you're only really limited by your skill and understanding. Instead of accommodating yourself to your software, you can accommodate your software to you, and make the right functionality trade-offs for you. There's a brilliant commercial piece of music looping sofware I use that could be massively more brilliant if there were a way of picking up the tempo automatically from the first recorded loop - it would free me from having to sing to a click and generally make the whole process easier. The developers have other (understandable) priorities, like porting the app to windows. And they're not wrong to do so. There were folk clamoring for a windows version, and if a developer isn't making money from a commercial application, then development will stop. I'm definitely not complaining, the feature is not so dramatically necessary that I'm prepared to spend the time learning how to do real time music programming in order to implement it, but if I want software to dance to /my/ tune then doing it myself is the only way.

So... choose tools that let you program them. I choose emacs and PostgreSQL, you might choose vim and SQLite or Atom and a NoSQL database, or you might just live in your Smalltalk image. Once you start to see your computing environment as truly soft and malleable, you can do amazing things, assisted by a computer that is truly /yours/.


*** DONE "A recipe is just a directed acyclic graph…"
:PROPERTIES:
:export_hugo_slug: recursive-sql-recipes
:export_file_name: recursive-sql-recipes
:export_date: 2019-03-04
:export_hugo_custom_front_matter: :series "Bakehouse diary" :math true
:ID:       F00B26A5-3E3A-42EC-858E-77A47CA209E3
:END:

In [[file:/2019/02/25/baking-with-emacs][the last post]] I handwaved the way I represented bakery formulae in the bakery database, so here's a little more detail. It helps to think of a bakery formula as a node on a directed acyclic
#+begin_marginnote
If you ignore the fact that a starter is made of flour, water and starter. Which, of course, we're going to.
#+end_marginnote
graph with weighted edges, where the weights are literally weights. Here's the graph a for a  couple of products

# #+begin_src dot :file formulae.svg :exports none :results file :cmdline -Tsvg
# digraph G {
# rankdir=LR;
# node [shape=box];
# { rank = same; "5 seed soaker"; "80% starter"; }
# { rank = same; node [shape=ellipse]; "water"; "white flour"; "salt"; "malthouse flour";
# "5 seed mix"; }

# "Small Seedy Malt" -> "Seedy Malt Dough" [label="600g"];
# "Small White Wild" -> "Basic White Sour" [label="600g"];

# "Basic White Sour" -> "80% starter" [label="90%"];
# "Basic White Sour" -> "white flour" [label="100%"];
# "Basic White Sour" -> "water" [label="55%"];
# "Basic White Sour" -> "salt" [label="3%"];

# "Seedy Malt Dough" -> "5 seed soaker" [label="50%"];
# "Seedy Malt Dough" -> "80% starter" [label="45%"];
# "Seedy Malt Dough" -> "malthouse flour" [label="100%"];
# "Seedy Malt Dough" -> "water" [label="47.5%"];
# "Seedy Malt Dough" -> "salt" [label="3%"];

# "5 seed soaker" -> "5 seed mix" [label="100%"];
# "5 seed soaker" -> "water" [label="120%"];

# "80% starter" -> "white flour" [label="100%"];
# "80% starter" -> "water" [label="80%"];
# }
# #+end_src

#+results:
#+begin_RESULTS
[[file:formulae.svg]]
#+end_RESULTS

#+hugo: more

And here's how we represent that in the database
#+begin_marginnote
This table is the result of a query on my real database, where the quantities are in kg, as opposed to the graph representation which was handrolled and adjusted to use bakers' percentages which is how formulae are traditionally written.
#+end_marginnote
@@:

#+begin_comment
#+begin_src sql :exports results
WITH RECURSIVE f(name,ingredient,amount) AS (
  SELECT recipe, ingredient, amount
    FROM bakehouse.recipe_item
   WHERE recipe IN ('Small Seedy Malt', 'Small White Wild')
 UNION
  SELECT ri.recipe, ri.ingredient, ri.amount
   FROM f
   JOIN bakehouse.recipe_item ri ON ri.recipe = f.ingredient
)
select name, ingredient, format('%s kg', ROUND(amount, 2)) from f order by name;
#+end_src
#+end_comment

#+results:
| name             | ingredient                    | format  |
|------------------+-------------------------------+---------|
| Small Seedy Malt | Seedy Malt Dough              | 0.63 kg |
| Small White Wild | Basic White Sour              | 0.63 kg |
| Basic White Sour | Organic white flour           | 2.00 kg |
| Basic White Sour | Sea salt                      | 0.06 kg |
| Basic White Sour | Water                         | 1.10 kg |
| Basic White Sour | 80% starter                   | 1.80 kg |
| Seedy Malt Dough | 5 Seed Soaker                 | 4.00 kg |
| Seedy Malt Dough | Water                         | 3.80 kg |
| Seedy Malt Dough | Sea salt                      | 0.22 kg |
| Seedy Malt Dough | 80% starter                   | 3.60 kg |
| Seedy Malt Dough | Organic light malthouse flour | 8.00 kg |
| 5 Seed Soaker    | Water                         | 1.20 kg |
| 5 Seed Soaker    | 5 seed mix                    | 1.00 kg |
| Mother           | Water                         | 3.20 kg |
| Mother           | Organic white flour           | 4.00 kg |

Suppose we have an order for 8 Small White loaves. We need to know how much starter to mix tonight. We know that we need 0.63 kg of dough for each loaf, so that's a total of 5.04 kg of Basic White Sour. The formula for Basic White Sour makes a total of $1.10 + 1.80 + 0.06 + 2.00 = 4.96 \mathrm{kg}$ of dough. So we need to multiply each quantity in that formula by the weight of dough we need divided by the total weight of the recipe $(5.04/4.96 = 1.016)$. This is straightforward enough for flour, water and salt, which are basic ingredients, but we'll need to do a similar calculation to work out how much flour and water we'll need to make $1.016 × 1.8 = 1.829 \mathrm{kg}$ of starter. You can see how this might become a little tedious.

If I were going to be doing these calculations by hand, it would definitely pay me to normalize my intermediate formulae so they all made a total of 1 kg of stuff. But screw that, we have a computer, so we can make it do the work.

I'm going to simplify things a little (the real database understands about dates, and we need to know a little more about recipes, products and ingredients than will fit in the ~recipe_item~ table that describes the graph) but this should give you an idea of the recursive queries that drive production planning.

Let's introduce a ~production_order~ table, where we stash our orders

#+begin_marginnote
The real table has extra information about customers and order dates:
#+end_marginnote

| product          | quantity |
|------------------+----------|
| Small White Wild |        5 |
| Small Seedy Malt |        5 |

And that's all we need to fire off a recursive query.
#+begin_marginnote
I'm writing this using the literate programming capabilities of org-mode, so the code you see is being run against my production database, and the results are using my working formulae. Which is why we're not querying the real ~production_order~ table.
#+end_marginnote

#+name: 6A645983-A0FF-42B1-A9D8-A0756FCD1A45
#+begin_src sql
WITH RECURSIVE po(product, quantity) AS (
    SELECT 'Small White Wild', 5
  UNION
    SELECT 'Large White Wild', 5
), rw(recipe, weight) AS (
    SELECT recipe, sum(amount)
      FROM bakehouse.recipe_item
  GROUP BY recipe
), job(product, ingredient, quantity) AS (
    SELECT po.product,
           ri.ingredient,
           po.quantity * ri.amount
      FROM po
      JOIN bakehouse.recipe_item ri ON po.product = ri.recipe
      JOIN rw ON ri.recipe = rw.recipe
  UNION
    SELECT job.ingredient, ri.ingredient, job.quantity * ri.amount / rw.weight
      FROM job
      join bakehouse.recipe_item ri on job.ingredient = ri.recipe
      join rw on job.ingredient = rw.recipe
)
SELECT product formula, ingredient, ROUND(sum(quantity),2) quantity from job group by job.product, job.ingredient order by formula;
#+end_src

Which gives the following result:

#+results:
| formula          | ingredient          | quantity |
|------------------+---------------------+----------|
| Basic White Sour | Sea salt            |     0.09 |
| Basic White Sour | Water               |     1.72 |
| Basic White Sour | Mother              |     2.81 |
| Basic White Sour | Organic white flour |     3.13 |
| Large White Wild | Basic White Sour    |     4.65 |
| Mother           | Organic white flour |     1.56 |
| Mother           | Water               |     1.25 |
| Small White Wild | Basic White Sour    |     3.10 |

A quick sanity check seems to show this is correct (we're making 7.75kg of Basic White Sour, which tallies with the weights needed to make the loaves).
So what's going on in the query? In SQL, ~WITH~ is a way of giving names to your intermediate results, akin to ~let~ in a Lisp. We fake up a table to hold our production orders (~po~) and the ~rw~ clause is totals the weights of all our recipes (in the real database, it's a view). The magic really starts to happen when you use the ~WITH RECURSIVE~ form. With ~RECURSIVE~ in play, the last query is treated differently. Instead of being a simple two part ~UNION~ what happens is that we first run:

#+name: 729E572D-94B2-4170-8561-FA051EE59B22
#+begin_src sql
SELECT po.product, ri.ingredient, po.quantity * ri.amount
  FROM po
  JOIN bakehouse.recipe_item ri on po.product = ri.recipe
  JOIN rw on ri.recipe = rw.recipe
#+end_src

and call the results ~job~ and then run the second query, adding any extra rows generated to the results, and repeating that query until the result set stops growing. If we didn't have ~WITH RECURSIVE~ available, and we knew the maximum depth of recursion we would need, we could fake it by making a bunch of intermediate clauses in our ~WITH~. In fact, until I worked out how ~WITH RECURSIVE~ works, that's exactly what I did.

Have you spotted the mistake? I didn't, until a few bakes when horribly wrong.

Here's what happens when we have an order for 3 small loaves and two large ones

| formula          | ingredient          | quantity |
|------------------+---------------------+----------|
| Basic White Sour | Sea salt            |     0.02 |
| Basic White Sour | Water               |     0.41 |
| Basic White Sour | Mother              |     0.68 |
| Basic White Sour | Organic white flour |     0.75 |
| Large White Wild | Basic White Sour    |     1.86 |
| Mother           | Organic white flour |     0.38 |
| Mother           | Water               |     0.30 |
| Small White Wild | Basic White Sour    |     1.86 |

We're only making 1.86 kg of dough? What's going on?

It turns out that the way a ~UNION~ works is akin to doing ~SELECT DISTINCT~ on the combined table, so it selects only unique rows. When two orders end up requiring exactly the same amount of the 'same' dough, they get smashed together and we lose half the weight. This is not ideal.
#+begin_marginnote
It's /especially/ not ideal when you don't spot there's a problem and end up making far fewer loaves than you expect. Or on one /really/ annoying occasion, making a dough that was far too dry because we lost some water along the way. You can correct this during the mix, but it was a nasty shock.
#+end_marginnote
I fixed it by adding a 'path' to the query, keeping track of how we arrived at a particular formula. Something like:

#+name: 48148626-CBC5-4AF1-9E88-7821F8099F36
#+begin_src sql
WITH RECURSIVE po(product, quantity) AS (
    SELECT 'Small White Wild', 3
  UNION
    SELECT 'Large White Wild', 2
), rw(recipe, weight) AS (
    SELECT recipe, sum(amount)
      FROM bakehouse.recipe_item
  GROUP BY recipe
), job(path, product, ingredient, quantity) AS (
    SELECT po.product,
           po.product,
           ri.ingredient,
           po.quantity * ri.amount
      FROM po
      JOIN bakehouse.recipe_item ri ON po.product = ri.recipe
      JOIN rw ON ri.recipe = rw.recipe
  UNION
    SELECT job.path || '.' || job.ingredient,
           job.ingredient,
           ri.ingredient,
           job.quantity * ri.amount / rw.weight
      FROM job
      join bakehouse.recipe_item ri on job.ingredient = ri.recipe
      join rw on job.ingredient = rw.recipe
)
SELECT product formula, ingredient, round(sum(quantity),2) weight from job group by formula, ingredient order by formula;
#+end_src

This query gives us:

#+results:
| formula          | ingredient          | weight |
|------------------+---------------------+--------|
| Basic White Sour | Sea salt            |   0.05 |
| Basic White Sour | Water               |   0.83 |
| Basic White Sour | Mother              |   1.35 |
| Basic White Sour | Organic white flour |   1.50 |
| Large White Wild | Basic White Sour    |   1.86 |
| Mother           | Organic white flour |   0.75 |
| Mother           | Water               |   0.60 |
| Small White Wild | Basic White Sour    |   1.86 |

This time we're making 3.74 kg of dough, which is right.

In order to see what's going on, we can change the final ~SELECT~ to ~SELECT formula, path, ingredient, round(quantity,2) weight FROM job~, and now we get:

| formula          | path                                     | ingredient          | weight |
|------------------+------------------------------------------+---------------------+--------|
| Large White Wild | Large White Wild                         | Basic White Sour    |   1.86 |
| Basic White Sour | Large White Wild.Basic White Sour        | Mother              |   0.68 |
| Basic White Sour | Large White Wild.Basic White Sour        | Organic white flour |   0.75 |
| Basic White Sour | Large White Wild.Basic White Sour        | Water               |   0.41 |
| Basic White Sour | Large White Wild.Basic White Sour        | Sea salt            |   0.02 |
| Mother           | Large White Wild.Basic White Sour.Mother | Water               |   0.30 |
| Mother           | Large White Wild.Basic White Sour.Mother | Organic white flour |   0.38 |
| Small White Wild | Small White Wild                         | Basic White Sour    |   1.86 |
| Basic White Sour | Small White Wild.Basic White Sour        | Organic white flour |   0.75 |
| Basic White Sour | Small White Wild.Basic White Sour        | Sea salt            |   0.02 |
| Basic White Sour | Small White Wild.Basic White Sour        | Water               |   0.41 |
| Basic White Sour | Small White Wild.Basic White Sour        | Mother              |   0.68 |
| Mother           | Small White Wild.Basic White Sour.Mother | Organic white flour |   0.38 |
| Mother           | Small White Wild.Basic White Sour.Mother | Water               |   0.30 |

Which shows that we're considering two lots of Basic White Sour with exactly the same weights, but we (and more importantly, the database engine) know that they're distinct amounts because we get to them through different routes. Hurrah! The problem is solved and we can accurately work out what we should be mixing.

**** What's still missing
:PROPERTIES:
:ID:       868FF41D-EB97-4079-8710-EBBE6B50AB15
:END:

As a baker, I know  if I've got an order for bread on Friday, then I need to mix the starters on Wednesday night, then spend Tuesday mixing, fermenting and shaping the loaves, which will spend the night in the retarder ready to be baked at 4 on Friday morning. But the schema I've outlined here doesn't. In my full bakehouse schema, I have a few extra tables which hold timing data and such. In particular, I have a ~product~ table, which knows about everything I sell. This table knows holds info about how many I can make per hour of work and the bake time and temperature. Then there's a ~recipe~ table which holds information about how long a formula needs to rest.
#+begin_marginnote
This could be the bulk fermentation time if it's a formula for a dough or a starter, a proof time if it's a loaf, or a soaking time for a soaker (a soaker is usually a mixture of seeds or fruit and a liquid, usually water, but occasionally fruit juice or booze depending on the final product).
#+end_marginnote
The real queries take this into account to allow us to work back from the ~due_date~ of a real order to the day we need to do the work. If you want to dig into how I handle dates  you can check out the repository at [[https://github.com/pdcawley/bakehouse/]].


**** The perils of writing stuff up

Never write your work up for your blog. Especially if you're mostly happy with it. As I was writing this, I realised there's an annoying bit of code duplication that I think I can eliminate. In the current code, I repeat what's essentially the same query structure in a couple of different views, but the formula graph is essentially static unless I add or adjust a recipe. Now I'm wondering if I could make a materialised view that has enough information to shortcut the calculations for both making the production list (what needs to be mixed, when) and for working out my costings (to put a price on a loaf, you need to know how much the raw ingredients cost, and that involves walking the tree again. Maybe a table like:

| product          | sub_formula      | ingredient  | factor | lead_time |
|------------------+------------------+-------------+--------+-----------|
| Large White Wild | Basic White Sour | White Flour |  0.403 | 1 day     |
| Large White Wild | Basic White Sour | Salt        |  0.012 | 1 day     |
| Large White Wild | Basic White Sour | Water       |  0.222 | 1 day     |
| Large White Wild | Basic White Sour | 80% Starter |  0.462 | 1 day     |
| Large White Wild | 80% Starter      | White Flour |  0.288 | 2 days    |
| Large White Wild | 80% Starter      | Water       |  0.173 | 2 days    |

If we have that table, then two days before our bread is due, if we have an order for 10 white loaves, we'll need to mix \(9.3 × .288 \approxeq 2.68\) kg of flour and $9.3 × 0.173 \approxeq 1.61$ kg of water. Which we can do with a simple non-recursive ~SELECT~. Something like:
#+begin_marginnote
NB: I've not tested this because I don't have the precalculated table, but it seems like it should work. In fact, thinking about it, we could probably build the ~precalc~ table so that we can simply do ~precalc.factor * po.quantity~, since any change that affects recipe weight will also affect our precalculated table.
#+end_marginnote
@@

#+name: A9B65C0A-2496-4A3B-B0FB-8AEBE9B5BE6A
#+begin_src sql
WITH weighted(formula, ingredient, weight, due) AS (
    SELECT precalc.sub_formula,
           precalc.ingredient,
           precalc.factor * po.quantity * rw.weight,
           po.due_date - precalc.lead_time
      FROM precalc
      JOIN production_order po ON precalc.product = po.product
      JOIN recipe_weight rw ON precalc.product = rw.recipe
)
  SELECT formula, ingredient, sum(weight)
    FROM weighted
   WHERE due = 'today'
GROUP BY formula, ingredient
#+end_src

We can use the same table to calculate the raw material costs for a given recipe, using a simple non-recursive query too.

I think, however, I'm going to leave it alone until I have to write another recursive view that walks the same graph, at which point I'll bite the bullet and do the pre-calculated version.




** Week Notes :weekNotes:
:PROPERTIES:
:export_hugo_custom_front_matter: :series Week Notes
:END:
*** 2023
**** DONE Week ending 2023-07-16
CLOSED: [2023-07-16 Sun 18:32]
:PROPERTIES:
:export_file_name: week-ending-20230716
:export_hugo_slug: week-note
:END:
Small victory of the week: I'm starting to get on top of the washing

#+hugo: more

***** Tuesday

Overwhelm had left us with a huge pile of washing to do, filling the sink, the draining board, and various work surfaces and I kept putting off tackling it because my brainweasels just saw the sheer amount of work involved and shut down. No fun. Anyway, Gill grabbed her perching stool and set to and before I knew it there was a full dishwasher burbling away, an empty sink, a full draining board and the beginnings of a system to keep it that way. The goal is to keep the sink empty and the draining board full. Before I cook, I clear the draining board. Any pans I use go in the sink and the next time I make tea, I wash up what's in the sink and anything that's still not been done of the mahoosive pile, until there's a full draining board again. Next time I'm brewing up, I can put the dry stuff away and, if I have the spoons, chip away at some more of the pile (though, post-COVID, I rarely have the spoons for much -- I can only stand for so long).

It's not perfect, but it gets stuff done, and I'm calling that a win.

***** Wednesday

Emily came over for rehearsal and Carcassonne. It was mostly Carcassonne, if I'm honest, but /The Housewife's Lament/ is starting to seem like we've learned it, as is /We'll Sit Upon The Gate,/ though that one feels like it could use another verse. /The Mary Ellen Carter/ is pretty damned solid too, which is good.

We set a new record city score in Carcassonne too, managing to share a 105 point city. We even managed my first ever draw in the second game.

***** Friday

A solo stream this week. Again with the Overwhelm getting in the way of getting more guests booked, but I'm starting to fill the diary again, which is good. I've got Alex Cumming as my guest in a couple of weeks, and Helen Edwards, Talis Kimberley, Emily, and a folk legend who will remain nameless for the time being lined up for August and September.

Loopy Pro was mostly rock solid. The one-shot overdub whine cropped up once, and there was a hard crash to the home screen at one point, but a restart was fast and clean. Perils of running beta versions of sofware, I guess.

***** Saturday

I toddled over for the morning and afternoon sessions at the Bradfield Traditional Music Weekend -- spent a happy few hours singing Americana (I sang /Cabin in Glory/ and /We're Gonna Camp a Little While in the Wilderness/ which seemed to go down well) in the first session, then there was a lovely, ballad heavy, song session. I sang /Tamlyn/ about as well as I've ever sung it, and it went down really well. I was knocked out by a cracking version of /The Famous Flower of Serving Men/ in particular, but the whole session was great.


***** Sunday

Dim sum at the China Palace for lunch with Dougal & Liz, Matt and Jo and a few of the kids. Excellent as always. We may have overordered

I'm off to the closing session of BTMW later. I suspect it will be as good as the Saturday sessions.


**** DONE Week ending 2023-07-23
CLOSED: [2023-07-23 Sun 21:37]
:PROPERTIES:
:export_file_name: week-ending-20230723
:export_hugo_slug: week-note
:END:

Small victory of the week: Actually got off my arse and did something about selling off my old /Magic the Gathering/ cards. For my next trick, I hope to do the same with my collection of [mostly card] magic books.

#+hugo: more

***** Tuesday
Made a capture template for adding a week note. Support functions are currently not the prettiest, and don't deal with a bunch of corner cases, but they seem to work for my case, so I'll leave 'em be for the time being. I plan to write it up in a longer post, and that will no doubt tweak my coder pride enough to make things suck a little less.

Oh god, once I start fiddling with my Emacs configuration, it's impossible to stop!

***** Wednesday
Nipped over to Mum and Dad's for lunch at Zini's, and to borrow dad's drills for my on going cigar box MIDI controller project. Managed to get eight holes accurately placed enough that I only had to drill 7.8mm holes for the M7 threaded rotary encoders I'd soldered to my stripboard. I'm calling that a win! Next trick, get the microcontroller wired up and appropriate software written.

Also discussed making PID controller I promised to make dad for his heat treatment setup a while back. A Pi Pico and one of its mini displays looks like it should do the job nicely. The plan is to make an extension cable with an SSR as a separate bit of kit, then control that from the prototype controller. Once they're working as separate parts, we can work out how to bring it all into one container. I shall wuss out of making the kind of thing I saw in a commercial radio controlled plug, which powered the control circuit with a very simple capacitor based power supply, with the slightly worrying wrinkle that the controller's 0V line was floating at around 5V below mains Vmax. Clever, sure, but scarier than I'm prepared to work with.

***** Friday

Holy crap, but old /Magic the Gathering/ cards are getting horrifically pricy. According to the buy list of the shop I just took my cards in to, I should be expecting about £400 for just four of my cards. And probably another couple of hundred for the two dual lands (assuming they're not from the Unlimited set, in which case they're worth a /lot/ more). All being well that's covered the cost of getting my grandfather's old recliner reupholstered and fixed.

If I could be arsed with it, I could probably get a lot more by selling direct on eBay, but I was already losing the will to live just sorting things out to take in to the shop.

Do /not/ ask me about the /Tabernacle at Pendrell Vale/ and /Black Lotus/ that I sold far too early, because that might make me grumpy.

**** DONE Week ending 2023-07-30
CLOSED: [2023-07-30 Sun 22:48]
:PROPERTIES:
:export_file_name: week-ending-20230730
:export_hugo_slug: week-note
:END:

Three weeks on the trot. Definitely calling that a win.

Also, Good Omens 2 is a delight. Still enough of Terry's character hanging
around it, and the new writers help it not feel too Neil-y.
#+hugo: more

***** Wednesday

After a bit of fiddling, I've worked out how to add helpers to the Emacs `C-x 8` keymap, so now I have shortcuts for typing 'λ', '🙂' and various other characters that I type more or less frequently. Beats the crap out of doing `C-x 8 <ret>` and then typing out the name of the character I'm looking for.

In case you're interested, here's the code:

#+begin_src emacs-lisp
    (general-define-key
      :keymaps 'iso-transl-ctl-x-8-map
      ". ," "…"
      ": )" "🙂"
      ": D" "😀"
      "; )" "😉"
      "\\"  "λ"
      "a ^" "↑"
      "a u" "↑"
      "a v" "↓"
      "a d" "↓"
      "a |" "↕")
#+end_src

If you're not using `general`, but you've got `use-package` installed, you can do something similar with `bind-keys`:

#+begin_src emacs-lisp

  (bind-keys
   :map 'iso-transl-ctl-x-8-map
   (". ," . "…")
   (": )" . "🙂")
   (": D" . "😀")
   (":|"  . "😐")
   ("; )" . "😉")
   ("\\"  . "λ")
   ("a ^" . "↑")
   ("a u" . "↑")
   ("a v" . "↓")
   ("a d" . "↓")
   ("a |" . "↕"))

#+end_src

You can no doubt use define-key as well, but I find `general` or `bind-keys` to be much nicer to work with. The latter has the advantage that it's included in Emacs as part of `use-package` and plays nice with `which-key`, so I might go and redo my key bindings and get rid of `general`, nice as it is, since the real selling point of that library is how easy it is to bind stuff in `evil-mode` states.
***** Sunday

I still miss /Twitch Sings./ It's how I started streaming—long before the Friday night Song Swaps and folk streams. I'd be happily belting out Lady Gaga's /Bad Romance/, hamming it up to /You Spin Me Round/ or giving it my best Johnny Cash
#+begin_marginnote
Not a particularly good impression. I can't get that low!
#+end_marginnote
on /Hurt./ It was just huge fun and a great way to make friends on Twitch.

Twitch ended up pulling the plug because it was a free app and… well, free apps and sync rights really don't play well together.

You'll still find people doing Karaoke on Twitch though, many of them the same faces I met back in /Twitch Sings/ days. This morning, I woke up early and spotted some friends Karaoke-ing it up on a Discord, so I pulled on pyjamas and went and joined 'em for a few songs. These days, I just use [[https://loopypro.com][Loopy Pro]] rather than searching YouTube for backing tracks. It's great fun though, and definitely makes for a more enjoyable way to spend the occasional hour or so of early morning insomnia.

Singing in company, even virtual company is still the best thing you can do in public with your clothes on. I encourage you all to sing more. What's the worst that could happen?
**** DONE Week ending 2023-08-13
CLOSED: [2023-08-14 Mon 09:02]
:PROPERTIES:
:export_file_name: week-ending-20230813
:export_hugo_slug: week-note
:END:
Oops, missed a week; seems I didn't have anything interesting to say, or I was too busy doing stuff to write about it. Probably the former.

Not a bad week, this week. My step daughter and her family called in on their way back from holiday on Friday night and we spent a pleasant evening with them and a few Cawleys who were knocking about, sat outside the Wool Market. Mostly good food, but apparently the Greek place isn't that good. Rustic Pizza is still good though.

#+hugo:more
***** Friday

Most of the proceeds of my /Magic: The Gathering/ cards will be spent on repairing my grandfather's recliner. But... I wouldn't be me if I didn't spend some of it on something gamelike. So I bought myself a 'GameDad'. In my case, an [[https://anbernic.com/products/rg353v-rg353vs][Anbernic RG 353VS]] and it's a hell of a thing. Not much bigger than an old school Game Boy (and /cheaper!/ Not just in real terms, but the Game Boy launched at $89.99 and I got mine for $87.99), but with a large, bright colour screen and enough grunt to play SNES and PlayStation games at full tilt. Apparently, you can even make it play Nintendo 64 stuff, but not necessarily at full speed.

I don't really care about emulating consoles I never owned though. I want to play /Manic Miner/, /Tempest/, /Dig Dug/, /Galaxians/ and the other games that gladly ate my pocket money, ten pence at a time, down the local arcade (the building's still there in all it's new brutalist concrete glory, but the arcade where I boggled at /I, Robot/ and thrilled to the exploits of the masters of /Defender/ and /Robotron/ is long gone).

So, in search of that heady thrill and those unmistakable sound effects, I've been frequenting archive.org's library of delights and installing a few of my old favourites.

The first to get seriously played was my old favourite /Tempest/ -- Atari's miracle of colour vector graphics where you controlled a spiky yellow thing running around the top of a blue tube shooting the terrifying geometric shapes that were climbing up towards you with deadly intent. When I first started playing it, I'd hold the fire button down and spin madly round the top of the tube and die all too quickly. But it was such fun I'd just shove another coin in the slot until my money was all gone. Then, in an arcade in Whitby, I watched someone playing the game in an entirely new way and my mind was blown. The walls weren't blue! The colours were different and there were new, scary shapes. This guy wasn't spinning around, and he wasn't just holding down the fire button either.

Tempest was unusual for the time in that it had autofire. If you held down the fire button on most games of the era, you'd fire one shot, then nothing would happen. But in Tempest, you'd autofire bursts of eight missiles, then a slight pause and the cycle would repeat. And it was the slight pause that would kill you. The Whitby guy had sussed that out and was mashing the fire button at a measured speed that kept up a constant stream of evenly spaced bullets that were far more likely to save you when a Flipper had reached the top of the tube and was making its way towards you; they could only kill you if they in the same space as you and were vulnerable to your shots while they were flipping that last step towards you. If you were simply relying on autofire, you could bet that that flip would happen during the short pause between bursts.

Whitby guy had also worked out that the larger the angle a flipper had to flip through, the more chance you had of killing it before it killed you, so for lots of levels, it was just a matter of finding the safest place and staying there. There are a couple of levels where you were only 'safe' from flippers coming from one side. Those were the levels that killed you unless you got good at moving from place of safety to place of safety.

I watched intently and, when I returned to my home arcade, suddenly the top three scores -- the ones that got burned into non volatile memory -- on the arcade's machine belonged to PDC. I could reliably reach the red levels and even the next, yellow, set.

I can't do that on the Game Dad. Not yet at least. I'm old enough and RSI'd enough, that the thought of bashing the fire button at 8 Hertz just gives me the shivers.

But! Modern emulators have all sorts of convenience functions, surely I could configure something that would emulate the steady rate of fire that my youthful fingers were capable of. And maybe I could do something about the incredibly sensitive controls, where even the lightest touch of the analog stick would see me moving two or more segments when what I really wanted was a surgical one step move.[fn:2]

I turns out that I could. But, frustratingly, not via the very slick UI. I had to edit text files! I had to make new text files. And because popping the Micro SD card out of the Game Dad and into a card reader, editing a file, putting it back in the GD, testing it and then having to fiddle with the text file again is… less than ideal, I did it by /logging into my handheld games console via SSH from my iPad, editing the file and just restarting the game!/

You can't do that with an original Game Boy can you? The damned thing's running Linux. I'm at once annoyed that I had to log in to it and fiddle with text files and astonished that I could even do that.

It's not the nostalgia that's making me feel old, it's my assumptions about what's capable of what kind of computing.
**** DONE Week ending 2023-08-20
CLOSED: [2023-08-21 Mon 10:17]
:PROPERTIES:
:export_file_name: week-ending-20230820
:export_hugo_slug: week-note
:END:

A quiet week. Had to cancel Friday night's singing session with Emily – initially because Emily's still recovering from COVID, but on the night itself, my diabetes meds decided to give me hellacious indigestion. Ozempic/semaglutide might well do wonders for my HBA1c readings, but it can't half mess with my guts as well.
**** DONE Week ending 2023-08-27
CLOSED: [2023-08-27 Sun 12:32]
:PROPERTIES:
:export_file_name: week-ending-20230827
:export_hugo_slug: week-note
:END:

A bit of a mixed week, mood wise. Capped by a great day's singing and chatting in Peterborough yesterday.

It's great to get out of the house sometimes. Gill coped really well by herself too -- I'm a full time carer, but it's definitely good to know that I can have the odd day off without it completely buggering things up.

#+hugo: more
***** Monday
****** Folk FOMO
Whitby Folk Festival FOMO is real. But also, there's a COVID spike going on, and crowded rooms full of unmasked singers aren't the safest of environments, so I think I'll comfort myself in the knowledge that at least I won't be likely to bring an infection home with me.
****** Blog fiddling
I swear I'm going to wrap my head around the workings of the way to optionally build a custom formatted Date tree using =org-capture=, but for now I've just tweaked the template I use to add

#+begin_src org
#+hugo: more
#+end_src

to the heading for the week. This means that, when Hugo's rendering the index page, the week's notes will be represented by a summary which links to the extended per-day notes for the week.

Furthermore, I've added a new capture to let me capture a weeks' summary. I think I'll probably end up wrapping that in a =summarize-week= command that will show me the wider weeknote context while I write the note, then mark the week as =DONE=, then bring up =magit= so I can commit and push the changes. But maybe not for a while yet, on the "fake it until you can't stand /not/ to automate it." principle.
***** Thursday

So, I have the ADHD thing of putting a thing down and completely forgetting where I put it, or even its very existence. Object permanence is clearly not a thing with me.

Or I thought it was.

We have a house guest right now, and she has this habit of trying to help by tidying putting stuff in 'sensible' places. So I'll find the squash in amongst the bottles of oil, vinegar and sauces in a /completely other part of the kitchen;/ or Gill's socks will show up in an admittedly convenient, but surprising, new place after I've given up looking for them in the place I usually put them, and the airer I dry them on, and in the washing machine and laundry basket. Maybe it's on the floor between any of those places… Grrr.

It turns out I'm kind of comfortable with not quite knowing where a thing is, but I am absolutely viscerally /infuriated/ by finding said thing in the wrong fucking place, somewhere I would never ever ever in a month of Sundays deliberately put it.

And don't… don't get me started on the utter utter utter wrongness of using the lids of things as shelves. I will end up foaming at the mouth and shouting. Ask me how I know.

It's all the more distressing because I hate getting angry about stuff, especially objectively trivial stuff like this, and so the rate spirals. Bah!
***** Saturday

Had a great day at Mill Con 2 down in Peterborough. I still think filk music as a genre is a bit weird, but there's no denying that the people who make it are lovely people, and it's hard to beat singing in company for lifting your mood.

Mike Whitaker was kind enough to give me a concert spot at a week's notice too, so I did a forty minute set with a couple of songs with Loopy Pro in what was only the second time I've used the gear in any setting but my 'streaming studio.' It went well, but there's still a way larger profusion of wires than I'm happy with, and I definitely want to assemble some kind of all in one pedal setup if I'm going to be taking the gear out of the house more often.
**** DONE Week ending 2023-09-03
CLOSED: [2023-09-03 Sun 13:47]
:PROPERTIES:
:export_file_name: week-ending-20230903
:export_hugo_slug: week-note
:END:

Another quiet week. Streamed tired on Friday night, so quite a bit of pilot error with the looper, but folk still seemed to enjoy it.

Scrooby show was lovely on Saturday. Nice to catch up with a few folk I've not seen in quite a while and the weather was flat out gorgeous. I took some modelling balloons, planning to do a few balloon animals and hats, had something like a 60% burst rate with the Sempertex 260Ss that were all I could get hold of at short notice. Won't be using those again. Qualatex all the way, I think.
**** DONE Week ending 2023-09-24
CLOSED: [2023-09-24 Sun 10:47]
:PROPERTIES:
:export_file_name: week-ending-20230924
:export_hugo_slug: week-note
:END:

I'm not quite sure where the time went these last couple of weeks, but here we are at another Sunday. We've spent quite a bit of the time watching a new family of kittens that have taken to playing on the flat roof of our garage. They're almost obscenely cute scraps of black and white fur and just delightful to watch.

#+hugo: more
***** Sunday

Back in 2012, we were living in Cornwall and used to go to the regular Farmers' Markets in Mullion and Helston. One week, at Mullion, a new trader showed up selling home made bean to bar chocolate under the name of [[https://chocolarder.com/][Chocolarder]]. I got chatting with Mike, the guy who made the stuff, and bought a few bars and some of his [[https://www.chocolarder.com/shop/sea-salt-caramel-truffles/][sea salt caramel truffles]]. If we weren't actually his first customer, we were damned close.

Every month, he showed up with plain looking bars of /amazing/ chocolate. One time he'd bought a bunch of rose petals (apparently, they can be had quite reasonably after Valentine's Day because there's something of a glut), dessicated them, ground them fine and added them to the chocolate. Bloody delicious!

I told Mike about some milk chocolate with sea salt that I'd tried and really loved and suggested he do something similar. He'd have a go he said. Months later (after many experiments, apparently) there he was with some bars of salted milk chocolate so I bought as many as I had the cash for and loved every mouthful. He didn't make them again though. Except, today, with a bit of birthday money burning a hole in my pocket, I thought "I'd love some Chocolarder chocolate, it's been an age" and what did they have? You guessed it: [[https://www.chocolarder.com/shop/sea-salt-milk/][Cornish sea salt]] milk chocolate. So that's a chunk of birthday money spent.

Yes, it's a lot of money for a bar of chocolate, but believe me, it's amazing stuff and Mike is as committed to ethical and sustainable manufacture as anyone I've ever met. We've visited the factory a couple of times and I remember the time we visited and he was more excited about showing off his new, plastic free packaging as he was about the chocolate. He buys direct from cacao farmers and has been known to get his beans shipped by sail rather than container ship.

** DONE My Virtual Gig-Like Thing
:PROPERTIES:
:export_hugo_slug: virtual-gig-like-thing
:export_date: 2020-04-08T00:00:00
:EXPORT_FILE_NAME: virtual-gig-like-thing
:ID:       C2642DFD-B4E8-44DB-B576-BED6A8C96223
:END:

On Thursday the 9th of April at 7pm UK time, I'm streaming my first attempt
at a  full folk club style gig from my study to my
Twitch stream and I would  love for you to be there.

#+hugo: more

*** Schedule
:PROPERTIES:
:ID:       6769254B-F1F3-46DF-814F-63D96F985D7C
:END:

It all kicks off at 7pm, UK time with a kind of Q&A session and
introduction to Twitch for newcomers. I'm particurly planning to help
other independent musicians reach their audience through the platform.
#+begin_marginnote
Recent deals with [[https://soundcloud.com][SoundCloud]] have made it /much/ easier for experienced
performers to access the means to get paid on Twitch, and it seems to be
the most transparent platform for getting paid.
#+end_marginnote
@@


Then, I plan to follow the Royal Traditions/Singing Together format of two
forty minute sets of folk material with a 10 minute refreshment and raffle
break in the middle.

After the folk club concert I'll be jumping onto [[https://twitch.tv/sings/download/][Twitch Sings]] to round out
the evening singing implausible songs with friends from that community and
any folky friends who've managed to get themselves up on Twitch by then. I'm
hoping it'll be a lot of fun.


*** Ticket Prices
:PROPERTIES:
:ID:       0E43DD7E-5512-435C-B7C4-73910B049C75
:END:
It's the internet! It won't cost you a penny to watch me perform. However,
right now, daft stuff like this is my only potential source of income, so
I would be deeply grateful if you could either [[https://ko-fi.com/pdcawley]["Buy me a coffee"]] via Ko-Fi
or [[https://twitch.tv/signup][sign up]] for a free Twitch account and subscribe to my channel.

*** Free money for your favourites!
:PROPERTIES:
:ID:       AFDB4ED1-8FAB-461B-816A-CD0BF60D7CC2
:END:
If you are an Amazon Prime subscriber and you don't yet have a Twitch
Subscription, there's a wonderful thing you can do that means that Amazon
will give me (or any other streamer you enjoy) some money and it won't
cost you a penny. [[https://twitch.amazon.com/prime][Sign up]] for Twitch Prime, which is just like a regular
twitch account, but you can subscribe to one channel for free each month.
The streamer gets paid by Twitch as if you'd signed up for a regular
subscription, but you don't get charged a penny because you're already
paying Amazon for your Prime account. The only difference between a Prime
subscription and a regular one on Twitch is that you can't set up a Prime
sub to renew. If you would like to keep making regular payments to the
streamer of your choice, you need to remember to resubscribe every month.

*** One off tips
:PROPERTIES:
:ID:       95E39426-BE56-4078-9BF5-E7B2BE229683
:END:
A Ko-Fi coffee comes in at £3, but if you want to tip me or any other
twitch performer with an arbitrary amount, then Twitch Bits are your
friend. You buy 'em from [[https://bits.twitch.tv/][Twitch]] and can then use them as a virtual
currency. For the performer, 100 bits is equivalent to $1, but they will
cost you more than that to buy, because Twitch are (understandably, it's
not a cheap platform to run!) going to have to take a cut somewhere. By
loading it on the cost of bits to the giver, they make things really
transparent. It's not like the weird alchemy where you pay a music
streaming site 69p for a track or whatever and, unbeknownst to you unless
you really dig into it, the artist sees maybe 6p of that.

Other performers have other ways for you to support them, whether it be
public amazon wishlist, paypal tip jar, patreon page or some other service
I've not heard of yet. In some ways, it's never been easier for you to
support the work of artists you love.


** DONE Asshole Free Devil's Advocacy :philosophy:blether:
:PROPERTIES:
:export_file_name: devils-advocacy-without-asshattery
:export_hugo_slug: devils-advocacy-without-tears
:export_date: 2018-10-25
:ID:       B96DE889-2A35-4276-B716-EB558186DB55
:END:


So, you want to play Devil's Advocate, but you're afraid you might come across as a bit (or a lot) of an asshole? Here's some suggestions for how to avoid that.

#+hugo: more

*** Maybe don't?
:PROPERTIES:
:ID:       DFD8CB3D-98AB-414B-8766-B64DBC5E1D04
:END:

Seriously, why does the Devil need an advocate? If you want to play DA because you think the position you want to argue has some merit, then argue the position honestly and own it. If it doesn't survive the discussion (or is shouted down), then "Ah right, I hadn't thought of that, you're right" or words to that effect and file that position in your memory as a bad one (along with the skeleton of /why/ it's bad). Nothing wrong with holding strong opinions, the thing that's bad is holding onto them if they're shown to be bad. If the group you're talking with just shouts you down and doesn't convince you that your position is a bad one, maybe find a different group? Or agree with them to steer clear of that topic.

What's really intellectually dishonest is to say "I was only playing Devil's Advocate!" after an idea has been shot down. I'm sure your intentions are entirely honorable, but what if they weren't? Say you genuinely held that the best thing to do with the children of the poor was to turn them into cheap and delicious meals for the richest in society. Say you advanced this position to your friends and were utterly appalled by the idea. Then maybe you'd try to distance yourself from it by saying "Whoah! Guys!
#+begin_marginnote
I know. But the kind of people who make this move in an argument are usually the kind of people who'd address a mixed group of folk as "guys".
#+end_marginnote
I was only playing Devil's Advocate!"

When I hear someone playing that card, how am I supposed to distinguish between the well-meaning "There is this argument I've come across that I'm not sure I agree with, but it maybe has some merit and I don't know how I'd argue convincingly against it" types and the assholes who were flying a kite? Maybe the non-assholes will have friends who'll tell me that "They might seem like a bit of an arse, but they're not really." I've been that guy, and I don't want to be him again. Why is it okay for me to load the work of explaining that I'm not dickhead onto my friends rather than just not acting like a dickhead in the first place? Eventually, friends get tired. Eventually they'll shift to "Yeah, I know he seems like an ass, and he kind of is, but..." and then one day, they won't be your friends any more.

{{{newthought(Before you introduce the idea)}}} you want to play Devil's Advocate for, say something like "D'you mind if I play Devil's Advocate for a moment?" And when the group tells you "Yes, we do mind. Why help the devil?" listen to them. If it's genuinely that you've heard some argument that on the face of it seems repugnant, but you can't find a hole in it, then say as much: "What's wrong with this idea? Clearly feeding poor babies to the 1% is utterly repellant, but I can't find an effective counterargument."

Don't keep doing it, mind, or you'll start looking like the kite flying asshole again.

** DONE Adding a generic oembed handler for Hugo :hugo:
:PROPERTIES:
:export_hugo_slug: oembed-for-hugo
:export_file_name: oembed-for-hugo
:export_date: 2020-05-12
:ID:       950F43FF-3632-48D9-B768-02CC5154A220
:END:
If you're at all like me, you have content on a bunch of different sites (Instagram, Youtube, Flickr, Soundcloud, Bandcamp...) and, especially for multimedia content, it's great to be able to link to 'live' versions of that content. Of course, all those sites will let you 'share' content and usually have an 'embed' option that hands you a bunch of HTML that you can paste into your blog entry. But screw that! I'm a programmer for whom laziness is one of the cardinal virtues -- if it's at all possible, I prefer to let the computer do the work for me.
#+begin_marginnote
If nothing else, once I've got the programming right, it's less likely to screw up than me
#+end_marginnote

Hugo[fn:1] sort of supports this out of the box with its ~youtube~, ~instagram~, ~vimeo~ etc. built in shortcodes. The thing is, they're not lazy enough -- you have to dig into each URL to extract a content ID and pass that in to ~{{%/* youtube kb-Aq6S4QZQ */%}}~ or whatever. Which would be kind of fine, if you weren't used to the way sites like Facebook, Twitter, Tumblr and so on work. With those sites, you enter a URL and they disappear off behind the scenes and fill in a fancy preview of the page you linked to. Why can't Hugo do that?

#+hugo: more

Well, it can. It just takes a little work.[fn:3] The ~question~ to ask is how do all those user friendly sites do there thing? Twitter and Facebook, being the walled garden behemoths that they are do it by dictating two different microformats
#+begin_marginnote
Of bloody course!
#+end_marginnote
that live in a page's ~HEAD~ section. The microformat approach has a good deal to be said for it: In theory, you can just make a ~HEAD~ request to the URL you're interested in, parse out the microformat of your choice and build your own media card. I've not worked out how to do this yet though. However, before Twitter and FB started throwing their weight around, there was an open standard that lots of sites support, it's /really/ easy to use. It's called [[https://oembed.com/][oembed]] and it's great. The idea is that it too is discoverable via a ~HEAD~ request to your media page. You look for something matching src_html[:exports code]{<link rel="alternate" type="application/json+oembed" href="..." ...>}, make a JSON request to the ~href~ url and paste in the contents of the ~html~ key in the object you get back. The catch, of course, is that you still end up having to parse the document's HEAD.

The cool thing about ~oembed~, though, is that you /can/ discover its endpoints that way,
#+begin_marginnote
Though, I'm seeing fewer and fewer oembed links cropping up in sites that I /know/ support the protocol
#+end_marginnote
 but there's also a big list of known endpoints on the [[https://oembed.com/][Oembed homepage]], which is also available as a big old JSON object if you want to go the full programmatic route. There are JavaScript libraries available that will walk your webpage and the JSON object and replace all your links with chunks of embedded content, that that's what I used to use on this site. But... that's not how I currently roll at Just A Summary. There are currently no ~<script>~ tags to be found on here and I plan to keep it that way. So I wrote a Hugo shortcode. Here it is:

#+name: Initial embed shortcode
#+caption: Initial embed shortcode
#+begin_src go-html-template
{{ $url := (.Get 0) }}
{{- range $.Site.Data.embed }}
  {{- if le 1 ( findRE .pattern $url | len ) }}
    {{- with (getJSON .endpoint "?" (querify "format" "json" "url" $url)) }}
      {{ .html | safeHTML }}
    {{ end }}
  {{ end }}
{{ end }}
#+end_src

We use it like: ~{{</* embed "https://youtub.be/kb-Aq6S4QZQ" */>}}~, which displays like this:

@@hugo:{{< embed "https://youtu.be/kb-Aq6S4QZQ" />}}@@

{{{newthought("But how does it work?")}}} I hear you ask? It works in conjunction with some per-site data entries that I've added to the directory ~data/embed~ in this site's base directory. You might have guessed that the data entries are maps with two entries, a ~pattern~ and an ~endpoint~. If the URL argument matches the ~.pattern~, then we make a ~getJSON~ request to ~.endpoint~ with a sanitised version of the URL argument tacked on as our query string and inserting the JSON response's ~.html~ entry.
#+begin_marginnote
It's rather tricky to implement oembed for on a strictly static site, but I love the simplicity of it. I have a few thoughts about that though. Watch this space.
#+end_marginnote

I made the data files by taking the big JSON object from https://oembed.com/providers.json and massaging the supplied patterns into regular expressions. In theory, I could write a script to do the conversion for me, but I'm only really interested in four providers for this site, so I just did it by hand. So the entry for [[https://instagram.com/][Instagram]]:

#+caption: The https://oembed.com/providers.json entry for Instagram
#+name: 521EC4E0-5CE6-4667-9558-16262848DD6D
#+begin_src json
{
    "provider_name": "Instagram",
    "provider_url": "https:\/\/instagram.com",
    "endpoints": [
        {
            "schemes": [
                "http:\/\/instagram.com\/*\/p\/*,",
                "http:\/\/www.instagram.com\/*\/p\/*,",
                "https:\/\/instagram.com\/*\/p\/*,",
                "https:\/\/www.instagram.com\/*\/p\/*,",
                "http:\/\/instagram.com\/p\/*",
                "http:\/\/instagr.am\/p\/*",
                "http:\/\/www.instagram.com\/p\/*",
                "http:\/\/www.instagr.am\/p\/*",
                "https:\/\/instagram.com\/p\/*",
                "https:\/\/instagr.am\/p\/*",
                "https:\/\/www.instagram.com\/p\/*",
                "https:\/\/www.instagr.am\/p\/*",
                "http:\/\/instagram.com\/tv\/*",
                "http:\/\/instagr.am\/tv\/*",
                "http:\/\/www.instagram.com\/tv\/*",
                "http:\/\/www.instagr.am\/tv\/*",
                "https:\/\/instagram.com\/tv\/*",
                "https:\/\/instagr.am\/tv\/*",
                "https:\/\/www.instagram.com\/tv\/*",
                "https:\/\/www.instagr.am\/tv\/*"
            ],
            "url": "https:\/\/api.instagram.com\/oembed",
            "formats": [
                "json"
            ]
        }
    ]
}
#+end_src

becomes

#+name: instagram.yaml
#+caption: ~./data/embed/instagram.yaml~
#+begin_src yaml
endpoint: "https://api.instagram.com/oembed/"
pattern: "^https?://(www\\.)?instagr(\\.am|am\\.com)/((.*/)?p/|tv/)"
#+end_src

Collapsing all those ~scheme~ entries down to a single regular expression was a slight pain to do by hand, and I'm not /entirely/ sure the regular expression will match exactly what the schemes match, but it's not broken on any of the Instagram links I've thrown at it so far, so that's good enough for me.

{{{newthought(This isn't the shortcode's final form)}}} -- it's not as robust as I'd like it to be in the face of a missing or temporarily down oembed endpoint, so it would be good to have some kind of fallback in case an endpoint changes or goes away. Also, there are some sites that have their own methods for embedding previews, which don't support oembed
#+begin_marginnote
All those IndieWeb sites that use ~h-entry~ and ~h-card~ microformats to make the webpage machine parseable, for instance.
#+end_marginnote
and it would be great to get at those somehow. I suspect I will end up with a shortcode which is essentially a big case statement dispatching to different partials which will handle the real rendering. Again... watch this space


** DONE «tap tap» is this thing on? :indieweb:
CLOSED: [2022-04-12 Tue 16:26]
:PROPERTIES:
:export_file_name: 20220412-is-this-thing-on
:export_hugo_slug: is-this-thing-still-on
:END:

#+begin_description
In which Piers attempts to explain why he's not been blogging in years, and makes vague noises about getting back to it again, in the hope that this time his [[https://indieweb.org/][IndieWeb]] inspired enthusiasm will last longer than a couple of weeks.
#+end_description

It's been a while hasn't it? I've been blogging on and (mostly) off since 2004 (at least according to the oldest article on here), and the [[https://indieweb.org/][IndieWeb]] movement reminds me of those heady days before Facebook, Twitter and the other monoliths scooped up all the bloggers.

It was probably Twitter that killed my regular blogging -- before Twitter, if I had something to say, I'd write a blog (or a LiveJournal for more personal stuff) post. Maybe a few days later, someone would reply, or write a blogpost of their own as a reaction and I'd get a pingback. These days, when I blog, my posts sit in splendid isolation, which wasn't really a thing back in Blogging's heyday. Spam killed my will to support comments and the growing complexity of blogging software was a real turn off. {{{marginnote(And I speak as someone who was the maintainer of [[https://typosphere.org/][Typo]] for a few years.)}}}

I burned out.

I ran this site on Typo, but most of the work I was doing on it was implementing features I didn't need which made the code slower and harder to understand, so I stepped back just as Twitter started its rise.

I've made a few abortive returns to blogging since, prompted by the rise of static site generation engines
#+begin_marginnote
I'm now using [[https://gohugo.io][Hugo]], [[https://orgmode.org/][org-mode]] and [[https://github.com][Github Actions]] to manage the site, and it's all hosted as a bunch of text files on a Raspberry Pi in one of [[https://mythic-beasts.com/][Mythic Beasts]]' racks somewhere.
#+end_marginnote
and the fact that I like having something to fiddle with. I could have just installed WordPress, but the idea of simply serving up a pile of static files (and no JavaScript!) seems way more sustainable (and secure) to me.
#+begin_marginnote
 Executing code that's exposed to the internet when I could just be serving textfiles is a recipe for pain and suffering.
#+end_marginnote

{{{newthought(Not running code on my server)}}} makes it a bit tricky to be fully engaged in IndieWeb ideal of a /connected/ web of websites using [[https://www.w3.org/TR/webmention/][WebMentions]] to make those interactions visible, but [[https://www.w3.org/TR/webmention/][it can be done]], and I too shall achieve it! One day. Baby steps, eh? I might resort to a Javascript based setup initially, but long term I want to keep the site completely script-free and fast.

*** Other writing

{{{newthought(I've written a few pieces)}}} now for [[https://jonwilks.online/][Jon Wilks]]' new and rather wonderful  [[https://tradfolk.co/][Tradfolk]] website. You can find those (and any future articles) at [[https://tradfolk.co/author/pierscawley/]] if you're interested in my suggestions on how to get started singing without accompaniment and building your repertoire.

I think that's what's got me returning to this site frankly. I'd forgotten how much I enjoyed writing long-ish form stuff rather than 280 character miniatures.

*** Coming up

{{{sc(newthought)}}}I suspect that,{{{sc(/newthought)}}} like every other IndieWeb blogger, I'll have a few upcoming articles detailing how I make things work here, {{{marginnote(Can there be anything more fascinating than tech navel gazing?)}}} but there's a few things in my drafts folder that I want to return to, and probably some discussion of my experiences streaming folk songs every Friday night for the best part of two years now.

Let's revisit this in a couple of months and see if it's still the most recent article on the site, eh?

** DONE We have WebMentions
CLOSED: [2022-04-16 Sat 14:53]
:PROPERTIES:
:export_file_name: we-have-webmentions
:END:

#+begin_description
Taking one more step on the road to full IndieWeb citizenship or whatever it's called, [[file:/][Just A Summary]] now displays webmentions.
#+end_description

After much fiddling with [[https://n8n.io/][N8N]], [[https://webmention.io/][webmention.io]], and the usual combination of [[https://gohugo.io][Hugo]]'s powerful, yet inscrutable templating language and my tenuous understanding of CSS, we're now /displaying/ our webmentions. We've been directing them to webmention.io for years now, but scratching my head over what to do with them.

The way it works at the moment is I run a task every few hours that checks webmention.io, merges the results with the stuff we already know about and commits the updated data files to Github, which triggers a github action that rebuilds the site. This is… inefficient. My next step is to either expose the n8n workflow via a webhook, or work out how to retain some information from the previous run and use that to ensure we only fetch any mentions that've arrived since the last time we checked. But that's work for another day. Right now I'm calling what I have a win, merging this branch to main and basking in the warm glow of taking one more step down the IndieWeb road.

** DONE Keep it Simple, But Where's The Fun In That? :indieweb:webmentions:
CLOSED: [2022-04-24 Sun 16:30]
:PROPERTIES:
:export_file_name: 20220423-keep-it-simple-but-where-s-the-fun-in-that
:export_hugo_slug: not-so-simple
:END:

#+begin_description
The beauty of using a static site generator to build your website is supposed to be that it's all delightfully simple. Simple markdown formatted files go in at one end and a slim, fast and easy to serve website comes out the other end. All that remains is to upload those files to the appropriate directory on your server and all is well.

But never underestimate the ability of a long time Emacs user to complicate things.
#+end_description

The beauty of using a static site generator to build your website is supposed to be that it's all delightfully simple. Simple markdown formatted files go in at one end and a slim, fast and easy to serve website comes out the other end. All that remains is to upload those files to the appropriate directory on your server and all is well.

But never underestimate the ability of a long time Emacs user to complicate things. For instance, markdown is all well and good, but I've been doing most of my writing in [[https://orgmode.org/][Org Mode]][fn:4] so I really want to stay in Org mode to write these blog posts. [[https://gohugo.io/][Hugo]] understands =.org= files, so I could just lean on that, but the way Hugo treats org files seems slightly out of whack with what I think of as the Org way and I'd end up having to stick with the subset of org syntax that Hugo know. So I use [[https://ox-hugo.scripter.co][ox-hugo]], there's a bit of configuration needed to make it work the way I like, but I prefer to change software to accommodate me rather than change me to accommodate software
#+begin_marginnote
I'd go so far as to say it's a point of pride.
#+end_marginnote

I've had all that set up for a while. As I say, a tad fiddly at first, but once it's in place, it just works.

{{{newthought(Except…)}}} =ox-hugo= works by generating =.md= files from an org source, which are then used to generate the site, and I had things set up to autogenerate the html whenever I commited to the main branch of the blog repo, and the git server hook based system I was using only worked if those exported files were in repo.

That's the sort of thing that makes me itch, because there were two files for any given article:

- =all-posts.org= :: the org file in which I write all my articles
- =article.md= :: the generated file that hugo uses to build the site.

The generated file is an artefact of the build process and simply repeats the info in the org file, which should be our single source of truth. It's not a file that should be left around to be edited willy nilly because it could get out of sync with its source file. It's certainly not the sort of file that should live in the repository.

I didn't worry about this for /ages,/ but it niggled at me. Then one day I read an article about using [[https://github.com/features/actions][Github Actions]] to build an ox-hugo based site by installing emacs and ox-hugo on the VM that does the build step and generating the markdown files during the build by running Emacs


#+begin_marginnote
Yes, Emacs is an editor, but if you do 「src_emacs-lisp[:exports code]{emacs all‑posts.org ‑‑batch ‑l ox-hugo ‑‑eval='(org-hugo-export-wim-to-md t)' ‑‑kill} 」 it will happily execute any lisp code you care to ask it to.
#+end_marginnote
in batch mode. The  markdown files never exist anywhere that anyone can edit them. So, of course I had to do that. Again, fiddly to set up, and arguably only of philosophical benefit, but worth it, I think.[fn:5]

{{{newthought(I could've left it there,)}}} but the thing I miss about the old, slow, hard to maintain version of this site, is the sense of connection. The old site had comments, and pingback links to other blogs. There was a sense of connectedness that's missing from a collection of articles. I want some of that back.

There is a way. In the time I've been mostly not blogging, some of the folks who kept at it have been cooking up a collection of tools, technologies and standards under the [[https://indieweb.org][IndieWeb]] banner. There's a whole suite of technologies involved, but the piece of the puzzle that I'm interested in right now is the [[https://indieweb.org/WebMention][WebMention]], described as

#+begin_quote
… an @ mention that works across websites; so that you don't feel immovable from Twitter or Fb
#+begin_cite
[[https://twitter.com/rngala][Roney Ngala]] ([[https://twitter.com/rngala][@rngala]]) on [[https://twitter.com/rngala/status/852354426983591937][Twitter]]
#+end_cite
#+end_quote

Now we're talking! It's a really simple standard too. When you mention, like, comment on, repost, reply to, bookmark or simply publicly interact with an "h-entry"[fn:6] on the IndieWeb, you can send a webmention by sending a small chunk of JSON to the webmention endpoint of the entry you mentioned. Assuming all the content is marked up correctly, /sending/ a webmention is delightfully easy. You can do it with ~curl~, if that's your thing, but I'm in an emacs buffer, so let's use [[https://github.com/pashky/restclient.el][~restclient~]]

We mention [[https://indieweb.org]] in this post, so let's find out its webmention endpoint.

#+begin_src restclient :exports both
HEAD https://indieweb.org
#+end_src

#+results:
#+BEGIN_SRC html
<!-- HEAD https://indieweb.org -->
<!-- HTTP/1.1 200 OK -->
<!-- Date: Thu, 21 Aug 2025 20:55:46 GMT -->
<!-- Content-Type: text/html; charset=UTF-8 -->
<!-- Connection: keep-alive -->
<!-- Server: cloudflare -->
<!-- Link: <https://webmention.io/indiewebcamp/webmention>; rel="webmention" -->
<!-- Cache-Control: no-cache -->
<!-- X-No-Cache: 1 -->
<!-- X-Cache: BYPASS -->
<!-- Cf-Cache-Status: DYNAMIC -->
<!-- Report-To: {"group":"cf-nel","max_age":604800,"endpoints":[{"url":"https://a.nel.cloudflare.com/report/v4?s=AcdDojTYPMSIrmWJHpOrSeRUOgkMOS5R%2BU8A%2FpEtRdGdGILIA0DwvJcCiFhtKp6Q1em%2BPnsMp7E8%2BhMzx4JN65Thuu2UeCM3AibOYQ%3D%3D"}]} -->
<!-- Nel: {"report_to":"cf-nel","success_fraction":0.0,"max_age":604800} -->
<!-- CF-RAY: 972d087bbb33bed7-LHR -->
<!-- alt-svc: h3=":443"; ma=86400 -->
<!-- Request duration: 1.125278s -->
#+END_SRC

We're looking for the 「src_html[:exports code]{Link: … ; rel="webmention"}」 line. This tells us that to send a webmention targeting https://indieweb.org, we need to post it to https://webmention.io/indiewebcamp/webmention. Which is almost as simple as finding the end point. Here we go:

#+begin_src restclient :exports both
POST https://webmention.io/indiewebcamp/webmention
Content-Type: application/x-www-form-urlencoded

source=https://bofh.org.uk/2022/04/24/not-so-simple&target=https://indieweb.org
#+end_src

#+results:
#+BEGIN_SRC json
{
  "status": "queued",
  "summary": "Webmention was queued for processing",
  "location": "https://webmention.io/indiewebcamp/webmention/oYamc823u4mVmGD3BmPu",
  "source": "https://bofh.org.uk/2022/04/24/not-so-simple",
  "target": "https://indieweb.org"
}
// POST https://webmention.io/indiewebcamp/webmention
// HTTP/1.1 201 Created
// Content-Type: application/json;charset=UTF-8
// Content-Length: 236
// Connection: keep-alive
// Status: 201 Created
// Cache-Control: no-store
// Access-Control-Allow-Origin: *
// Location: https://webmention.io/indiewebcamp/webmention/oYamc823u4mVmGD3BmPu
// X-Content-Type-Options: nosniff
// Date: Thu, 21 Aug 2025 20:56:00 GMT
// X-Powered-By: Phusion Passenger 5.3.1
// Server: nginx/1.14.0 + Phusion Passenger 5.3.1
// Request duration: 0.590250s
#+END_SRC

The job is done, and we get a nice JSON formatted summary of what's going on to boot.

Of course, if a webmention is so simple to send then it's probably a pain in the bum to receive and it is… sort of. To receive a webmention request, you need to:

1. Run a web app to handle the request
2. Visit the source link
3. Parse out the microformats associated with the entry, its author and content
4. Figure out how to display the information

Steps 1--3 aren't particularly hard, but they're fiddly to get right and involve making web connections to potentially unsafe sites and I'm using Hugo to generate this site because I don't want to be running potentially insecure code that's exposed to the internet on a server that I own if I can possibly help it. Thankfully, I don't have to. I can take a leaf out of indiweb.org's book and just delegate that part to [[https://webmention.io][webmention.io]]. Webmention.io handles all that icky visiting of foreign websites and parsing out microformats for you and instead presents you with a feed consisting of all the webmention's that've been sent to your site in a variety of formats. I've been consuming their ~.jf2~ formatted feed for a while now. JF2 is a JSON representation of the microformats associated with the webmention's source. Let's grab something from that feed

#+begin_src restclient :exports both
GET https://webmention.io/api/mentions.jf2?per-page=2&page=0&sort-dir=up&target=https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/
#+end_src

#+results:
#+BEGIN_SRC json
{
  "type": "feed",
  "name": "Webmentions",
  "children": [
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "David Gallows",
        "photo": "https://avatars.webmention.io/pbs.twimg.com/e7b750d847ffdcfc174845aadc9196125b83647258a1789bb2b92b493d223e8b.jpg",
        "url": "https://twitter.com/DavidGallows"
      },
      "url": "https://twitter.com/pdcawley/status/1517783526049001472#favorited-by-877428607",
      "published": null,
      "wm-received": "2022-04-23T09:59:17Z",
      "wm-id": 1385464,
      "wm-source": "https://brid.gy/like/twitter/pdcawley/1517783526049001472/877428607",
      "wm-target": "https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/",
      "wm-protocol": "webmention",
      "like-of": "https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/",
      "wm-property": "like-of",
      "wm-private": false
    },
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "David Gallows",
        "photo": "https://avatars.webmention.io/pbs.twimg.com/e7b750d847ffdcfc174845aadc9196125b83647258a1789bb2b92b493d223e8b.jpg",
        "url": "https://twitter.com/DavidGallows"
      },
      "url": "https://twitter.com/DavidGallows/status/1517852498555555840",
      "published": "2022-04-23T13:06:50+00:00",
      "wm-received": "2022-04-23T15:12:04Z",
      "wm-id": 1385681,
      "wm-source": "https://brid.gy/comment/twitter/pdcawley/1517783526049001472/1517852498555555840",
      "wm-target": "https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/",
      "wm-protocol": "webmention",
      "content": {
        "html": "enjoyed reading about it :)\n\nI've been a trackball man since the word go, But have never been able to move away from Qwerty keyboards\n<a class=\"u-mention\" href=\"http://bofh.org.uk/\"></a>\n<a class=\"u-mention\" href=\"https://twitter.com/DrugCrazed\"></a>\n<a class=\"u-mention\" href=\"https://twitter.com/keyboardio\"></a>\n<a class=\"u-mention\" href=\"https://twitter.com/pdcawley\"></a>",
        "text": "enjoyed reading about it :)\n\nI've been a trackball man since the word go, But have never been able to move away from Qwerty keyboards"
      },
      "in-reply-to": "https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/",
      "wm-property": "in-reply-to",
      "wm-private": false
    }
  ]
}
// GET https://webmention.io/api/mentions.jf2?per-page=2&page=0&sort-dir=up&target=https://bofh.org.uk/2013/03/10/in-which-piers-prepares-to-void-the-warranty/
// HTTP/1.1 200 OK
// Content-Type: application/json;charset=UTF-8
// Content-Length: 2075
// Connection: keep-alive
// Status: 200 OK
// Cache-Control: no-store
// Access-Control-Allow-Origin: *
// X-Content-Type-Options: nosniff
// Date: Thu, 21 Aug 2025 20:56:16 GMT
// X-Powered-By: Phusion Passenger 5.3.1
// Server: nginx/1.14.0 + Phusion Passenger 5.3.1
// Request duration: 0.160096s
#+END_SRC

Lot's of lovely structured data. Webmention.io has worked out that one mention was a ~like-of~ [[file:/2013/03/10/in-which-piers-prepares-to-void-the-warranty/][the blog post]], and the other was ~in-reply-to~ it. We get details of the author of the mentioning post and, where appropriate, its content. If I wanted to run more Javascript on here (and I want to run less), I could attach a script which would consume the post's feed and build a display of all of the mentions. It has a certain appeal, just add one script to the site and a dummy ~<div>~ or ~<ul>~ somewhere and I'm laughing. Plenty of sites do just that.

This is not one of those sites.
#+begin_marginnote
Of course, this couldn't possibly because I tried to use the Javascript, couldn't make it work and decided to actually include webmentions in the generated files, that would be foolish!
#+end_marginnote
It's not even the first statically generated site to go down the route of statically generating a post's webmentions. I was mostly inspired by [[https://randomgeekery.org][Brian Wisti]]'s post about [[https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/][consuming the webmention.io API]] (except, of course, I don't use /any/ of his actual code.)

The site's [[https://github.com/pdcawley/bofh.org.uk/][Github repo]] is configured so any commit on the ~main~
#+begin_marginnote
It's 2022 already -- let's stop having 'master' branches, eh?
#+end_marginnote
branch fires off a workflow that builds the site and ships all the files over to the webserver using ~rsync.~ If I take Brian's idea for grabbing all my webmentions {{{marginnote(I set up the ~rel="webmention"~ link /ages/ ago and never quite got around to doing anything with the data)}}} and ignore his warning about splitting it out into Hugo data files and just do it, I can start building the webmentions for posts. Huzzah!

{{{newthought(It started so innocently,)}}} I have a server here that hosts a couple of Docker images and one of them is [[https://n8n.io/][N8N]], a super powered, self-hosted open source replacement for [[https://ifttt.com/][IFTTT]] with all sorts of hooks into other services and a much more powerful Github client than the IFTTT offering. It's a bit… JavaScript-y for my tastes, but you can't have everything.

With a bit of fiddling, I had something that grabbed the webmention.io feed for the site every few hours, split it out into multiple files in ~data/mentions~ and updated GitHub. That's what I was celebrating in [[file:post/we-have-webmentions.pre-processed.org][We have WebMentions]]. I've moved on
#+begin_marginnote
A cynical person might well read that as "broken things"
#+end_marginnote
since then, because /of course/ sorting out de-duplication and remembering information between runs of the script is annoyingly fiddly and full of edge cases. Basically, I ended up trying to emulate a proper database. Which is why the latest iteration of webmention handling uses a proper database. I would have used [[https://sqlite.org/][SQLite]], but N8N doesn't have a SQLite node available out of the box. It does have a [[https://postgresql.org/][PostgreSQL]] one though, and recent versions of that have really good JSON support. I'd tell you more, but ~wc-mode~ tells me I'm nearly 2500 words in to this article, I think I'll wrap up for now and promise to give you the gory details in an upcoming article.

** DONE Evolving my streaming setup
CLOSED: [2022-05-10 Tue 17:10]
:PROPERTIES:
:export_file_name: 20220510-evolving-my-streaming-setup
:export_hugo_custom_front_matter: :syndicate true
:export_hugo_custom_front_matter+: :tweet "Will I ever learn to leave well enough alone? I've written up the state of my streaming setup here."
:export_hugo_custom_front_matter+: :syndicated_at '((twitter . "https://twitter.com/pdcawley/status/1524062540522790912"))
:END:

Back when I first started streaming on the internet, I used a Logitech webcam and some lights I had picked up for doing product photography and such for the Loafery and some audio gear I had because, well, recording stuff is just fascinating. It was okay, but even with decent lighting and audio, the webcam was frustrating to control (basically, there /was/ no control), so I picked up a cheap capture card from Amazon  and drafted my Nikon D810{{{marginnote(Absolutely not the camera I would recommend if you're going out to buy a camera for streaming -- it's primary virtue being that it's the camera I already owned. Get something mirrorless if you're heading down this road)}}} as my webcam and the appearance of my streams improved enormously. This worked fine with my slightly aging PC and /Twitch Sings/.
#+hugo: more
Then Twitch pulled the plug on /Sings/ and I started doing my regular Friday night folk streams. At first this involved running OBS and Logic Pro on my aging MacBook Pro and it was sort of okay, until I started having guests and doing Song Swaps -- the MacBook simply wasn't up to the job of running Logic, OBS and Zoom, so for a while I had some unholy lashup, with Zoom and OBS running on the PC, my Mac running Logic, with patch leads between the Mac and PC audio interfaces so I could hear my guests and vice versa. It wasn't pretty.

What saved it was adding an [[https://www.blackmagicdesign.com/uk/products/atemmini][ATEM Mini Pro ISO]] from BlackMagic. Now I could hand off all the capturing, streaming and recording duties to that box and run Logic and Zoom on the Mac and everything just worked (with an utter rats nest of cables on my desk). The ATEM takes HDMI input from up to four sources and lets me switch what gets sent to the stream between them. There's also a monitor preview output that can be switched independently between those four sources, as well as multiview and stream previews. Of course, I quickly used up all four sources, and I don't even have a second camera! The way things are arranged by default is that I have a camera feed, my mac's primary and secondary displays, and the output from a Raspberry Pi. Mac screen 2 is where the zoom window lives, and is connected to the ATEM via an HDMI splitter with the second output feeding a 7-inch field monitor that sits on a teleprompter setup so I can look guests in the eye.{{{marginnote(Best purchase ever! I primarily use it with Zoom or to display the YouTube chat when I'm doing solo streams)}}}
The primary Mac screen is where I set up streams and drive Logic from. It feeds into the ATEM mostly so I can see it in the preview window or full size when I need to without having to have a another screen, but if I ever get a second camera, I'll break mac screen 1 out to its own monitor and dedicate input 2 to that secondary camera. Input 4 is a Raspberry Pi that I use for motion graphics. This used to be a copy of chromium running in kiosk mode to display the [[https://ko-fi.com/pdcawley][Ko-Fi]] stream widget which displays donations as they happen, but I've recently managed to compile OBS studio with a working browser plugin and I'm using that instead now, which should allow me to add more overlays later. The only catch with that is that I've not yet managed to get [[https://bitfocus.io/companion/][Companion]] to compile, {{{marginnote(Companion's a brilliant app for controlling AV gear via a web interface or Stream Deck. I know it works on the Pi because they provide OS images for it.)}}} so I think I'll have to move that onto the Mac.

{{{newthought(This all worked fine)}}} until recently. You see, the thing I love about unaccompanied singing is singing harmonies. And harmonies don't work unless the timing is properly tight. That means I can't sing harmonies with Zoom guests because the speed of light{{{marginnote(and video and audio compression and decompression)}}} screws things up completely. I got around this by harmonising with myself -- either by using a Looper plugin in Logic[fn:7] or just by using Logic's multi-tracking[fn:8] to record multiple layers of a song's chorus. It all works, and works well, but I could never work out how to record harmonies for shanty type refrains.

Consider:
#+begin_verse
Oh the rain it rains all day long
  /Bold Reilly oh, bold Reilly!/
And them Northern winds they blow so strong
  /Bold Reilly oh's gone away/

*Chorus:*
  /Goodbye my sweetheart, goodbye my dear-o/
    /Bold Reilly oh, bold Reilly/
  /Goodbye my darling, goodbye my dear-oh/
    /Bold Reilly oh's gone away/
#+end_verse

Ideally, I want to be layering up harmonies on the /Bold Reilly oh, bold Reilly!/ and /Bold Reilly oh's gone away/ lines within each verse, as well as on the chorus (and potentially on any chorus repeats too). It should be possible to set up Logic's live looping feature to enable this sort of thing, but I could never work out how, and I wasn't ready to switch to Ableton Live (where I couldn't be sure I knew how to make it work either). So I stuck to just harmonising on the chorus and wishing there was a better way.

*** Enter [[https://loopypro.com/][Loopy Pro]]!

I'll write a full review of Loopy Pro one of these days, but suffice it to say, there is now a better way. Loopy Pro is the long awaited successor to Loopy HD, a software looper for iOS. It's been a very long time coming, but by god, does it deliver! As well as being a looper, it's a great replacement for MainStage and (at least for live use) Logic Pro, and it runs on even pretty ancient iPhones and iPads. It's predecessor was remarkably capable, but was 'just' a looper with a configurable number of loops available. Loopy Pro is fully customisable, supporting any number of loops, one shot samples, beat slicing, AUv3 hosting, mix busses, control widgets, faders and dials. There's a deep system of actions and 'follow actions' that allow you to customize its behaviour as well as its appearance, and the audio routing capabilities could embarrass some far more expensive DAW software. It's astonishingly capable.

#+caption: Loopy Pro configured for singing 'shanty' structured chorus songs
[[/ox-hugo/shanty-view.png]]

I've been fiddling with it since it was released, and now have it set up to allow me to sing shanty style songs with harmonies on the refrain as well as stuff like this:

@@hugo:{{< embed "https://youtu.be/hWPmADRfPFQ" />}}@@

so now I'm running Friday night stream audio from the iPad, leaving the Mac to run Zoom. This has all been made /much/ easier since I added a new audio interface: the iConnectivity [[https://www.iconnectivity.com/audio4c][AUDIO4c]] interface is a remarkable bit of kit. Uniquely, as far as I can tell, it can be used as an audio interface simultaneously by my mac and my iPad, and can route audio from the iPad to the mac and vice versa. It's got four inputs and six outputs, which is two more than existing interface. That means I can have my guest and me fed to the ATEM mini on separate channels, as well as giving myself a different headphone mix. And it's only one rack unit high!
#+begin_marginnote
Focusrite "small" interfaces, which are what I've used up to now are all about 1.5U high unless you buy the versions with 8 preamps -- lovely bits of kit, but rather more than I either need or can afford.
#+end_marginnote

The remaining bit of the puzzle is to reliably capture the iPad display. I'm looking for, and so far failing to find, a powered USB-C hub that has a bulletproof iPad HDMI connection and gigabit ethernet, which is much more reliable when it comes to remote control of the ATEM. It's a frustrating search. Everything I've found so far has intermittent HDMI dropouts, which would be annoying enough if it weren't for another 'feature' of iOS and iPadOS.

{{{newthought(It works like this:)}}} on iDevices, you don't have the option to choose which audio interface you want to use, instead the OS autoselects whichever interface was plugged in most recently. Which would be fine (sort of) if it weren't for the fact that an HDMI connection to an audio capable device is treated as a new audio interface. So... if the HDMI connection was reliable, getting prepped for a stream would just involve unplugging the audio interface from the hub, connecting the HDMI and reconnecting to the AUDIO4c. But then the HDMI drops and comes back, and suddenly /it/ is the most recently connected interface and the stream's audio is buggered.

If you know of an iPad friendly USB-C hub that has rock solid HDMI, then I'd love to hear about it because my search is getting really frustrating. Right now I'm working around it by disconnecting the audio, screen sharing to the Mac and reconnecting the audio, but even with a dual screen mac set up, screen sharing takes over both screens{{{marginnote(Well… it takes over one screen and fades the other to black. Thanks Apple!)}}} and the whole thing has a bunch of latency that you don't really want -- it's surprising how little latency will start making audio software in particular seem seriously out of sync. I can correct for that when editing, but not so much on a live stream.

But… once I have reliable HDMI from the iPad I run into another problem. Where do I plug it in? Suddenly four inputs on the ATEM aren't really enough.

Time to start saving up for an ATEM Mini Extreme ISO, which is the extra-wide version of the ATEM Mini Pro ISO, complete with 8 HDMI inputs, 2 HDMI outputs, 2 USB-C connections, a 3.5mm audio jack output (so I can monitor the audio going to the stream rather than just looking at the VU meters on the multiview display) and something called a 'Super Source', which would definitely simplify the business of setting up the split screen view when I have a Zoom guest.
#+begin_marginnote
Because of restrictions in the way the ATEM Mini Pro ISO works, I have to sit to one side of the shot because I can only adjust the scale, crop and position of one video source at a time. The Super Source deals with all that.
#+end_marginnote

The extreme version appears to fix pretty much everything that I find slightly annoying about the Mini, which is brilliant, but could be brillianter. Ah well, a boy can dream.

If you're interested in seeing what all this technology ends up looking like on stream, then I stream at 8pm UK time every Friday night on my [[https://youtube.com/c/PiersCawley][YouTube channel]]. Maybe pop by, and if you like what you see and hear, don't forget to like and subscribe.


** DONE Quick site update
CLOSED: [2022-04-28 Thu 13:01]
:PROPERTIES:
:export_file_name: 20220428-quick-site-update
:export_hugo_custom_front_matter: :syndicate true
:export_hugo_custom_front_matter+: :tweet "I've been doing a bit of gardening on my blog and hopefully setting up auto tweeting too."
:export_hugo_custom_front_matter+: :syndicated_at '((twitter . "https://twitter.com/pdcawley/status/1519655434818408448?s=20&t=JN0DWp5MSMU_IoGk-NnyvA"))
:END:
I'll get back to the gory details of my webmention catcher later, but I've been doing a bit of site gardening. Hopefully this means that our index page is looking much nicer, and things are a bit more parseable by IndieWeb tools.

Also, I hope, I've added some gadgetry that means that [[https://brid.gy][brid.gy]] will automatically tweet a link to this page once I've posted it.

** DONE We Deserve Better
CLOSED: [2014-01-11 Sat 11:01]
:PROPERTIES:
:export_hugo_slug: we-deserve-better-than-this
:export_file_name: 3408_we-deserve-better-than-this
:END:

{{{newthought(One hundred years ago)}}}, we got caught up in a really stupid war. War’s never what you’d call a good idea, but the first world war is the benchmark of stupidity (unless you’re Michael Gove, but he’s fast becoming the new benchmark of stupidity).

Something strange happened at the end of the war. In 1914, only around 30% of the adult population had the vote. By February 1918, a general election was years overdue. The Russians had killed the Tsar and were embracing communism; the women’s suffrage movement was threatening to start up again; and millions of returning soldiers — men used to violence by now — would have no say in how they would be governed.

#+hugo: more

Parliament read the tea leaves and passed the [[http://en.wikipedia.org/wiki/Representation_of_the_People_Act_1918][Representation of the People Act]], extended the franchise to all men over 21 and many women over 30. This tripled the size of the electorate, 43% of which was now female (if they’d allowed younger women the Vote, then women would have had a clear majority because the war had killed so many men. Voting ages were equalised in 1928).

In the election, not much changed. The Tories won the most seats with a new class of MP, mostly coming from trade and commerce. Labour’s share of the vote  increased dramatically, but the nature of the electoral system meant they only won 57 seats (fewer then Sinn Féin, who basically won Ireland). The Liberals came third, in the popular vote (second in seats, first past the post really sucks) but Lloyd George remained prime minister promising a land “fit for heroes”.

He didn’t deliver. The Irish had to fight for their independence and won it  in 1921 (ooh look, another stupid war) and in the 1922 election Labour took over from the Liberals as the second party British politics.

Without the first world war, I wonder how long it would have been before parliament was shamed into extending the franchise to all adults. The expanded electorate may not have got the government it deserved, but the Vote was won.

*** Time passes…

Seventy years ago, the next big war ended. This time the returning soldiery weren’t going to be fobbed off with fine words and broken promises. Young men came home from defeating fascism in Europe and saw a sitting government still dominated by the party that had blundered into the war in the first place, still promising more of the same. They heard the Labour’s promises of full employment, a National Heath Service, a cradle to grave welfare state and a compelling vision of the future. And they voted Labour. Oh, how they voted Labour.

Labour won the kind of majority that politicians dream about and went straight to work. Attlee’s government nationalised roughly 20% of the economy; built social housing and encouraged the growth of new towns; introduced national insurance, unemployment benefit and the family allowance; expanded on the universal free education introduced with the Education Act of 1944; and created our National Health Service and what came to be known as the “Postwar Consensus”.

In five years.

In the face of austerity that made our current conditions seem like the lap of luxury.

They didn’t just deliver homes, health and education. They found money for the Arts Council too. Because once you’ve dealt with the worst that physical poverty can bring, shouldn’t you look to do something about poverty of aspiration too?

Few revolutions are so successful. No others have achieved so much without violence. A generation came back from war, said to itself, “We deserve better than this” and /did something about it/. If you’ve got a grandparent living who voted in that election, go and thank them. Stopping Hitler was a towering achievement, but our grandparents managed to surpass even that.

*** Never knowingly not evil

The Tories /hated/ it. Every time they’ve had power since they’ve chipped away at the Postwar Consensus. They’ve had to be sneaky about it though. Once you’ve won the right to fall ill without fearing bankruptcy; once your children are guaranteed a decent education; once you have a roof over your head that isn’t two pay cheques away from being taken away… Well, you get attached to such things.

The 1944 education act was a Tory act, and rather than replace the old system, it /added/ state schools to the mix. The rich were able to opt out and keep their children in the public school system. The public schools and their associated ‘old boy’ networks survived. Etonians don’t just learn Latin and Greek and the art of fagging; they learn that glib smoothness, the art of masking base and selfish motives behind the a veneer of affability. They learn to help their friends and the Devil take the hindmost.

The thing about villains is, they think they’re heroes. They think there’s nothing nobler than helping a chum. They think the world is just. If you’re blessed with the kind of money that Cameron and Osborne inherited you’re going to convince yourself that you somehow deserve your wealth. And if you deserve your wealth, then it’s a small step to thinking that the poor deserve their poverty.

If the world is as it is because everyone deserves their station, then the welfare state is going to seem like the next best thing to evil. The state wants to take some of your money and use it to pay some loser’s rent? It wants to give a drunk a liver transplant? Disgusting! If those people /really/ cared about keeping their home, they’d get a decent job — it’s not hard, just have a word with a friend. And the drunk has only himself to blame. They’ve made their bed and they should lie in it.

The real trick though, is convincing those who really are a pay cheque or two from disaster (which is pretty much anyone with a mortgage or in private rented accommodation when you stop and think about it) that the enemy is the poor bastard on benefits. Not the landlord who banks their housing benefit. Not the employer who doesn’t pay a living wage; who lets the taxpayer top up their employees’ pay packets. And certainly not the government which won’t let local authorities build new social housing to help reduce housing costs (which would pay for itself in short order).

This government has that down pat. They’ve used a financial crisis — one whose seeds were sown when Thatcher and Reagan deregulated the markets and fertilised by every bloody government since (there are no innocents in this fiasco) — as the excuse and are dismantling what was so hard won by our grandparents. A government that promised “No top down reorganisations of the NHS” is gutting it. The poor are being forced out of rich areas by the benefits cap and the bedroom tax. The young are… oh god, the young… the coalition seems to read /[[http://en.wikipedia.org/wiki/A_modest_proposal][A Modest Proposal]]/ as sound policy. When I went to university, my fees were fully paid (Thatcher had frozen maintenance grants, not that I’d’ve got one after means testing). My step-grandson is looking at a /minimum/ debt of £27,000 — assuming he can live for nothing. If you’ve got the cash to get your kid the best education money can buy, you don’t want some bright lass from the local comprehensive competing with them for the plum jobs. Pull up the ladder Jack!

It doesn’t have to be like this. Ask yourself how it is that, in 1945, when the country was on the bones of its arse with precious few lines of credit and an industrial base battered by years of bombing we built a welfare state and a national health service that have lasted for seventy years? Ask how we could, at the same time, find the money to subsidise the Royal Opera House and Sadlers Wells and many other arts organisations? Ask how we could afford, as a country, to support our university students so they could spend their time concentrating on their degrees and the life of the university and not miring themselves in debt?

Ask how we can afford /not/ to do those things now.

There is no excuse for what our government is doing to the poorest among us. Or for what it’s doing to the middle classes come to that. An underclass is handy thing. They keep those on lower middle incomes so bloody scared of falling into poverty that they’ll put up with gross abuse just so they can hang on to what they have. Some guard their little portion with such jealousy that they will not just tolerate the abuse of the poor, they will be baying for blood.

It pains me to say this, but not everything the coalition has done is evil. And I don’t just mean Equal Marriage. Even Michael “Stopped Clock” Gove’s been right about something — the emphasis on learning to code rather than merely drive Powerpoint and Microsoft Word is a good thing. The gov.uk initiative is good news — anything which reduces the influence of KPMG, Capita, G4S and their cronies (and which employs so many of  my more technical friends) can’t be bad. But a ‘good in parts’ government is still intolerable.

There’s an election due in 2015. 2015, the 70th anniversary of the Attlee revolution. It’s time to do it again. Vote. Vote progressive. Vote independent or green. Hold your nose and vote Liberal or Labour. Join a fucking party and work to change their outlook. Vote pragmatic. But, whatever you do, vote. /Especially/ if you’re young. Politicians only care about keeping the people who vote happy — if you don’t vote, they’ll ignore you. If it makes some other part of their constituency happy, they’ll shit on you from great height (though I think that may backfire yet — the thing about grandparents is, they tend to like their grandchildren and don’t like seeing them get the shitty end of the stick)

You could listen to Russell Brand and not vote ’cos it’s “irrelevant” — there’s a revolution coming! You could. But you’d be an idiot and you’d be waiting a long time. There’s been one progressive revolution that actually stuck in this country, and that was achieved by voting.

Demand the nationalisation of public goods; the Post Office, Rail, Water, Gas, Electricity. Encourage small businesses and /making/ stuff. Build new public housing. Demand real transparency in markets and government. Fuck landlords. Fuck rentiers.

Change the world. Our grandparents did it seventy years ago. We deserve better. Let’s take a leaf out of their book and do it again.


** DONE Travelling hopefully
CLOSED: [2005-12-06 Tue 03:47]
:PROPERTIES:
:export_file_name: 2005-12-06-travelling-hopefully
:END:

I wonder if the ground state of the photographer is 'dissatisfied'. When
I bought a D100 two years ago I loved it. But it didn't take long for
disenchantment to set in; the frame buffer was too small, I couldn't use
old (and wonderful) manual focus lenses on it, digital noise was horrid
at high speeds, white balance was dodgy and it didn't feel as good in
the hand as my F100.

Some problems could be alleviated by shooting in RAW mode and
'developing' the images with Photoshop, but for all Photoshop's
undoubted excellence, this is awfully labour intensive.

So, when I went to EuroOSCON this year, I left the digital camera at
home, taking the F100 instead. Amsterdam has an excellent pro lab which
did dev and scan, so I managed to have several of my
[[http://flickr.com/photos/pdcawley/sets/1211132/][photos]] online
before the conference was over.

While we were there, Apple announced
[[http://www.apple.com/aperture/][Aperture]], their new pro
photographers' workflow tool. Like [[http://x180.net/][James Duncan
Davidson]], the official photographer, I was excited by the
announcement. According to the information on the website, it addressed
most of what pissed us off about other tools for managing photos. I
think James placed his order that day.

Then, at the beginning of November, Nikon announced a replacement for
the D100: the [[http://www.dpreview.com/articles/nikond200/][D200]]. As
with Aperture, its list of features seemed to have been specifically
written to address all my annoyances with the D100.

I ordered a D200 couple of weeks ago, and Aperture last night. Right now
I'm in an excited state. Hopefully, once the kit arrives I'll manage to
stay here for a while. Until the next shiny new thing comes along...


** DONE Reading Turing
CLOSED: [2013-03-17 Sun 12:49]
:PROPERTIES:
:export_file_name: 20130317-reading-turing
:END:

Some things never disappoint. And reading Alan Turing is one of those
things. In an earlier post I told an incorrect anecdote about Turing,
and Russ Cox pointed me at proof, in Turing's own words, that I was
wrong. I don't know why it's taken me so long, but I finally got around
to reading his
[[http://www.vordenker.de/downloads/turing-vorlesung.pdf][ /Lecture to the London Mathematical Society on 20 February 1947]]./

Wow.

#+hugo: more

Seriously. Wow. He's talking about programming the [[http://en.wikipedia.org/wiki/Automatic_Computing_Engine][ACE]], the
[[http://en.wikipedia.org/wiki/Pilot_ACE]['pilot']] version of which didn't run its first program until 1950. And the
[[http://en.wikipedia.org/wiki/Manchester_Small-Scale_Experimental_Machine][Manchester 'Baby']], the first stored program electronic computer, was more than a year away from running its first program. It sounds like it might be dreadfully speclative and either handwavy or as out there and daft as the usual crop of 'futurologist' type predictions.

As you can probably guess from the fact that I'm bothering to write this
up, it was nothing of the sort. I suggest you nip off and read it for
yourself. It won't take you long and it's well worth your time. Then
come back here and find out if the same things struck you that struck
me.

{{{newthought(Here's the sentence that brought me up short like a slap:)}}}

#+begin_quote
Computers always spend just as long writing numbers down and deciding
what to do next as they do in actual multiplications, and it is just the
same with the ACE.
#+end_quote

I got to the end of the sentence before it clicked that back then a
computer was a human being performing a computation. What we think of
today as 'a computer' was what Turing called 'the ACE' and back then it
certainly deserved that definite article.

Then I read it again and recognised the deep truth of it. Back in
Turing's day, the ACE was planned to have a memory store made up of 5
foot tubes full of mercury acting as an acoustic delay line. Each tube
could hold 1K bits and an acoustic pulse took 1 millisecond to get from
one end of a tube to the other, so the average access time for a single
bit of memory was around 500 microseconds. When it was finally built, it
was the fastest computer in the world, running at the mighty speed of
1MHz. Nowadays we think that a cache miss that costs 200 processor
cycles is bad news and our compilers and processors are designed to do
everything in their power to avoid such disasters. In Turing's day there
were no caches, every time something was fetched from memory it cost 500
cycles. (Well, in 1947 that would be 500 cycles + a year and a half
before there was a computer to fetch the memory from in the first
place).

Curiously, the gold standard of high performance memory in Turing's day
was the same circuit as you'll find in high speed SRAM today - the
bistable flip flop - but done with valves and hope rather than by
etching an arcane pattern on a bit of silicon.

{{{newthought(Turing seems to have invented the idea of the subroutine.)}}} Admittedly
it's implicit in his implementation of a Universal Turing machine in On
Computable Numbers..., but it's explicitly described here. And, rather
wonderfully, the pipedream of extensive code reuse is there in the
computer science literature right from the start:

#+begin_quote
The instructions for the job would therefore consist of a considerable
number taken off the shelf together with a few made up specially for the
job in question.

#+end_quote

There are several moments when reading the paper where I found myself
thinking "Hang on, he means that literally rather than figuratively
doesn't he?" and this is one of them. When your code is embodied in
punched Hollerith cards, a library is just that. Row upon row of shelves
carefully indexed with reusable code stacked on them like so many books.

Elsewhere he says:

#+begin_quote
It will be seen that the possibilities as to what one may do are
immense. One of our difficulties will be the maintainence of an
appropriate discipline, so that we do not lose track of what we are
doing. /We shall need a number of efficient librarian types to keep us
in order./

#+end_quote

That's my emphasis, and ain't /that/ the truth? I'm not sure that Turing
would have foreseen that the nearest thing we have to 'a number of
efficient librarian types' would turn out to be Google's computers
though. One wonders whether he'd be horrified or delighted.

*** Descrimination
:PROPERTIES:
:CUSTOM_ID: descrimination
:END:
Here he is, having painstakingly explained how the use of loops can
reduce the size of a program:

#+begin_quote
It looks however as if we were in danger of getting stuck in this cycle
and unable to get out. The solution of this difficulty involves another
tactical idea, that of 'descrimination'. ie. of deciding what to do next
partly according to the results of the machine itself instead of
according to data available to the programmer.

#+end_quote

And there we have the nub of what makes computing so powerful and
unpredictable. The behaviour of any program worth writing isn't
necessarily what you expect because it's making decisions based on
things you didn't already know (if you already knew them, you wouldn't
have to compute them in the first place). This is why I'm optimistic
about AI in the long run. I think that given that the behaviour of a
single neuron is understandable and simulatable then, eventually we'll
manage to connect up enough virtual neurons and sensors that the
emergent behaviour of those simulated neurons is as near to a 'real'
consciousness as makes no odds. I'm far less convinced that we're ever
going to be able to upload our brains to silicon (or whatever the
preferred computing substrate is by then). Whether we'll able to
communicate with such a consciousness is another question entirely,
mind.

*** Job Security Code
:PROPERTIES:
:CUSTOM_ID: job-security-code
:END:

#+begin_quote
The masters are liable to get replaced because as soon as any technique
becomes at all stereotyped it become possible to devise a ssystem of
instruction tables which will enable the electronic computer to do it
for itself. It may happen however that the masters will refuse to do
this. They may be unwilling ot let their jobs be stolen from them in
this way. In that case they would surround the whole of their work with
mystery and make excuses, couched in well chosen gibberish, whenever any
dangerous suggestions were made

#+end_quote

Oh, did Turing nail it here. 1947 and he's already foreseen 'job
security' code. I've seen this kind of behaviour all the time and it
drives me up the wall. What the peddlars of well chosen gibberish always
fail to see that, if you get it right, the computer ends up doing the
/boring/ parts of your work for you. And your time is then free to be
spent on more interesting areas of the problem domain. Software is never
finished, it's always in a process of becoming. There's a never ending
supply of new problems and a small talent pool of people able to solve
them; if you're worth what you're paid today then you'll be worth it
again tomorrow, no matter how much you've delegated today's work to the
computer. And tomorrow's work will be more interesting too.

Automating the shitwork is what computers are /for./ It's why I hate the
thought of being stuck writing code with an editor that I can't program.
Why I love Perl projects like Moose and Moo. Why I'll spend half a day
trawling [[http://metacpan.org/][metacpan.org]] looking to see if the
work has already been done (or mostly done - an 80/20 solution gets me
to 'interesting' so much quicker).

Job security code makes me so bloody angry. There are precious few of us
developers and so much work to be done. And we piss our time away on
drudgery when we simply don't have to. We have at our fingertips the
most powerful and flexible tool that humanity has ever built, and we use
it like a slide rule. Programming is hard. It demands creativity and
discipline. It demands the ability to dig down until we really
understand the problem domain and what our users and customers are
trying to do and to communicate the tradeoffs that are there to be
made - users don't necessarily understand what's hard, but they're even
less likely to understand what's easy. But its very difficulty is what
makes it so rewarding. It's hard to beat the satisfaction of seeing a
way to simplify a pile of repetitive code, or a neat way to carve a
clean bit of testable behaviour off a ball of mud. Sure, the insight
might entail a bunch of niggly code clean up to get things working the
new way, but that's the kind of drudgery I can live with. What I can't
stand is the equivalent of washing the bloody floor. Again. And again.
And again. I'd rather be arguing with misogynists - at least there I
might have a chance of changing something.

I'm not scared that I'm going to program myself out of a job. I'm more
worried that I'm never going to be able to retire because as a society
and a profession we're doing such a monumentally piss poor job of
educating the next generation of programmers and some of us seem to be
doing a bang up job of being unthinkingly hostile to the 50% of the
talent pool who are blessed with two X chromosomes. But that's probably
a rant for another day.


** DONE Big Data and Singing Crowds
CLOSED: [2013-03-17 Sun 10:37]
:PROPERTIES:
:export_file_name: 20130317-big-data-and-singing-crowds
:END:

#+begin_description
I watched the rugby yesterday. England vs Wales at Cardiff Arms Pack. It was a great game of rugby - England were comprehensively outthought by a Welsh side with more experience where it counts, but by gum, they went down fighting to the very end. It's going to be an interesting few years in the run up to the next World Cup.

While the game was going on, I found myself wondering why the crowd's singing sounded so very good.

#+end_description

{{{newthought(I watched the rugby yesterday.)}}} England vs Wales at Cardiff Arms Pack. It was a great game of rugby - England were comprehensively outthought by a Welsh side with more experience where it counts, but by gum, they went down fighting to the very end. It's going to be an interesting few years in the run up to the next World Cup.

While the game was going on, I found myself wondering why the crowd's singing sounded so very good. It's not a particularly Welsh thing
(though /Cwm Rhonda/, /Bread of Heaven/ and the whole Welsh crowd's
repertoire are have fabulous tunes). The Twickenham crowd getting behind
/Swing Low, Sweet Chariot/ sound pretty special too, even if I wish they
still sang /Jerusalem/ occasionally. How come a crowd of thousands,
singing entirely ad lib with no carefully learned arrangements or
conductor can sound so tight?

After all, if you took, say, 30 people and asked 'em to sing a song they
all know, it would sound ropey as hell (unless they were a choir in
disguise and had already practiced). Three or four together might sound
good because, with that few of you, it's much easier to /listen/ to your
fellow singers and adapt, but 30's too many for that and without some
kind of conductor or leader, things aren't likely to sound all that
great.

I think it's a statistical thing. Once you get above a certain number of
singers, the fact that everyone's going to sing a bum note now and
again, or indeed be completely out of tune and time with everyone else,
the song is going to start to make itself heard. Because, though
everyone is wrong in a different way, everyone is right the same way. So
the wrongs will start to cancel themselves out and be drowned by the
'organised' signal that is the song. And all those voices, reinforcing
each other make a mighty noise.

That's how big data works too. Once you have sufficient data (and for
some signals sufficient is going to be /massive/) then the still small
voices of whichever fraction of that data is saying the same thing will
start to be amplified by where the noise is dissipated.

Just ask an astrophotographer. I have a colleague who takes rather fine
photographs of deep space objects that are, to the naked eye nothing
more than slightly fuzzy patches of space, only visible on the darkest
of nights but which, through the magic of stacked imaging can produce
images of stunning depth and clarity.

If you've ever taken photographs with a digital camera at the kind of
high ISO settings that Mike used to take this, you'll be used to seeing
horrible noisy images. But it turns out that, by leveraging the nature
of the noise involved and the wonder of statistics, great photographs
like this can be pulled out of noisy data. It works like this:

Any given pixel in a digital photograph is made up of three different
componants:

- Real light from the scene in front of the camera
- Systematic error which is the same in every image
- Thermal (usually) noise

The job of an astrophotographer is to work out some way of extracting
the signal at the expense of the noise. And to do that, they have one
massive advantage compared to the landscape or portrait photographer.
The stars and nebulae may be a very very long way away. They may be very
dim. But they don't move. Once you've corrected for the motion of the
earth, if you point your scope at the horsehead nebula today it's going
to look the same as it did yesterday and the day before that. Obviously,
things do change, but, from the distance we're looking, the change only
happens on multi-hundred year timescales. This constancy makes the
astrophotgraphers task, if not easy, at least possible.

So... the stars (like the tune of Cwm Rhonda) are unchanging, but the
noise is different with every exposure (that's why it's called noise
after all). Even if, on any given exposure the noise is as strong as the
signal, by taking lots and lots of exposures and then averaging them,
the noise will get smeared away to black (or very dark grey) and the
stars will emerge from the gloom. Sorry. The stars and the systematic
error will emerge from the gloom. So, all that remains to do is to take
a photograph of the systematic error and take that away from the image.

Huh? How does one take a photograph of systematic error? You do it by
photographing a grey sheet. Or, because it's probably easier, by
throwing your telescope completely out of focus so what you see is to
all intents and purposes a grey sheet and taking a photograph (or lots
of photographs - you've still got noise to contend with...) and
subtracting the resulting error map from your stack of photographs and
bingo, you're left with an image that's mostly signal. All that remains
is to mess with the levels and curves and possibly to stack in a few
false colour images grabbed from the infra red or the hydrogen alpha
line where there's lots of detail and you're on your way to a cracking
photograph.

Obviously, it's not as easy as that - telescope mounts aren't perfect,
they drift, camera error changes over time. It's bloody cold outside on
a clear night. Sodium street lights play merry hell with the sky. And so
on. But if you persevere, you end up with final images like the one
above. That sort of thing's not for me, but I'm very glad there are folk
like Mike taking advantage of every clear night to help illuminate the
awesome weirdness of our universe.

Noisy data is a pain, but, we're starting to realise that, if you have
enough data and computing power, you can pull some amazing signals out
of it. Whether that's the sound of thousands of Welsh rugby fans
combining to sound like the voice of God; an improbably clear photograph
of something that happened thousands of years ago a very long way away;
your email client getting the spam/ham classification guess right 99
times out of 100; or Google tracking flu epidemics by analysing
searches, if you have enough data and the smarts to use it, you can do
some amazing things.

Some of them are even worth doing.

** DONE General purpose computing is the /best!/
CLOSED: [2022-05-12 Thu 13:21]
:PROPERTIES:
:export_file_name: 20220512-general-purpose-computing-is-the-best
:export_hugo_custom_front_matter: :syndicate true
:export_hugo_custom_front_matter+: :tweet "I added a Raspberry Pi to my streaming rig on spec, and of course now it's indispensible"
:END:

#+begin_description
Once I'd added the Mac Mini to the rack, there was a space in the bracket it was mounted on that was designed to hold one or two Raspberry Pis. I had a Pi sitting about, so of course I added it to the rig thinking "I'll work out what to do with that later."

It's proved invaluable…
#+end_description

Sometimes folk ask why there's a [[https://raspberrypi.org/][Raspberry Pi]] in the rack case that holds my streaming rig and I admit that the primary reason is that I had one kicking about the place, and the rack unit that holds my M1 Mac Mini is designed to hold a couple of Pis in the space that isn't holding the Mac, so I might as well attach it. I had the feeling it would come in handy.

It turns out, I was right. It runs OBS to handle motion graphics, and Companion to control the ATEM Mini from a streamdeck. In the future I plan to use it as a router so the gear in the rack can live on its own private network with the Pi handling the connection to the outside world either via a network cable or (hopefully not) wifi or a tethered phone.

The latest "Oh, of course! It can do that too!" job it's taken on is pretending to be an Apple TV, so I can mirror my iPad's screen to it without mucking up the Mac's display.

Once again, I'm reminded that computers can be anything you can program them to be... sometimes all at once. The Pi 4 is a mindbogglingly capable bit of kit. I've bought USB hubs{{{marginnote(USB Hubs that don't work!)}}} that cost more and do less than my Pi.

There's a Pi 3 plugged in somewhere{{{marginnote(I think I know where it is, but I'm not entirely sure)}}} that runs [[https://pi-hole.net][Pi Hole]] and helps eliminate intrusive ads from my web experience. It has sufficient spare power that, once I get around to it, I plan to hook up a cheap workhorse laser printer to it and configure it to work as a print server, which should let me retire the crappy unreliable bubblejet printer that only prints when you stand over it with a big stick and is always demanding the blood of innocents{{{marginnote(The printer calls it ink, but have you seen the price of that stuff?)}}} before it'll deign to even try to print something.

About the only thing wrong with them (at the moment) is that they're almost permanently out of stock everywhere. I watch [[https://rpilocator.com/][rpilocator]] and it's clear that people do get stock, but they sell out almost immediately. A chum who works for Raspberry Pi says that they are shipping lots and lots of boards, but the demand stays sky high. Which is a nice problem to have for them, I suppose.
** DONE Migrating to Mastodon
CLOSED: [2022-11-20 Sun 13:59]
:PROPERTIES:
:export_file_name: 20221120-migrating-to-mastodon
:END:

Twitter, eh? Elon bloody Musk!

In the happier timeline, Elton John bought Twitter and it became even more fabulous with every passing day. In the far more depressing timeline we find ourselves living in, Elon seems to be determined to tank the company and fuck the community.

So I've buggered off to Mastodon. At the time of writing, you'll find me at [[https://mendeddrum.org/@pdcawley][@pdcawley@mendeddrum.org]] and, you might even be reading a version of this via Mastodon rather than directly on the site.
#+hugo: more
** DONE More Mastodon fiddling
CLOSED: [2022-11-20 Sun 22:32]
:PROPERTIES:
:export_file_name: 20221120-more-mastodon-fiddling
:END:

There's a certain frustrating joy in fiddling with the details of a thing so as to improve the formatting of the new thing you've just added to your site, and discovering that a side effect of the change is that a couple of niggles that you'd not quite got to the bottom of on the site itself are fixed in passing.

I /think/ I've got the crossposting to Mastodon looking less awful, and I /know/ I've got [[https://bofh.org.uk/][my front page]] looking better. Isn't that lovely?
#+hugo: more
** DONE Impermanence matters
CLOSED: [2023-06-06 Tue 10:43]
:PROPERTIES:
:export_file_name: 20230606-impermanence
:END:


#+begin_description
Cool URLs don't change they say, and that's true. You'll always find my upcoming livestreams at [[https://youtube.com/pierscawley/live]], along with maybe one or two of the previous ones to catch up with. What you /won't/ find is the full three year archive of streams. Here's why…
#+end_description

Back when lockdown started, for all we were both classed as 'critically vulnerable', we did pretty well. We had each other for company, the house is paid for, we have some private outdoor space, Doncaster Market remained open and I'd got a 25kg bag of flour. Life was… tolerable.

Except, as any musician will tell you, making music needs company. At least it does if you catch the magic that happens when a group of people are together making something beautiful. Which is why I started singing folk songs to the internet[fn:9] every Friday night.[fn:10]  At first, I just sang into the dark to the two or three people who showed up in the text chat {{{marginnote(Thank you all of you! You were awesome.)}}} but I was still missing harmonies. So I worked out how to use Logic for live sound and did on the fly multitracking of chorus harmonies and that was great. Recently, I've switched to using [[https://apps.apple.com/gb/app/loopy-pro-looper-daw-sampler/id1492670451][Loopy Pro]] on my iPad[fn:11] and it's been great -- I can sing harmonies on far more songs now and I've started experimenting with fancier arrangements too.[fn:12]

{{{newthought(A key realisation came)}}} after a late night conversation with [[https://johnspiers.co.uk/][Squeezy John]] [Spiers] on Twitter about how a YouTube archive of performances can become a millstone around an artist's neck. After all, if someone can catch a performance online from a couple of years ago, why would they pay to watch you doing it again? I don't think most people think this way, but the life of a professional musician is marginal enough that it doesn't take many to have an effect. So I started making the catch-up videos private after a week. {{{marginnote(Or whenever I got round to it, if I'm honest)}}}

It was incredibly liberating. I stopped worrying too much about repeating myself every week -- I always open with the same song, I usually close with one of about three songs, there's a couple of staples that people seem to miss if I don't sing them and if I fuck something up, it's gone in a week and I can concentrate on doing better next time. My audience seem to be fine with it. If I do something particularly well, or something funny happens like my cat bringing the backdrop down on me

@@hugo:{{< embed "https://youtu.be/kbeFRIqSUZg" />}}@@

then I have the original video files, so I can edit and upload a high quality clip that I'm happy to leave available forever.

And it's closer to the experience of music in person, too. Live music is a magical transient thing that lasts as long as the song and then it's gone. Recordings are souvenirs, they can be delightful, but they simply can't be the same as being in the moment.

It's gone. I might sing it again next week, but just as you can't cross the same river twice, that performance will be different. And that's brilliant.

{{{newthought(I'll tell you what is permanent:)}}} the repeating Friday night entry in my diary that reads ‘Folk Stream.’ It doesn't matter whether I'm streaming for 2 people and no tips or a busy room and £100+ in [[https://ko-fi.com/pdcawley][Ko-fi's hat]], singing to the internet never fails to lift my mood. It's like I've made an appointment with joy.
** PUBLISHED Panning Overdubs in Loopy Pro
CLOSED: [2024-01-13 Sat 18:03]
:PROPERTIES:
:export_file_name: 20240113-panning-overdubs-in-loopy-pro
:END:

#+begin_description
A quick introduction to adjusting the panning of overdubs in Loopy Pro clips, including a link to a miRACK configuration and instructions on how to use it in your own Loopy Pro configurations
#+end_description

It's common practice in music production that, when you're layering your vocals with harmonies or doubles, you pan everything but the lead vocal around the stereo field. That gives a sense of physical separation between the voices and it feels more realistic -- or artificial, if that's what you're going for.

With loopers though, you'll more usually have your overdubs all in the same place, which is fine at the local open mic, where the front of house PA is often mono anyway, but for streamers like me, it feels a little limiting, so I've been working on a way to get that effect.

This is still a work in progress, but enough people expressed an interest when I showed this off in a [[https://www.youtube.com/live/uaP4np4WoAY?si=zPoXvCthRjsDUKEn]["How Do You Loop?"]] chat with John Paul Music UK here.

*** Quickstart

If you don't want the gory details of how the pandomiser works, here's how to add it to your Loopy Pro and get going quickly:

**** Set up miRACK in your project
+ Install [[https://apps.apple.com/gb/app/mirack/id1468259834][miRACK]] from the App store. It's a full-featured modular synthesizer simulator, and it's capable of far more and weirder things than we're making it do here. Check out the examples.

+ Grab the pandomizer bundle from [[/files/pandomiser.zip][my website]] and unzip with the Files app on your iDevice. Copy pandomiser.mrk to your miRACK folder so the plugin can find it.

+ Open the mixer, tap the ⊕ button and choose 'Add MIDI' and choose the miRack 'MIDI FX' option

+ Open the miRACK interface and tap on the four squares icon in the top left, choose 'Open Existing' and load ~pandomiser.mrk~.


**** Set Up Loopy's Audio Routing
I'm a pure vocal looper, so I'm going to assume you have a single audio input for your vocals that's routed to all Loopy's colours. If you've got seperate inputs for your voice and other instruments and not everything is routed to all the colours, you might have to add multiple panning busses, but what follows should give you enough information to get started. This setup also assumes that you don't want to affect the panning of your live audio, only where it gets placed in your loops and oneshots.

+ Add a send to your audio input, choose 'new bus' when prompted, then long press on the send and choose 'After All Effects'
+ Tap 'Destinations' in the new bus and turn off the hardware output channels. Tap the 'all' button to turn on all the Color Destinations.
+ Tap 'Destinations' on your audio input and 'none' to turn off all the Color Destinations

Now your input audio is going to your loops via this new bus, which means we can mess with its balance setting and it won't affect the live sound going to your speakers. We can do /anything/ here, and it won't be heard until the clip it's recorded on gets played out. Use this power responsibly. All we're going to do here is mess with the 'balance' setting.

Let's go.
+ Choose 'Control Settings' from the hamburger menu in the top right of Loopy's screen, then choose 'Default' from the Current Project setting.
+ Tap 'Add New Binding' and choose 'Adjust Parameter' from the *Bus Actions* section. Choose your new bus as the target, and make 'Balance' the parameter.
+ Change *Controller Input Start* to 1%. This avoids the problem that 0-127 doesn't have a central value. If you don't change this, then the bus's balance will get reset to 1 and, if you're anything like me, it will drive you up the wall.

Test everything is working by opening the mixer and bringing up the keyboard in the miRACK window then holding down C4. You should see your panning bus's balance jumping to a new random value, then resetting to the centre each time you press and release C4.

*** Basic Pandomiser use
Here's one simple way of ensuring that all your overdubs are placed at different points in the stereo field using a couple of follow actions.

+ Open *Clip Settings* from main menu, scroll down the settings sheet and choose *Follow Actions*
+ Add an action to *Begin Overdub,* choose *Send MIDI Message* with your miRACK as the target. Send a note, C4 on channel 1 with velocity (*Value* in the Loopy UI) 127 (those all the defaults for sending a note, by the way).
+ Go back to Follow Actions and tap the 'Reorder' button, now press and hold the follow action you just added and drag the new action down to *Finish Overdub*.
+ Open the new action and drag the *Value* slider down to zero.

Now, whenever you overdub a clip, as soon as your overdubbing starts, Loopy will 'hold down' C4 and the pandomiser will set the recording balance to a new random value. Once overdubbing stops, Loopy will 'release' the key and the balance will return to the centre.

*** Complicating things

In my Loopy setup, I don't want to change the balance of every overdub of every clip. There might be a couple of clips that will be overdubbed for each verse of the song, and I want the pan to remain the same for each overdub associated with the verse. So I can set the first clip to send the ~noteOn~ message when I start overdubbing and set the second to send a ~noteOff~ when I finish.[fn:13] You might only want to mess with the panning for certain colours, or even for specific clips, or you might want to set up widgets to record with or without messing with the panning. All you have to do is send C4 to miRACK when you want to randomise the balance, and release C4 when you want it reset to the centre. Have fun.


*** How does it all work?

A modular synthesizer like miRACK thinks in terms of voltages, and those voltages can mean different things. We use a midi trigger input module that we've configured to send +10V whenever C4 is held and we connect that to the *Gate* input of a Sample & Hold (S&H) module, which we're using as a source of randomness. Whenever the modules *Gate* voltage goes high, the module 'samples' the voltage at its input, and sets its output voltage to the same until the next time it detects a rising edge. If there's nothing connected to the input though, it /samples/ an internal noise generator and outputs that voltage. I've configured the module to so that its noise source is a white noise generator a range of ±5V, and we can think of that as ranging from a hard left pan at -5V through the centre at 0V and on to a hard right pan at +5V.

 The output of the S&H module is now jumping to a new random value every time we press C4, but we really want to output 0V when C4 isn't pressed, so we feed its output into the input of another staple of a modular setup, a Voltage Controlled Amplifier (VCA). We've set this VCA up at unity gain, which means that, when it sees 10V at its Control Voltage (CV) input, it outputs, it sends 100% of its input voltage to its output, and when it sees 0V CV, it sends 0% of its input. So, if we connect the C4 trigger to the VCA's CV input, we've turned it into a gate -- whenever C4 is held, the VCA sends the random voltage from S&H, otherwise it sends 0V.

Now we just need to convert that into something MIDI understands, an unsigned value between 0 and 127. The *MIDI CC Output* module can do some of this for us, but it's expecting a voltage in the range 0--10V, and right now we've got something in the range of ±5V. So we feed the signal from the VCA into the A input of a *CONST ADD MULT* module, set the constant to 5V, and feed the associated A+B output to one of our CC outputs that we've configured to send CC8 to our host app. Job jobbed!

*** Next Steps
I think the next version of this will allow me to sequence balance for the first few steps, so it might go: hard left, hard right, mid left, mid right, then random pans until the system is reset. I have ideas about how to implement this too, but if you beat me too it, please let me know!

I'll also be making a YouTube video walking you through it (think of this as a draft script for that video).
** PUBLISHED A Guest's Guide to Zoom Song Swaps
CLOSED: [2024-03-04 Mon 08:51]
:PROPERTIES:
:export_file_name: 20240225-a-guest-s-guide-to-zoom-song-swaps
:END:

This is intended as a quick guide for anyone who comes on as a Friday night Song Swap guest, but anyone who's thinking of using Zoom (or doing their own streams) to share music with folk might find it useful, so I'm making it public.

#+hugo: more

*** Publicity material
I'm absolutely terrible at marketing, but it will definitely help me do at least /some/ if you can provide me with some or all of the following:


**** A photo of you that you don't hate
If you've got a standard headshot or publicity photo, that's great. I'll use that to make the YouTube preview card.

If you don't, here's a few tips for taking your own. These are basic guidelines, not rules. You can ignore all of them and still get a great photo, but if you follow them, you should at least get a decent one.

***** Your phone is fine
Seriously, I would have killed for something the quality of even my iPhone SE back when I first started doing digital photography.

***** Try to enjoy yourself
If you don't like having your photo taken, it can show and you'll end up with another photo you don't like, so try this. For the duration of the shoot, pretend you're playing the part of someone who actually likes having their photo taken. Weirdly, that will almost certainly make the shoot go faster because you'll get a good shot nice and early and you can stop pretending.

***** Get a friend to take the photo
It's just easier. You can use a tripod or a selfie stick, but another human being's your best choice. If you've got a friend who's an experienced photographer, then for heaven's sake ask them and ignore the rest of this list -- be guided by them. Or book a session with a professional if you have the time, money and desire.

***** Use a big light
/Big/ light sources are the most forgiving and flattering ones. I like a nice big north facing window, or bright overcast days. It's not exciting or dramatic light, but that's fine.

***** It's not a firing squad
You know the typical passport photo shot? The one where you look like you've been lined up against a wall, standing square to the camera and looking nervous. Don't do that.

Here's a pretty foolproof lighting/posing idea:

1. Stand facing the biggest window you can find at a time when the sun isn't shining directly through it.
2. Turn about 45° to the left or right
3. Look across at your friend with the camera who's standing at 90° to the window light.
4. Your friend will, of course, take an otherwise fabulous photograph of you with your eyes closed, so repeat the last step until they manage a shot you like.
5. *CHECK YOUR BACKGROUND!*
   Make sure there's no dead flowers apparently growing out of your ears, an embarrasing cat licking its arse, or a pile of washing in the shot.

   Ideally you'll have a nice smooth out of focus thing going on there (portrait mode, if your phone has it can help), but if you can't manage that, shoot for something that's not too busy. You can't go far wrong with a bookshelf, but stand as far away from it as you can so it's not tack sharp and distracting.

***** Portrait or square format, please
Bear in mind that I'm going to be putting your photo into a square frame in the YouTube title card, so a wide image probably won't work too well.

**** Some links
Got a website? Bandcamp? YouTube channel? Tell me about them and I'll link to them in the event description and during the show.

**** A short biography
When I make the YouTube event for a song swap, I write something about my guests. I'll write something anyway, but it really helps if I've got something from you to base it on. After all, I know what I think about you, and I like you or I'd not have asked you to be my guest, but unless you /tell/ me, I don't know what you think is important about yourself. A short bio can really help there.

**** [Optional] Some talking points
A song swap isn't some kind of forensic interview process; it's supposed to be an informal chat interspersed with songs. If there's something you really want to talk about, please let me know. The same goes if there's anything you want me to steer clear of. It's fine if the conversation gets dark -- folk music's full of murders and misogyny after all -- but it's really not fine if it gets uncomfortable for you.

*** Tech
Zoom isn't my favourite piece of software and its default settings are definitely slanted towards business meetings rather than helping musicians sound good. The most important thing you can do in your Zoom settings is to turn on 'Original Sound For Musicians', which should show up in the top left of your screen. It's off by default, so click it and turn it on. If it doesn't show, you'll need to dig into Zoom's audio settings and check the box to make it available.

There's a catch: turning on original sound disables /all/ of Zoom's audio processing, including the echo cancellation magic, so it's really best if you can use a pair of headphones or earbuds rather than speakers to hear me. Or you can just remember to turn original sound on when you start singing and off again when we start chatting. Headphones are easier though.

If your laptop or phone's built in camera and microphone are all you have, don't worry, we can work with that. They're not the best, but they are optimised for someone sitting within reach of the keyboard and making human noises from their mouth hole. You'll look and sound fine.

If you've got money to spend and you want to look and sound better on stream then I have a few suggestions, but this is an area where there's no right answers, so do shop around and talk to anyone you know who you reckon looks good on your Zoom calls.

Prioritize your spending on gear. In general (and especially for musicians) sound is more important than lighting, which is more important than camera quality. A pin sharp, beautifully lit video of a muddy sounding performer is much harder to watch than a blurry, crystal clear sounding performer singing in a murky cave.


**** Some audio suggestions
If you're an unaccompanied singer, this is pretty easy because we don't have any problems getting your sound balanced and into Zoom. If you're an instrumentalist, or a band, things get a little more fun, so let's break it down based on the number of mics you'll need.

Bear in mind that there are entire books written on this subject; I'm barely scratching the surface here. If you're serious about getting good sound for streaming and/or recording, it's worth doing your own research. If all else fails, for your upcoming song swap, buy some of the gear recommended here from a reputable mail order site and rely on the 30 day, no questions asked returns policy they all have because that's a legal requirement in the UK. But MAKE SURE that when you know what you /really/ want, you buy from the same supplier.

***** One mic wonders
If the sound you make in the room is the sound you're happy with (unaccompanied singers, acoustic guitarists, acoustic bands) then it's just a matter of choosing between a USB mic and an XLR mic with an audio interface. Unless you're in a particularly noisy environment, I'd recommend some kind of condenser mic. The Blue Yeti has been the standard starter USB mic for years and you could do far worse than do that yourself. However, I would definitely recommend going down the slightly more expensive XLR mic and audio interface route as it's significantly more flexible and upgradeable.

You'll want a cardioid pattern large diaphragm condenser microphone (I love my Aston Spirit which looks and sounds great, but it's a multi-pattern mic and nearly £300 new). Brands like Rode, Aston and SE Electronics make great mics, and honestly, pretty much anything that comes up on an Amazon search for 'large diaphragm condenser microphone XLR' will still sound better than your laptop or webcam's microphone. You'll use a balanced XLR cable to connect that to your interface (a cheap cable's fine, more expensive ones with Neutrik brand connectors and the like might prove more durable and/or reassuring.)

With a single mic setup you only /need/ a really basic audio interface. Something like the Focusrite Scarlett Solo or 2i2 or any cheap class compliant USB audio interface will do the trick so long has it has phantom power available. Just plug your interface in, connect the mic, turn on 48v/phantom power and tweak the gain until, at your loudest you're not quite going into the red on the meters, select the interface in Zoom, turn on direct monitoring and you're good.

***** Fun with multiple inputs
If you're a band, or a guitarist where you want to adjust the balance between your voice and your guitar, you're going to need something a little more sophisticated. How much more sophisticated is up to you, of course and I'm a little out of my depth here, but I've got a few suggestions anyway. Don't hesitate to chat to any live sound engineers of your acquaintance -- buy the sound engineer at your local open mic a drink and quiz them, for instance.

The thing to remember here is that Zoom is pretty crap when it comes to audio handling -- it doesn't know anything about pro audio gear, it just expects to receive a mono mix on the first channel of the audio device you select (or a stereo mix on channels 1&2 if you turn stereo on in the audio settings), so you'll need to do the mixing yourself, either with a standalone mixer, the facilities of your audio interface or some other software on your computer.

I'm going to ignore the software option, but investigate software like Loopback on the Mac and Voicemeeter on Windows. Using your audio interface can be more or less easy, depending on what capabilities the interface has, of course. Modern interfaces are generally more capable in this area. I've not actually tried it, but something like the Zoom AMS-24 looks like it would be ideal for a guitarist (put it in 'streaming' mode and turn off loopback).

Once you get past a couple of input channels, you're going to have to go down the mixer route. You can either get a dumb mixer with at least as many inputs as you have instruments and mics, sort out your stereo mix and feed that into a simple two channel audio interface, which will make Zoom happy. That's fine if you're primarily interested in live performance, but if you want to do any recording, you'd be better off with a mixer that can also work as a multi-channel audio interface so you can record your vocals and instruments in separate tracks. Something like the Roland GigCasters or the RodeCaster II, for instance. I think Mackie do something in this space too, but I've not used any myself, but I do know there are plenty of options.

If your guitar's got a built in mic or pickup, just plug it into your mixer with a balanced cable, otherwise, you'll need to mic it up too. There's whole books written on mic placement, but it's generally accepted that a good starting point for micing an acoustic guitar is to point the mic at the place where the neck meets the body rather than at the sound hole, maybe a foot or so away. Again, if you know anyone with any audio engineering experience, then talk to them not me.

Once you've got your mixer, you'll need mics. Generally you'll be close miking things to allow you to mix the different sound sources (if you get lots of bleed between mics, then you have fewer options when it comes to mixing). In /theory/ you use a condenser mic for all these things, just put them close to your mouth or mic, turn the gain down and rely on the inverse square law to give you some separation. In practice, it's more common to grab a dynamic microphone or two and use them. The canonical mic for the job is probably the Shure SM58, which is built like a tank and looks exactly like you think a stage microphone should look. The SM57 is well regarded as an instrument mic too, and there's plenty of knock-offs of both. I have an SE Electronics V7, that I use for open mics which sounds pretty good too.

It /really/ helps to have someone else fiddling with the knobs to get your sound dialled in, because they're not hearing the sound in your head. With decent headphones on, they're primarily hearing the sound that's going through the mixer, so they can have a better chance of getting pre-amp gain dialed in, EQing your voice an instruments so they don't overlap too much and balancing your levels nicely. If /at all/ possible, get some help here.

EQing is a dark art that I'm only vaguely aware of, and mostly don't have to worry about anyway as an unaccompanied singer. I mostly just leave things flat and hope. There's plenty of advice to be found on YouTube or sites like Sound On Sound, so I recommend investigating those.

**** Lighting Suggestions

Again, there are entire books on this, and there's no end of gear you can buy if really fall down the rabbit hole. Elly Lucas made a great [[https://youtu.be/fYYzN2E8eX4]['Visual Content Level Up Tutorial']] that's a great starting point.

Seriously. Just watch that. I was going to write more, but she covers pretty everything I was going to say.

**** Cameras

If at all possible, don't use the webcam in your laptop. Investigate ways to use your phone as a webcam. Certainly that's possible if you're in Apple World -- Zoom can treat your iPhone as a webcam and the camera in your phone is substantially better than almost any webcam you can find. If you've got a mirrorless or dSLR camera, more recent ones often have software that lets you use them as a webcam -- check your manufacturers website. If they can't be used directly as a webcam, check whether they have what's referred to as a 'clean HDMI' output and look at getting a cheap and cheerful usb HDMI capture card (or spend rather more on something like the Elgato Camlink. I went with the cheap and cheerful option and it's fine).

Stick your camera or phone on a good solid tripod, wobbly cameras are really distracting. And level is great. You don't want people wondering why the things on your shelves aren't sliding off. Plain backgrounds make this less critical.

If you're shooting for a solo video, you probably want to frame things so you're slightly off centre in the frame. However, it makes life much easier for me setting up the Song Swap if you frame yourself in the middle of the shot. One of these days I might fix things so that's not necessary, but for now centred is best.



**** Set dressing

Plain walls are great. If you can arrange to hang something like a duvet behind you, that acts as quick and dirty audio treatment of your room. I have a duvet and a rug hanging behind me as a background and it definitely helps with the sound. Getting some distance between you and your background helps blur it a little and make it less distracting.

The advice on making your own headshot applies here as well.

*** What to expect
The aim of a song swap is to have a good old natter and sing a bunch of songs and to enjoy ourselves while we do it. It's not an interview, if only because I'm a terrible gobshite with a tendency to go off on tangents. Don't hesitate to tell me to shut up. I try to rein myself in, but every time I watch a show back I think "Yeah, you could have shut up a bit more there Piers."

If you're the sort who likes a set list, I'd suggest planning to cover as much material as you'd get through in a forty minute folk club set with maybe a couple of encore pieces. Nobody's run out of material yet.

It's a song swap tradition that the first question I ask a new guest is to ask them to talk about their first encounter with Martin Carthy, whether in person or recorded. Chris Manners memorably [[https://youtu.be/_wjZAKqdZdg][described first hearing Martin singing /The Bedmaking/ on the John Peel show]] playing a guitar 'hard enough to drive rivets through concrete walls' and rearranging his entire world. My first encounter was at the Soles and 'Eels folk club in Northampton. Everyone had hyped the gig up beforehand like it was the Second Coming and I bloody /hated/ it. Martin was great, as usual, I just wasn't in the right place to realise that. We're not about gatekeeping here though, so if you don't know who I'm talking about, let me know and I'll probably ask you how you came to discover you were a musician.


**** Payment
The show is supported by people chucking money in the virtual hat at [[https://ko-fi.com/pdcawley]]. On the following Monday, I tot up the total takings and send you half through the magic of Paypal.

** DONE Fiddling with structural templates in ~Org-mode~
CLOSED: [2025-08-27 Wed 21:59]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 20250827-fiddling-with-structural-templates-in-org-mode
:EXPORT_FILE_NAME: index
:END:

 #+begin_description
I spent a few hours reducing a small annoyance related to the way I use Emacs to maintain its literate configuration file by incrementally implementing slightly better processes until I reached the point where it was Good Enough to spend several more hours writing it up for the blog.

Not an elevator pitch for Emacs.
 #+end_description

I've been dealing with some enduring niggles in my literate Emacs configuration, and have just landed [[https://github.com/pdcawley/dotemacs/commit/dbc316bfca27a37319b5316ea1281ccbebd526aa][Commit dbc316b]], and I thought I'd write about it here because it's an example of what keeps me on Emacs more than thirty five years after I first started using it.

Back when I started, Emacs was merely a text editor that felt easier to use than =vi=, but these days, it's all that and more. I don't live in Emacs quite as much as I used to; I don't hang on USENET or IRC any more, and I check my email as little as possible, so I've not got around to configuring Emacs for that again.
#+begin_marginnote
Back in the day, it all went through the behemoth that is GNUS, but I lost that version of my =.emacs= file several computers and ISPs ago.
#+end_marginnote

These days, what I like about Emacs is it's malleability. It's not uniquely malleable, either. Vim and Neovim diehards will no doubt have tales to tell about their setups, but Emacs is my editor. There are  others like it, but this is mine.

I've been seduced by the Literate Programming idea of maintaining my [[https://github.com/pdcawley/dotemacs][=~/.emacs=]]
#+begin_marginnote
Emacs used to keep its config in a file in your home directory called =.emacs=, then it moved to =\~/.emacs.d/init.el=, which made it a little easier to break a big config out into multiple files. These days, Emacs looks first in =${XDG_CONFIG_HOME}/emacs=, which defaults to =\~/.config/emacs= and that's where my config files live today.
#+end_marginnote
file in a single =org-mode= file, which gets 'tangled' into =early-init.el= and =init.el=, which are the files that Emacs actually loads.

One feature of Org mode's literate programming support that I rather like and take advantage of is the ability to write things out of order and assemble them correctly using =noweb=. The idea is that ~src~ blocks can be named, and then referenced from other source blocks. For instance, you might have:

#+begin_example
,#+begin_src emacs-lisp
#+end_example
#+begin_src emacs-lisp
(dolist (template `(("t" "Task with annotation" entry
                     (file ,pdc/org-inbox-file)
                     "* %?\n:PROPERTIES:\n:created: %U\n:END:\n\n%i\n\n~ %a"
                     :prepend t)
                    <<capture-templates>>
                   ))
    (add-to-list 'org-capture-templates template t
                 (lambda (a b) (equal (car a) (car b)))))
#+end_src
#+begin_example
,#+end_src
#+end_example

which will eventually be tangled as a ~dolist~ that adds /all/ your capture templates to ~org-capture-templates~.

That ~<<capture-templates>>~ is what makes the magic happen. When we tangle =README.org=, the exporter gathers up the contents of any source blocks associated with the tag and replaces ~<<capture-templates>>~ with them
#+begin_marginnote
It applies some heuristics as well, which is why that ~dolist~ isn't indented exactly how it would be without the noweb reference, but you can read the docs to find out more.
#+end_marginnote

So, elsewhere in my =README.org=, I can keep capture templates related to a particular app close to the rest of the configuration of that app, where it makes sense to me. For example, in the section where I configure my blogging tools, I do this:

#+begin_example
,#+begin_src emacs-lisp :tangle nil :noweb-ref capture-templates
#+end_example
#+begin_src emacs-lisp
("b" "bofh.org.uk post" entry
 (file+headline ,(pdc-site-posts-file "bofh") "Posts")
 (function +org-hugo-new-subtree-post-capture-template))
#+end_src
#+begin_example
,#+end_src
#+end_example

Notice the header arguments. ~:tangle nil~ tells the exporter not to simply write the code out at the current position, and ~:noweb-ref capture-templates~ tells the exporter to instead write it out wherever it sees ~<<capture-templates>>~ in a source block.

We have to be careful to ensure that the including code gets run when and where all the values variables and functions used in the included fragment are in scope, which can be fiddly, but it's definitely doable.

{{{newthought(Which brings me to what I actually want to write about!)}}} I don't type all that ~#+begin_src …~ stuff out by hand every time. Because doing that is simply asking for errors. Instead, I take advantage of an org feature called structure templates, so I have:

#+begin_example
,#+begin_src emacs-lisp :tangle nil :noweb-ref org-structure-templates
#+end_example
#+begin_src emacs-lisp
(add-to-list 'org-structure-template-alist <<org-structure-templates>>)
'("el" . "src emacs-lisp")
'("ett" . "src emacs-lisp :tangle nil :noweb-ref")
#+end_src
#+begin_example
,#+end_src
#+end_example

And, until slightly before I wrote this, I'd type =<el= at the beginning of a line, hit TAB and org would expand that to

#+begin_example
,#+begin_src emacs-lisp

,#+end_src
#+end_example

And =<ett= would expand to

#+begin_example
,#+begin_src emacs-lisp :tangle nil :noweb-ref

,#+end_src
#+end_example

Then I'd fill in the correct ~:noweb-ref~ and the appropriate code.

It was fine.

Well, it was better than typing it all by hand, but as soon as I'd expanded a template, I'd immediately hit =C-c '= to edit the code block in a separate buffer that was in the correct mode to edit Emacs Lisp (or whatever language the source block was for).

Eventually, I got annoyed enough by the repetition to work out how to make that happen automatically. Normally, I'd expect to add a function to a hook variable somewhere, but that doesn't quite work here. Time to break out the Swiss Army Knife that is ~advice-add~.

Here's my first take:

#+begin_src emacs-lisp
(defun +org-insert-structure-template/after-advice (&rest _)
  (when (derived-mode-p 'org-mode)
    (org-edit-special)))
(advice-add 'tempo-insert-template :after #'+org-insert-structure-template/after-advice)
(advice-add 'org-insert-structure-template #'org-edit-special)
#+end_src

We're adding advice to two different functions here, because there are two different mechanisms for inserting a structure template, either via the =<foo= expansion, or by calling =M-x org-insert-structure-template=, both of which I make use of on different occasions.

{{{newthought(This version lasted a while.)}}} It did 90% of what I wanted after all. Indeed, for most of my structure templates, it does 100% of what I want.

But there's always that one case, isn't there? Take a look at that =ett= template from earlier. Notice that it's missing the value to assign to =:noweb_ref=. In a perfect world, we should fill that in before we start editing the code. Or rely on remembering to do it after the fact. Because we /always/ do that, don't we?

So, this morning, that chunk of code looked a little like this.
#+begin_marginnote
I've had to reconstruct the code from memory, I'm afraid because it never made it into the git repo. You can call me sloppy if you like, but this is personal code written on my own time, so you can fuck off.
#+end_marginnote

#+begin_src emacs-lisp
(defun +org-insert-structure-template/after-advice (&rest _)
  (when (derived-mode-p 'org-mode)
    (let ((datum (org-element-begin datum)))
      (save-excursion
        (goto-char (org-element-begin datum))
        (when (re-search-forward
               "\\(:\\S-+\\)\\s-*$" (pos-eol) t)
          (let ((key (match-string-no-properties 1)))
            (end-of-line)
            (unless (looking-back "\\s-" 1)
              (insert " "))
            (insert (read-from-minibuffer (format "%s: " key)))))))
    (org-edit-special)))

(advice-add 'tempo-insert-template
            :after #'+org-insert-structure-template/after-advice)
(advice-add 'org-insert-structure-template
            :after #'+org-insert-structure-template/after-advice)
#+end_src

Because an org file is Just A Text File™, we could have written this using Emacs' basic buffer editing commands, but we'll take advantage of some of org and =org-babel='s helper functions to make life a little easier and (hopefully) to help me understand what I'm doing and why I'm doing it when I come back to the code later. Named behaviour is great
#+begin_marginnote
/Especially/ in a self-documenting editor like Emacs. If I'm not sure what a particular function in this code does, the documentation, or even the source code, is always a couple of keypresses away.
#+end_marginnote
for helping make code more understandable.

What we do here is save our place in the buffer, jump back to the very beginning of the source block and look at the header arguments. If they end with a property name (=:like-this=), then we deduce that more information is needed, so we use ~read-from-minibuffer~ to ask for it, add the answer to the end of the header arguments, jump back to wherever the template originally left us (by exiting the ~save-excursion~ block) and call ~org-edit-special~ to start editing the file in a dedicated buffer.

{{{newthought(Job jobbed\, no?)}}}

Well… kinda. See, we're filling in the value of =:noweb-ref= using an error prone free text value, rather than presenting a list of known noweb references to choose from. In the case where the unset parameter is =:noweb-ref=, we really want to use ~completing-read~. A quick trawl through the existing code didn't find a function to do what we want, nor did a web search. An org file's Just A Text File though, and ~org-babel-noweb-wrap~ returns a regular expression that will match a noweb reference in the current file
#+begin_marginnote
~<<reference>>~ is the default form for a noweb ref, but the delimiters are overridable. At one point, I was using ~«reference»~ rather than the defaults, so it's handy to have a function that deals with that for us.
#+end_marginnote
so we could save our place, jump to the beginning of the file and find every match for that regular expression and use that to build a ~completing-read~ candidates list. But =<<foo>>= is only a noweb reference if it's in a source block, so we could end up with a bunch of false positives. We want to search through every source block, ignoring the rest of the file. Surely there's already something in existence to let us do that since it's the sort of thing that happens during the process of tangling a file.

A quick =M-x describe-function org babel src block= yields a bunch of interesting functions, including the promising sounding ~org-babel-src-blocks~. The documentation reads:

#+begin_example
Signature
(org-babel-map-src-blocks FILE &rest BODY)

Documentation
Evaluate BODY forms on each source-block in FILE.

…
#+end_example

It goes on to explain that the body is evaluated with some useful variables set. The one we're interested in is ~body~, which is a "string holding the body of the code block". Sorted.

With that, and other helper functions, we can write:

#+begin_src emacs-lisp
(defun +org-babel-noweb-refs ()
  "Find all the noweb refs in the current buffer."
  (require 's)
  (require 'dash)
  (let ((match-exp (org-babel-noweb-wrap))
        result)
    (org-babel-map-src-blocks nil
      (let ((plain-body (substring-no-properties body)))
        (setq result
              (-concat
               result
               (-map (-partial #'s-replace "(.*)\\'" "")
                     (-map #'second
                           (s-match-strings-all
                            match-exp
                            plain-body)))))))
    (-sort #'string< result)))
#+end_src

It's a bit unsubtle, but it's quick enough and accurate enough for my purposes. Then we can rewrite the relevant bit of our advice function along these lines:

#+begin_src emacs-lisp
(if (re-search-forward "\\(:\\S-+\\)\\s-*$" (pos-eol) t)
    (let* (arg (match-string-no-properties 1))
      (value
       (cond ((string= arg ":noweb-ref")
              (completing-read ":noweb-ref: "
                               (+org-babel-noweb-refs)))
             (t (read-from-minibuffer (concat arg ": "))))))
  (end-of-line)
  (unless (looking-back "\\s-" 1)
    (insert " "))
  (insert-value))

#+end_src

Note the use of ~cond~ here even though we could use a single ~if~. I'm making it easier to special case behaviour for header arguments other than =:noweb-ref=. I'm probably not gonna need it, but it's easy enough to be kind to the future me who /does/ need it.

{{{newthought(I'm sure your editor of preference)}}} can do something like this. If it can't, then why on earth do you put up with it? I know Emacs though, and it it's taken me longer to write about this whole process of eliminating a bump in my road than it did to implement the necessary functions and advice in the first place. I didn't even have to restart Emacs, and it remained usable throughout the process
#+begin_marginnote
The code was actually written within a source block
#+end_marginnote
but it got smoother and smoother with every step.

I'm not the first person to point out how powerful Just A Text File can be, especially if you've also got a huge pile of functions at your disposal to manipulate that file in useful ways and with mode specific semantics. Provided, of course, you've got decent tools to search through that pile. Emacs is just such a pile of useful functions and is a great tool for sifting through it. Give it a go, why don't you.

Take the time to look at how you use your editor. I'm sure some point of friction will come to mind. Then work out how to write some code that will make things a bit smoother. You're not looking for perfect here, you're looking for /better./ The remaining roughness will no doubt niggle at you enough for you to take another pass at sanding it down one day, but for now luxuriate in the fact you've made life a little better for yourself.

I'd suggest that, if you keep doing that as part of your practice, you'll eventually have your tools working exactly how you want them to. But I've been an Emacs user since 1988 and I've yet to reach that point. But it's about the journey, not the destination, isn't it?
** DONE Fetching webmentions again. With Emacs this time! :webmentions:indieweb:
CLOSED: [2025-09-07 Sun 17:17]
:PROPERTIES:
:EXPORT_HUGO_SLUG: fetching-webmentions-again-with-emacs
:EXPORT_HUGO_BUNDLE: 20250907-fetching-webmentions-again-with-emacs
:EXPORT_FILE_NAME: index
:END:

#+begin_description
I've reinstated webmention processing here and have semi-automated it with a pile of Emacs Lisp and a =Makefile=, so I thought I'd write up some of the gory details.

Part 1 of… some?
#+end_description

You might have noticed, if you're a regular visitor that webmentions have started showing up on the site again. I turned them off a while ago, {{{marginnote(I turned off the home server that was handling the web hook calls from Webmention.io, planning to quickly move it and spin it up again. Ask me how that's going.)}}} but [[https://aaronparecki.com][Aaron Parecki]]'s invaluable [[https://webmention.io][Webmention.io]] service has still been gathering them for me, so I've turned them back on. But in the mean time, I mislaid the code I was using to populate the necessary Hugo data files from Webmention. Exploratory code ahoy.

*** Start by faking it

I'm heavily indebted to [[https://masto.hackers.town/@randomgeek][Brian Wisti]] for his post, [[https://randomgeekery.org/post/2020/11/using-the-webmention.io-api/][Using the Webmention.io API]] as the starting point to my explorations, but since I can't be doing with Python, I used emacs.

I started with my very minor fork of [[https://github.com/pdcawley/restclient.el][=restclient=]]

#+name: wm-token
#+begin_src emacs-lisp :exports none
(setq restclient-response-body-only t)
(getenv "WM_API_TOKEN")
#+end_src

#+begin_highlight
#+name: last5
#+begin_src restclient :var token=wm-token()
# Grab the most recent 5 webmentions of bofh.org.uk
GET https://webmention.io/api/mentions.jf2?domain=bofh.org.uk&sort-dir=down&per-page=5&token=:token
#+end_src
#+end_highlight

Which produces the following JSON data:
#+begin_details
#+begin_summary

Disclose this for the full wall of JSON

Don't say you weren't warned!
#+end_summary

#+call: last5()

#+results:
#+BEGIN_SRC json
{
  "type": "feed",
  "name": "Webmentions",
  "children": [
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "Mike Spencer",
        "photo": "https://avatars.webmention.io/fsn1.your-objectstorage.com/3ba5a0fdc660c44995fef428a601770fd0fe2619fc1f8c7e70ec7e9e1da66d4b.jpg",
        "url": "https://mastodon.scot/@mikerspencer"
      },
      "url": "https://mendeddrum.org/@pdcawley/115162152891409560#favorited-by-109365771998686190",
      "published": null,
      "wm-received": "2025-09-07T09:35:22Z",
      "wm-id": 1936897,
      "wm-source": "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115162152891409560/109365771998686190",
      "wm-target": "https://bofh.org.uk/note/8/",
      "wm-protocol": "webmention",
      "like-of": "https://bofh.org.uk/note/8/",
      "wm-property": "like-of",
      "wm-private": false
    },
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "Jess Robinson",
        "photo": "https://avatars.webmention.io/fsn1.your-objectstorage.com/a11ee0a58e54873140bf1f1965900378d866fce3fafae79e116b979bea3a8773.jpg",
        "url": "https://fosstodon.org/@castaway"
      },
      "url": "https://mendeddrum.org/@pdcawley/115160370354067277#favorited-by-109562941096076318",
      "published": null,
      "wm-received": "2025-09-07T07:19:01Z",
      "wm-id": 1936873,
      "wm-source": "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115160370354067277/109562941096076318",
      "wm-target": "https://bofh.org.uk/note/7/",
      "wm-protocol": "webmention",
      "like-of": "https://bofh.org.uk/note/7/",
      "wm-property": "like-of",
      "wm-private": false
    },
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "Daniel Kelly Music",
        "photo": "https://avatars.webmention.io/fsn1.your-objectstorage.com/7aa4815cbc1f993c0e2a6df03280dc168f5ad07fecd0313ddfc27eeb02e0b437.png",
        "url": "https://aus.social/@yasslad"
      },
      "url": "https://mendeddrum.org/@pdcawley/115160370354067277#favorited-by-109307830089461078",
      "published": null,
      "wm-received": "2025-09-07T01:31:46Z",
      "wm-id": 1936817,
      "wm-source": "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115160370354067277/109307830089461078",
      "wm-target": "https://bofh.org.uk/note/7/",
      "wm-protocol": "webmention",
      "like-of": "https://bofh.org.uk/note/7/",
      "wm-property": "like-of",
      "wm-private": false
    },
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "Nick Anderson",
        "photo": "https://avatars.webmention.io/fsn1.your-objectstorage.com/856b210b0770a292a4f9e76699c84aa3833f9252716ad3cab58b50a7b57205ee.jpg",
        "url": "https://fosstodon.org/@nickanderson"
      },
      "url": "https://mendeddrum.org/@pdcawley/115107421781297473#favorited-by-109475479621313511",
      "published": null,
      "wm-received": "2025-08-28T21:48:52Z",
      "wm-id": 1934308,
      "wm-source": "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115107421781297473/109475479621313511",
      "wm-target": "https://bofh.org.uk/note/6/",
      "wm-protocol": "webmention",
      "like-of": "https://bofh.org.uk/note/6/",
      "wm-property": "like-of",
      "wm-private": false
    },
    {
      "type": "entry",
      "author": {
        "type": "card",
        "name": "Nick Anderson",
        "photo": "https://avatars.webmention.io/fsn1.your-objectstorage.com/856b210b0770a292a4f9e76699c84aa3833f9252716ad3cab58b50a7b57205ee.jpg",
        "url": "https://fosstodon.org/@nickanderson"
      },
      "url": "https://fosstodon.org/@nickanderson/115108589417986943",
      "published": "2025-08-28T21:48:05+00:00",
      "wm-received": "2025-08-28T21:48:51Z",
      "wm-id": 1934307,
      "wm-source": "https://brid.gy/comment/mastodon/@pdcawley@mendeddrum.org/115107421781297473/115108589456284711",
      "wm-target": "https://bofh.org.uk/note/6/",
      "wm-protocol": "webmention",
      "content": {
        "html": "<p><span class=\"h-card\"><a href=\"https://mendeddrum.org/@pdcawley\" class=\"u-url\">@<span>pdcawley</span></a></span> I was gonna say, that looks like a source block within a source block which means there's another src block to make it render. Nice</p>",
        "text": "@pdcawley I was gonna say, that looks like a source block within a source block which means there's another src block to make it render. Nice"
      },
      "in-reply-to": "https://bofh.org.uk/note/6/",
      "wm-property": "in-reply-to",
      "wm-private": false
    }
  ]
}
#+END_SRC
#+end_details

The essential shape is something like this:

#+BEGIN_SRC json
{ "type": "feed",
  "name": "Webmentions",
  "children": [
    { "wm-target": "https://bofh.org.uk/note/8/",
      "wm-property": "like-of",
      ... },
    { "wm-target": "https://bofh.org.uk/note/8/",
      "wm-property": "in-reply-to",
      ... },
    ... }]}
#+END_SRC

Restclient is great for interactively exploring a RESTful API, but it's not so great for slicing and dicing the data in a Emacs-y way. I could sit down and learn =jq= again, but I know Lisp, dammit, so after a frustrating hour or so trying to wrap my head around the default ~url-retrieve~ interfaces, I went and grabbed the [[https://github.com/tkf/emacs-request][=emacs-request=]] package instead because I found its API more comprehensible.

Because ~request~ is a function where ~restclient~ is more like an application running in Emacs, it's way more useful for automating things. Here's more or less the same request as above done in Lisp.

#+name: request-mentions
#+begin_src emacs-lisp :var wm-api-token=wm-token()
(let (response)
  (request
    "https://webmention.io/api/mentions.jf2"
    :params `(("domain" . "bofh.org.uk")
              ("token" . ,wm-api-token)
              ("per-page" . "5")
              ("sort-dir" . "down"))
    :parser 'json-parse-buffer
    :sync t
    :success (cl-function
              (lambda (&key data &allow-other-keys)
                (setq response data))))
  response)
#+end_src

The code is obviously fiddlier, but it's also programmable and, because we set an arbitrary ~:parser~ function, it's trivial to convert the returned JSON into a native Emacs lisp hash table
#+begin_marginnote
It's not hard to generate an old school alist either, but that was annoyingly hard to serialise back to JSON, so I went with the default types because they seem to just work.
#+end_marginnote
which looks a bit like this:

#+begin_details

#+begin_summary
A wall of Lisp
#+end_summary

#+call: request-mentions() :results pp

#+results:
#+begin_example
#s(hash-table test equal data
              ("type" "feed" "name" "Webmentions" "children"
               [#s(hash-table test equal data
                              ("type" "entry" "author"
                               #s(hash-table test equal data
                                             ("type" "card" "name"
                                              "Mike Spencer" "photo"
                                              "https://avatars.webmention.io/fsn1.your-objectstorage.com/3ba5a0fdc660c44995fef428a601770fd0fe2619fc1f8c7e70ec7e9e1da66d4b.jpg"
                                              "url"
                                              "https://mastodon.scot/@mikerspencer"))
                               "url"
                               "https://mendeddrum.org/@pdcawley/115162152891409560#favorited-by-109365771998686190"
                               "published" :null "wm-received"
                               "2025-09-07T09:35:22Z" "wm-id" 1936897
                               "wm-source"
                               "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115162152891409560/109365771998686190"
                               "wm-target" "https://bofh.org.uk/note/8/"
                               "wm-protocol" "webmention" "like-of"
                               "https://bofh.org.uk/note/8/" "wm-property"
                               "like-of" "wm-private" :false))
                  #s(hash-table test equal data
                                ("type" "entry" "author"
                                 #s(hash-table test equal data
                                               ("type" "card" "name"
                                                "Jess Robinson" "photo"
                                                "https://avatars.webmention.io/fsn1.your-objectstorage.com/a11ee0a58e54873140bf1f1965900378d866fce3fafae79e116b979bea3a8773.jpg"
                                                "url"
                                                "https://fosstodon.org/@castaway"))
                                 "url"
                                 "https://mendeddrum.org/@pdcawley/115160370354067277#favorited-by-109562941096076318"
                                 "published" :null "wm-received"
                                 "2025-09-07T07:19:01Z" "wm-id" 1936873
                                 "wm-source"
                                 "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115160370354067277/109562941096076318"
                                 "wm-target" "https://bofh.org.uk/note/7/"
                                 "wm-protocol" "webmention" "like-of"
                                 "https://bofh.org.uk/note/7/" "wm-property"
                                 "like-of" "wm-private" :false))
                  #s(hash-table test equal data
                                ("type" "entry" "author"
                                 #s(hash-table test equal data
                                               ("type" "card" "name"
                                                "Daniel Kelly Music" "photo"
                                                "https://avatars.webmention.io/fsn1.your-objectstorage.com/7aa4815cbc1f993c0e2a6df03280dc168f5ad07fecd0313ddfc27eeb02e0b437.png"
                                                "url"
                                                "https://aus.social/@yasslad"))
                                 "url"
                                 "https://mendeddrum.org/@pdcawley/115160370354067277#favorited-by-109307830089461078"
                                 "published" :null "wm-received"
                                 "2025-09-07T01:31:46Z" "wm-id" 1936817
                                 "wm-source"
                                 "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115160370354067277/109307830089461078"
                                 "wm-target" "https://bofh.org.uk/note/7/"
                                 "wm-protocol" "webmention" "like-of"
                                 "https://bofh.org.uk/note/7/" "wm-property"
                                 "like-of" "wm-private" :false))
                  #s(hash-table test equal data
                                ("type" "entry" "author"
                                 #s(hash-table test equal data
                                               ("type" "card" "name"
                                                "Nick Anderson" "photo"
                                                "https://avatars.webmention.io/fsn1.your-objectstorage.com/856b210b0770a292a4f9e76699c84aa3833f9252716ad3cab58b50a7b57205ee.jpg"
                                                "url"
                                                "https://fosstodon.org/@nickanderson"))
                                 "url"
                                 "https://mendeddrum.org/@pdcawley/115107421781297473#favorited-by-109475479621313511"
                                 "published" :null "wm-received"
                                 "2025-08-28T21:48:52Z" "wm-id" 1934308
                                 "wm-source"
                                 "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115107421781297473/109475479621313511"
                                 "wm-target" "https://bofh.org.uk/note/6/"
                                 "wm-protocol" "webmention" "like-of"
                                 "https://bofh.org.uk/note/6/" "wm-property"
                                 "like-of" "wm-private" :false))
                  #s(hash-table test equal data
                                ("type" "entry" "author"
                                 #s(hash-table test equal data
                                               ("type" "card" "name"
                                                "Nick Anderson" "photo"
                                                "https://avatars.webmention.io/fsn1.your-objectstorage.com/856b210b0770a292a4f9e76699c84aa3833f9252716ad3cab58b50a7b57205ee.jpg"
                                                "url"
                                                "https://fosstodon.org/@nickanderson"))
                                 "url"
                                 "https://fosstodon.org/@nickanderson/115108589417986943"
                                 "published" "2025-08-28T21:48:05+00:00"
                                 "wm-received" "2025-08-28T21:48:51Z" "wm-id"
                                 1934307 "wm-source"
                                 "https://brid.gy/comment/mastodon/@pdcawley@mendeddrum.org/115107421781297473/115108589456284711"
                                 "wm-target" "https://bofh.org.uk/note/6/"
                                 "wm-protocol" "webmention" "content"
                                 #s(hash-table test equal data
                                               ("html"
                                                "<p><span class=\"h-card\"><a href=\"https://mendeddrum.org/@pdcawley\" class=\"u-url\">@<span>pdcawley</span></a></span> I was gonna say, that looks like a source block within a source block which means there's another src block to make it render. Nice</p>"
                                                "text"
                                                "@pdcawley I was gonna say, that looks like a source block within a source block which means there's another src block to make it render. Nice"))
                                 "in-reply-to" "https://bofh.org.uk/note/6/"
                                 "wm-property" "in-reply-to" "wm-private"
                                 :false))]))
#+end_example

#+end_details

Verbose as hell, but something we can work with. Here's a simplified alist representation which might be a little easier to understand.

#+begin_src emacs-lisp
'((type . "feed")
  (name . "Webmentions")
  (children
   . [((wm-property . "like-of")
       (wm-target . "https://bofh.org.uk/note/8/")
       ...)
      ((wm-property . "in-reply-to")
       (wm-target . "https://bofh.org.uk/note/8/")
       ...)]))
#+end_src

The interesting stuff lives under the ="children"= key, which we can get with ~(gethash "children" data)~.

To get all the webmentions for our domain, the Webmention API allows for pagination. We can ask for pages of, say 100 entries and if we get 100 entries back, append the result to our running collection of entries and request the next page. Once we get a result with fewer than 100 entries, we know we're done and we can massage the data into a shape that Hugo can cope with

*** Then turn what we learn into a commands

Now we know what the data coming from Webmention.io looks like, and how we can page through it, let's write a function, ~wm--fetch-all~ to do that for us.

#+transclude: [[file:./support-code/wm.el::wm--fetch-all]] :lines 1-38 :src emacs-lisp



The ~(while more? ...)~ loop keeps requesting more data until it gets a short response, at which point ~more?~ becomes false and we return the accumulated ~all-entries~ vector


*** And relax

We now have a handy list of all the webmentions relating to our site. The next step is to massage it into a data structure that will suit Hugo and export it as JSON files in the site's =data= directory. Which is a topic for another blog post, I think. If only because I'm reasonably sure that the data structure I'm currently using isn't great.

I'll hack it about a bit and report back.
** DONE Making use of Webmentions :webmentions:indieweb:hugo:
CLOSED: [2025-09-09 Tue 20:49]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 20250909-making-use-of-webmentions
:EXPORT_FILE_NAME: index
:END:

#+begin_description
In which we finish with Webmentions for the time being by massaging a flat list of mentions into a two-level hash table/JSON object that's easy to make use of in Hugo.

And speculate about how we could improve things further, because things can always be improved.
#+end_description

When [[/2025/09/07/fetching-webmentions-again-with-emacs/][last we left off]] we had worked out how to grab all the mentions of this site that [[https://webmentions.io/][Webmentions.io]] knew about and now we want to write that out to the =data/= directory in a format that's easy to deal with in Hugo.

If you've read [[*\[2025-09-09 Tue 06:55\]][my earlier note]], you'll know that I've been evolving the data schema towards something that's easy for Hugo to deal with and reasonably comprehensible for me too.

As things currently stand, I've settled on dropping all the mentions in a single file, =data/mentions/all.json=
#+begin_marginnote
I'd rather use =data/mentions.json=, but Hugo's data system doesn't seem to pick that up, so I'll live with the slightly more clunky option.
#+end_marginnote
which is structured along these lines:

#+begin_src json
{
  "/note/7/": {
    "like-of": [
      {
        "type": "entry",
        "author": {
          "type": "card",
          "name": "Daniel Kelly Music",
          "photo": "https://avatars.webmention.io/fsn1.your-objectstorage.com/7aa4815cbc1f993c0e2a6df03280dc168f5ad07fecd0313ddfc27eeb02e0b437.png",
          "url": "https://aus.social/@yasslad"
        },
        "url": "https://mendeddrum.org/@pdcawley/115160370354067277#favorited-by-109307830089461078",
        "published": null,
        "wm-received": "2025-09-07T01:31:46Z",
        "wm-id": 1936817,
        "wm-source": "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115160370354067277/109307830089461078",
        "wm-target": "https://bofh.org.uk/note/7/",
        "wm-protocol": "webmention",
        "like-of": "https://bofh.org.uk/note/7/",
        "wm-property": "like-of",
        "wm-private": false
      },
      {
        "type": "entry",
        "author": {
          "type": "card",
          "name": "Jess Robinson",
          "photo": "https://avatars.webmention.io/fsn1.your-objectstorage.com/a11ee0a58e54873140bf1f1965900378d866fce3fafae79e116b979bea3a8773.jpg",
          "url": "https://fosstodon.org/@castaway"
        },
        "url": "https://mendeddrum.org/@pdcawley/115160370354067277#favorited-by-109562941096076318",
        "published": null,
        "wm-received": "2025-09-07T07:19:01Z",
        "wm-id": 1936873,
        "wm-source": "https://brid.gy/like/mastodon/@pdcawley@mendeddrum.org/115160370354067277/109562941096076318",
        "wm-target": "https://bofh.org.uk/note/7/",
        "wm-protocol": "webmention",
        "like-of": "https://bofh.org.uk/note/7/",
        "wm-property": "like-of",
        "wm-private": false
      }
    ],
    "in-reply-to": [],
    "mention-of": [],
    "repost-of": [],
    "other": []
  }
}
#+end_src

Just imagine that JSON object has a bunch more paths as keys referencing similar objects keyed by mention type.

As it stands, ~wm--fetch-all~ is returning a flat sequence of webmention objects that we want to process into a more structured object,
#+begin_marginnote
JSON/Javascript calls them objects, old Perl heads like me think of them as hashes, and they're "Hash Tables" in Emacs Lisp. I'll be calling them hashes from now on.
#+end_marginnote
in other words we want to fold (or "reduce" in Emacs Lisp terminology) the sequence into a hash. And I know just the function for that. Let's see what ~describe-function~ has to say about ~seq-reduce~:

#+begin_example
seq-reduce is a byte-compiled function defined in seq.el.gz.

*Signature*
(seq-reduce FUNCTION SEQUENCE INITIAL-VALUE)

*Documentation*

Reduce the function FUNCTION across SEQUENCE, starting
with INITIAL-VALUE.

Return the result of calling FUNCTION with INITIAL-VALUE
and the first element of SEQUENCE, then calling FUNCTION
with that result and the second element of SEQUENCE,
then with that result and the third element of SEQUENCE,
etc. FUNCTION will be called with INITIAL-VALUE (and then
the accumulated value) as the first argument, and the
elements from SEQUENCE as the second argument.

If SEQUENCE is empty, return INITIAL-VALUE and FUNCTION
is not called.

This does not modify SEQUENCE.
#+end_example

So we can write

#+begin_src emacs-lisp
(seq-reduce #'wm--add-mention-to-hash-table
            (wm--fetch-all)
            (make-hash-table :test 'equal))
#+end_src

and that will handle the business of iterating over the sequence of mentions for us, and all we have to do is write ~wm--add-mention-to-hash-table~ to populate the hash we made with ~(make-hash-table :test 'equal)~
#+begin_marginnote
We need to use that ~:test 'equal~ part because ~json-insert~ wants a hash with strings as keys and the default hash returned by ~(make-hash-table)~ compares keys using ~eql~ which might or might not work when comparing strings. Not a problem which ~equal~ has.
#+end_marginnote
one mention at a time, and return the modified hash (You and I both know that it's the same old hash mutated, but let's pretend it isn't, eh?).

What does that function look like? Here's what I wrote:

#+begin_src emacs-lisp
(defun wm--add-mention-to-hash-table (acc mention)
  "Helps reduce a list of mentions into a two level hash."
  (require 'dash)
  (let* ((path (--> mention
                    (gethash "wm-target" it)
                    (url-generic-parse-url it)
                    (url-path-and-query it)
                    (car it)))
         (mentions-hash (or (gethash path acc nil)
                            (wm-new-mentions-hash)))
         (mention-type (gethash "wm-property" mention))
         (mentions (or (gethash mention-type mentions-hash)
                       (progn
                         (setq mention-type "other")
                         (gethash mention-type mentions-hash))))
         (new-mentions (if (seq-contains mentions mention)
                           mentions
                         (vconcat mentions (list mention)))))
    (puthash mention-type new-mentions mentions-hash)
    (puthash path mentions-hash acc)
    acc))

#+end_src

We grab the path from the ="wm-target"= key, which is actually a URL rather than a simple path
#+begin_marginnote
We /could/ just use the URL, and that would work fine on this site, but not when I'm running on localhost. The path will always match with ~.RelPermalink~, but the host part of ~.Permalink~ is different in development than in production.
#+end_marginnote
so, rather than writing

#+begin_src emacs-lisp
(car
 (url-path-and-query
  (url-generic-parse-url
   (gethash "wm-target" mention))))
#+end_src

we'll thread ~mention~ through that series of transformations using =dash.el='s threading macro, ~-->~.

We use the path to grab ~mentions-hash~ from the ~acc~-umulating hash and, if there isn't already one there, we grab an empty, but structured hash using ~wm-new-mentions-hash~, which looks like this:

#+begin_src emacs-lisp
(defun wm-new-mentions-hash ()
  "Make a new empty hash to hold categorised webmention data."
  (copy-hash-table
   #s(hash-table
      test equal
      data ("like-of" [] "in-reply-to" []
            "mention-of" [] "repost-of" []
            "other" []))))
#+end_src

Now we look up ~"wm-property"~ in ~mention~, and use that to grab its associated vector of mentions. Well, we would, but there's a small wrinkle.

@@hugo:{{%newthought %}}@@@@hugo:We're only currently interested in four kinds of mention,{{% /newthought %}}@@ but Webmention.io doesn't know that. We could throw the extras away, but what if we became interested in =bookmark-of= mentions or whatever somewhere down the road. So let's collect them under the =other= key. Which is where this hacky section of our ~let*~ form comes in:

#+begin_src emacs-lisp
(mention-type
 (gethash "wm-property" mention))
(mentions
 (or (gethash mention-type mentions-hash)
     (progn
       (setq mention-type "other")
       (gethash mention-type mentions-hash))))
#+end_src

What's going on here then?

First, we make a guess at the ~mention-type~ we're going to file the current mention under by grabbing the ="wm-property"= and use that value to lookup the mention type in ~mentions-hash~. If it's one of the four types we're interested in, that will be a vector, which is truth-y, otherwise we get ~nil~, which is false-y so we change the mention type to "other" and grab that vector from the mention hash.

We now know the key path we're going to store our mentions in, and we have the current vector of mentions associated with it. So, if we already know ~(seq-contains mentions mention)~ about the current mention, we reuse that, otherwise we make a new vector with the current mention added to it.

That done, it's a simple matter of putting the new mentions vector into our mentions hash, putting the mentions hash into our accumulating hash and returning that.

With that done, it's a simple matter of opening =data/mentions/all.json=, erasing the buffer, calling =(json-insert (seq-reduce ...))= to update the data and saving it. Here's the code which does exactly that.

#+begin_src emacs-lisp
(defun wm-unflatten-mentions (mentions-vec)
  (seq-reduce 'wm--add-mention-to-hash-table mentions-vec
              (make-hash-table :test 'equal)))

(defun wm-fetch-mentions ()
  "Fetch the webmentions of `wm-domain'."
  (interactive)
  (save-current-buffer
    (let ((all-entries (wm--fetch-all)))
      (with-temp-file (expand-file-name "all.json" wm-data-dir)
        (erase-buffer)
        (json-insert (wm-unflatten-mentions all-entries))))))
#+end_src

@@hugo:{{%newthought %}}@@Over in the Hugo partial@@hugo:{{% /newthought %}}@@ that renders the bit of the page immediately after this, we can get at the data like this:

#+begin_src go-html-template
{{- $all_mentions := index site.Data.mentions.all .RelPermalink  -}}
{{ $likes := index $all_mentions "like-of" | default slice -}}
{{ $reposts := index $all_mentions "repost-of" | default slice -}}
{{ $replies := index $all_mentions "in-reply-to" | default slice -}}
{{ $mentions := index $all_mentions "mention-of" | default slice -}}
<footer class="metaline">
  <ul class="response-summary">
    <li>{{ $likes | len }} {{ if eq 1 (len $likes) }}like{{ else }}likes{{ end }}</li>
    <li>{{ $reposts | len }} {{ if eq 1 (len $reposts) }}repost{{ else }}reposts{{ end }}</li>
    <li>{{ $replies | len }} {{ if eq 1 (len $replies) }}reply{{ else }}replies{{ end }}</li>
    <li>{{ $mentions | len }} {{ if eq 1 (len $mentions) }}mention{{ else }}mentions{{ end }}</li>
  </ul>
</footer>
...
#+end_src

I'll leave the rest as an exercise for the interested reader. However, I will note that the Webmention.io API includes the option to pass in a =since= argument, so it wouldn't be hard to write

#+begin_src emacs-lisp
(seq-reduce
 'wm--add-mention-to-hash-table
 (wm-fetch-mentions-since wm-last-checked)
 (wm-parse-mentions-file
  (expand-file-name "mentions/all.json"
                    wm-data-dir)))
#+end_src

without having to change our reducing function at all.

Separation of concerns, baby! Separation of concerns!

** Recovered Posts
*** DONE Laying out code
CLOSED: [2025-09-24 Wed 21:50]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 20030816-laying-out-code
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-24 Wed 21:50]
- State "REVISING"   from "DONE"       [2025-09-20 Sat]
- State "DONE"       from "TODO"       [2003-08-16 Sat]
:END:

#+begin_subsection
*2025 Editor's Note:*\\
What the hell was I thinking?
#+end_subsection

A couple of articles back, I reviewed /Smalltalk Best Practice Patterns/
and mentioned that it's a book that concentrates on the tactics of
programming rather than the big strategic stuff. Beck even takes his
life in his hands and lays down a set of patterns for laying out code.
The (very short) set of patterns he comes up with do seem to generate
remarkably clear code.

I'm a big fan of this book, and I've lifted many of the ideas about how
to structure Smalltalk code and used them when I'm writing OO Perl (to
the extent that I sometimes find myself wishing that Perl had Smalltalk
like message selectors), so now I'm toying with the idea of using Beck's
rules, or something like them, for laying out my Perl code.

#+hugo: more

Here's a method from Pixie::Proxy (one of the scarier classes in Pixie I
must admit):\\

#+begin_src perl
sub _px_extraction_thaw {
  my $self = shift;
  my $pixie = Pixie->get_the_current_pixie;
  my $ret = $pixie->cache_get($self->_oid);
  if ( defined $ret ) { $pixie->obliterate($self); return $ret; }
  $self->px_lock_strategy( $pixie->get_the_current_lock_strategy );
  if ($self->px_class->px_is_immediate) {
      my $oid = $self->_oid;
      $pixie->obliterate($self);
    return $pixie->_get($oid);
  }
  else {
      $self->px_the_store($pixie);
      $pixie->cache_insert($self);
    return $self;
  }
}
#+end_src

Now, here it is again reformatted according to my adaptation of Beck's rules.

#+begin_src perl
sub _px_extraction_thaw {
  my $self = shift;
  my $pixie = Pixie->get_the_current_pixie;
  my $ret = $pixie->cache_get($self->_oid);
  if ( defined $ret ) { $pixie->obliterate($self); return $ret; }
  $self->px_lock_strategy( $pixie->get_the_current_lock_strategy );
  if ($self->px_class->px_is_immediate)
  { my $oid = $self->_oid;
    $pixie->obliterate($self);
    return $pixie->_get($oid) }
  else
  { $self->px_the_store($pixie);
    $pixie->cache_insert($self);
    return $self; }
}
#+end_src


The main change in appearance comes from using what Beck calls
rectangular blocks. Moving to this style has shortened the method by
three lines, which isn't bad. Moving to using cuddled
elses
#+begin_marginnote
A cuddled else looks like ~} else {~ and is evil, bad
and wrong.
#+end_marginnote
would only have saved one line and I don't like them
anyway because I tend to lose the ~else~. With rectangular blocks, the
control structure is still evident, which is nice.
It's quite strange looking at that code; it looks odd, but I don't think
it looks actively /bad/. I'm off to recast a whole module in this style
and see if I can boil things down to as compact a set of rules as Beck
came up with. Or I might decide it looks horrible, but I do think it's
worth a look.

Has anyone else tried anything like this? Did it work for you?



*** DONE Essential Perl 6
CLOSED: [2025-09-20 Sat 22:53]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 20030815-essential-perl-6
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :work '((author . "Allison Randal") (title . "Perl 6 Essentials") (type . "Perl 6 Essentials"))
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :cover '((s . "https://covers.openlibrary.org/b/olid/OL3327054M-S.jpg") (m . "https://covers.openlibrary.org/b/olid/OL3327054M-M.jpg") (l . "https://covers.openlibrary.org/b/olid/OL3327054M-L.jpg"))
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-20 Sat 22:53]
- State "REVISING"   from "DONE"       [2025-09-20 Sat]
- State "DONE"       from "TODO"       [2003-08-15 Fri]
:END:

As most of you probably know, unless you came
here via a link from
[[http://weblogs.java.net/pub/wlg/353][java.net,]]
I write a summary every week of the ongoing developments on the Perl 6
development mailing lists. Which means, if nothing else, that my review
of
#+header: :trim-pre t :trim-post t
#+begin_cite
Perl 6 Essentials
#+end_cite
by Randal, Sugalski & Tötsch might be just a little
partial.

#+hugo: more

Any book which aims to hit a target as mobile as Perl 6 and
Parrot
#+begin_marginnote
Parrot is the register based virtual machine that will host Perl 6.
#+end_marginnote
is always going to have a hard time, but the
writers are all intimately involved in their design and development, so
they're going to be closer to the mark than most. Allison Randal is a
member of the core team designing Perl 6 the language; Dan Sugalski is
the project leader for Parrot and Leopold Tötsch, generally described in
my
[[http://www.perl.com/pub/at/16][Perl
6 Summaries]] as the Patch Monster has a phenomenal work rate and knows
Parrot inside out.

The book opens with a short overview of the genesis of Perl 6 and how
the project is structured and managed, and how you can get involved in
the various subprojects. Included in this section is an overview of how
Perl 6 the language is being designed. One of the criticisms that's been
levelled at Perl 6 is that it's being
[[http://bleaklow.com/alanbur/p6_cover.gif][designed
by a committee.]] However, this isn't the way most of the people
involved in Perl 6 see it. The language is being designed by Larry Wall,
with direct support from Damian Conway, Allison Randal and the others on
the core team. Meanwhile mailing list participants pitch in with new
ideas, questions, clarifications etc. It might look like there's a lot
of noise and disparate voices if you're watching the mailing lists, but
it's very apparent from reading the design documents that Larry puts out
([[http://www.perl.com/pub/au/Wall_Larry][The
Apocalypses]]) that Larry is /the/ designer of Perl 6. There's a
distinctive Wallian feel to them that's very different from the stuff
produced on the mailing lists, and even from the stuff Damian Conway did
in his
[[http://www.yetanother.org/damian/Perl5+i/][Perl
5+i]] effort. It's quite weird---often I'll see an idea on the mailing
list and think “No, that's just going too far.”, then along comes Larry
in the next Apocalypse and he's taken the idea I'd previously rejected,
pushes it even further and comes back with something that's powerful,
Perlish and broadly useful.

Ahem, I digress.

Next up is an overview of the Perl 6 design philosophy. If you've seen
Allison speaking about this at OSCON or YAPC then much of the material
in this chapter will be familiar (I do find myself wondering which came
first, the talk or the chapter).
#+begin_marginnote
Ah… I just got mail from Allison, the chapter got done
first and the process of writing it inspired the talk.
#+end_marginnote
This is a well written,
thoughtful explanation of the principles underlying the language design.
In a sense, this chapter can be thought of as an essence of
Perl---There is very little in here that doesn't apply equally to earlier
Perls, possibly right back to Perl 0.whatever. Even if you're not
particularly interested in Perl 6 (or even Perl) there's a good deal to
think about here---the importance of considering natural languages
when designing programming languages, and of giving the program the
freedom to express her intent in several ways (and the responsibility to
choose the clearest option of course)---there's certainly plenty of
meat for the
[[http://lambda.weblogs.com/][Lambda
the Ultimate]] and
[[http://ll1.ai.mit.edu/][LL1]]
crowds.

Chapter 4 covers the syntax of Perl 6. It's written as if it's an early
draft of the Perl 6 edition of Programming Perl. I really like this
chapter, it covers an awful lot of ground and it does so with admirable
clarity. The most obvious change is Larry's total rethink of the pattern
matching syntax, which is a fantastic piece of work and no mistake, but
a no less important change (to my way of thinking at least) is the
changes in the way blocks work.

If you listen to the likes of
[[http://perl.plover.com/][Mark
Jason Dominus]] (and if you don't listen to Mark, you really should)
you'll be aware of the importance that he places on Perl's very high
level capabilities, particularly its functional programming
capabilities. Well, in Perl 6, functional programming just got a whole
lot less wordy. And with tail call elimination on the cards, it should
be getting faster too.

The shift to function signatures which name the arguments helps to
reduce the ‘noise' in the body of the the subroutine. Hoisting parameter
naming into the signature gets rid of all the tedious manipulation of
~@_~ that characterises every single subroutine block in Perl. I
sometimes think that the parameter handling folderol is one of the main
reasons that too many Perl 5 functions and methods stay long and don't
get factored into small, comprehensible units of code.

Perl 6 has also dropped the requirement to use ~sub~ to declare
anonymous subroutines, making it far easier to write methods and
functions that can be used as if they were part of the language. And
hey, it's four characters less to type every time you call a higher
order function or method. It doesn't /sound/ like much, but if you go
and take a look at Ruby or Smalltalk and the way in which so many of
those languages' powerful constructs make heavy use of syntactically
light
#+begin_marginnote
By which I mean blocks are introduced with a minimum of
gubbins, no keywords required.
#+end_marginnote
blocks. See
[[http://www.perl.com/pub/a/2003/07/29/exegesis6.html][Exegesis
6]] for a very good set of examples covering almost everything to do
with subroutines, methods and blocks.

Also in this chapter is coverage of Perl 6's replacement for Perl
Compatible Regular Expressions. Wow. If I were a Python or Ruby
evangelist, then I'd currently be busy stealing the ideas and syntax in
the new Perl 6 Rules and trying to get something up and running before
Perl 6 does. The new Perl 6 Rules/Grammar system is a comprehensive
rethink of how pattern matching works and should work. As I've mentioned
in an earlier entry, I went to Damian Conway's talk on Perl 6 Rules at
OSCON this year, and he showed off a partial implementation (in Perl 5)
and they're phenomenal parsing tools. That afternoon, I rode in Ward
Cunningham's Jeep back from Portland Zoo and we talked about Perl 6
rules. I may not have got my Ward number down to 1 at OSCON, but I can
say that Ward seemed excited by the possibilities inherent in the new
rules system. He's not alone.

{{{newthought(The rest of the book is concerned with Parrot\,)}}} Perl 6's target VM.
Unlike Perl 6, Parrot is available to download and run today. It's not
finished, but it's becoming more capable as every day passes (thanks in
no small part to Leo Tötsch's phenomenal workrate, and, in recent weeks,
Michal Wallace's sterling work on getting Python up and running on
Parrot). This does mean that the Parrot section of the book has a few
inaccuracies where Parrot has changed the way it works. My favourite is
found in the discussion of Coroutines on p93 where Dan writes
“Coroutines can be implemented in terms of continuations if need by, but
that requires using a full continuation-passing function call system,
something we choose not to do”. Well, that's what most copies say; Mine
has a signed correction from Dan as I believe that particular statement
was out of date about a day after too book went to press. There aren't
many of these however, and I'd be worried if there weren't /any/ ---
good design arises from experience, and there aren't too many people
with experience of writing a register based VM. Overall, the Parrot
Internals chapter is strong on the structure of Parrot, and offers
insight into the /why/ of it. If you intend to help with the task of
implementing Parrot then this is an excellent place to start; you'll
still have to read the source, and the detailed design documents, but if
you've read this you'll have a good map in your head of how things hang
together.

The last two chapters are concerned with writing assembly programs to
run on Parrot. Essentially the would be language implementer can either
write all his code in native Parrot Assembly Language, managing register
allocations and the like himself and generally getting all those
associated headaches. Or, he can write code for IMCC using Parrot
Intermediate Language (known as PIR for reasons that aren't entirely
clear even to one who has been watching the mailing list since the
Parrot project started) which is an ‘overlay' on top of PASM. IMCC
handles all your register allocation needs, implements macros, handles
the parrot callling conventions and generally makes the poor compiler
writer's life easier. The idea is that IMCC will provide language
independent optimizations such as automatic inlining of function calls,
loop unrolling and (eventually) the whole arsenal of assembly level
optimization tricks that have been developed down the years. All you
have to do is write your compiler/interpreter reasonably simply and let
IMCC handle the bookkeeping. But, I'm getting ahead of myself again.

Reading the chapter on Parrot Assembly Language can be a strange
experience, especially if you're used to ‘real' assembly languages. It
starts off gently, looking pretty much like ‘real' machine code, but
with the odd wrinkle that there seems to be no way of accessing the main
memory, and there's PMCs to worry about that don't look like anything
you'd get in a ‘real' assembler---what was the last chip you saw with
a fully functioning =sprintf= opcode? The chapter finishes with a handy
reference of Parrot ops and how to use them, which is excellent; I
generally don't have sufficient screen real estate to go tracking
through doc files in search of something, but a book open beside you is
a godsend. Parrot Assembly is a remarkably powerful and expressive
assembly language, but for anything serious you should really press on
to the next chapter, which covers IMCC.

IMCC is great. Although it was intended as a target for compilers that
didn't want to have to worry about the register allocation bookkeeping,
it's also a very pleasant environment in which to write your own code.
Again, this section of the book is well written and makes a very handy
reference. Last but not least is a decent index (given the speed with
which this book was put together I'm amazed that it has /an/ index, let
alone a decent one.)

Perl 6 Essentials
has had a somewhat mixed reception in various places. The major
criticism (from those who have neither read it nor intend to read it) is
along the lines of “Even by the most optimistic estimates, Perl 6 is at
least a couple of years away, why do we need this book?” Well, yes, Perl
6 is at least a couple of years away, but Parrot (or something very like
it) is here right now and it's supporting some ‘real' programming
languages, not just toys like BASIC and Python, it can even host
Brainfuck and Befunge. If you want to start targetting Parrot, then this
book is a great place to start.

The Perl 6 half of the book is important too. Allison has pulled
together the existing Apocalypses and Exegeses, taken the various
changes that have happened since they were written and boiled the state
of Perl 6 down into a straightforward and readable description of where
we stand. From the feedback I've been getting about my weekly Perl 6
Summaries, I know that there are plenty of people out there who are
interested in what's going on in Perl 6, but who don't have the time to
read the mailing lists. I don't doubt that there are also people out
there who are interested in Perl 6 but who don't have time to read the
summaries for whom this book would also be ideal.

{{{newthought(I do wish it had larger margins though.)}}} I can see this becoming a book
that I end up covering with annotations and addenda as the language
changes with each new Apocalypse, Exegesis, Parrot Design Document and
large patch from Leo Tötsch. And I do wonder if it wouldn't have been
better entitled /The Perl 6 Annual 2003./

*** DONE Certification and Standards
CLOSED: [2025-09-20 Sat 22:21]
:PROPERTIES:
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_BUNDLE: 20030807-the-quality-without-a-name
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-20 Sat 22:21]
- State "REVISING"   from "DONE"       [2025-09-20 Sat 22:10]
- State "DONE"       from "TODO"       [2003-08-07 Thu 00:01]
:END:

One of the less satisfying sessions/panels at OSCON this year was the
‘Perl Certification' Panel, in which a panel of various luminaries,
moderated by Tim Maher of the Seattle Perl Users' Group spoke
inconclusively about whether there was a need for Perl Certification. It
seems to me that, if you're going to have a panel on this kind of topic,
you /must/ make sure that your moderator is impartial (but not
uninterested). Tim Maher, for all his many virtues, was not impartial.

I arrived late to the panel, so I could be forming a bad impression, but
it seemed to me the panel had the cart before the horse, and any similar
panel will also have such an ungainly configuration, and here's why:

#+hugo: more

The important thing about certification is not the certificate but the
standards on which it is based.

My wife has been involved in the business of producing standards for
trainers, health and safety professionals and others here in the UK;
these standards are used as the basis of high level vocational
qualifications for such professionals, and they seem to be successful.
The way the process works in the UK is as follows:

1. Employers, professionals and people with experience writing standards
   meet and thrash out the competencies required in their field. At this
   stage, the role of the standards developers is purely to /describe/ competence.
2. Once consensus is reached, the standards are published. You could,
   theoretically stop there, and have a useful set of guidelines for
   trainers, professionals and employers.
3. An awarding body may then go on to develop qualifications based on
   these standards. This includes developing ways of assessing
   candidate's competence through any or all of
   - Observation of practical work
   - Written work
   - Verbal questioning and discussion
4. The qualification is published.
5. Trainers develop training programs and materials aimed at bringing
   candidates up to the standards required.

In order to qualify there is no requirement placed on the candidate to
undergo training, they can simply pay an assessment fee and if they can
show competence they qualify. This assessment may well be a relatively
expensive process; competency cannot usually (ever?) be assessed with a
simple paper examination. Passing a written exam simply proves you can
answer questions, but says nothing at all about your ability to do
anything else.

Also, trainers/assessors /must themselves be competent/ (and they must
also be competent assessors). Under the NVQ system there's a whole
series of checks and balances involving external assessors and
supporting materials. In essence though, the whole thing is
straightforward, a candidate goes to a competent assessor, demonstrates their
competence and receives either a qualification or guidance on what areas
they need to develop further. That is all. The whole edifice stands or
falls on the quality and integrity of this assessments, but that was
always the case, it's just made explicit with standards based
qualifications.

One of the things that slowed the take up of standards based vocational
qualifications in the UK has been the inertia of the training
organisations. Trainers like to sell training packages, but the
qualifications emphasise assessment---Training requirements may arise
where more competence is required. Trainers need to rethink their
priorities; when assessment is what counts, trainers should become
assessors too and start making money from the assessment process as well
as from any training requirements that arise. Many UK trainers have now
made this jump.

I doubt very much that we'll ever get a single standard in this area.
But that's fine, I'm sure that the various software tribes will be able
to agree on a core set of standards, then the Crafty Camp can go on to
develop standards for competence in, say, CRC Manipulation, Estimation,
Test Infection, Pair Programming etc. Meanwhile the Software Engineering
Collective can develop standards in UML Reading, Formal Analysis
Techniques, Bogging the Project Down in Use Case Writing... (can you
tell which side of that particular divide I'm on?)

{{{newthought(Of course\, if the Agile camp had standards\,)}}} they might encourage the
development of standards for customers. I can just imagine the pre-sale
conversation:

“Ah, you have a level III Extreme Customer NVQ, that carries a 10%
increase in velocity over a project with an inexperienced customer”

“And I see your team has an average Level IV in Refactoring and Test
Writing, but your Estimation could use some work, let's see if we can't
all improve while we work on this”

“Okay, so what are the stories?”

...

“So, three months to start with, fortnightly iterations, the standard XP
contract?”

“Yeah, let's get started”

*** DONE The Quality Without A Name
CLOSED: [2025-09-20 Sat 22:06]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 20030729-the-quality-without-a-name
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :work '((author . "Kent Beck") (title . "Smalltalk Best Practice Patterns") (type . "Smalltalk Best Practice Patterns"))
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :cover '((s . "https://covers.openlibrary.org/b/olid/OL991031M-S.jpg") (m . "https://covers.openlibrary.org/b/olid/OL991031M-M.jpg") (l . "https://covers.openlibrary.org/b/olid/OL991031M-L.jpg"))
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-20 Sat 22:06]
- State "REVISING"   from "DONE"       [2025-09-20 Sat 21:33]
- State "DONE"       from "TODO"       [2003-07-29 Tue 00:01]
:END:
"The Quality Without A Name" is a phrase coined by Christopher Alexander
in /The Timeless Way of Building/ to describe the feeling of satisfaction
and contentment engendered by good building. He later went on to call it
‘life', but a friend of mine described it as ‘The Tao of Building',
which seems rather appropriate too.
#+header: :trim-pre t :trim-post t
#+begin_cite
The Timeless Way of Building
#+end_cite
is a fantastic, if somewhat overwritten book, introducing Alexander's themes
and ideas about how modern architects and builders can recapture the
qualities inherent in great (usually old) buildings.

Alexander later went on to crystallise his ideas about how

to lay out
cities, towns, neighbourhoods, houses, rooms, windows, etc. in his
massively influential book,
#+header: :trim-pre t :trim-post t
#+begin_cite
A Pattern Language,
#+end_cite
in which Alexander and
his co-authors attempted to set down a ‘language' that would enable
anyone to design and build somewhere that possessed the Quality Without
a Name for themselves. Sadly, as they admit later, they failed in this
attempt; efforts to use this pattern language by laymen resulted in
interesting, but flawed, buildings. Despite the failure (in Alexander's
terms) it's a great book; the prose can be a little annoying at times,
but the analysis is deep, and mind-changing.

Here's an extract from one of the patterns:

#+begin_quote
*208. Gradual Stiffening*

*The Fundamental philosophy behind the use of pattern languages in
buildings is that buildings should be uniquely adapted to individual
needs and sites; and that the plans of buildings should be rather loose
and fluid, in order to accommodate these subtleties.*

[An essay describing the problem more fully, and the reasoning behind
the solution presented]

Therefore:

*Recognize that you are not assembling a building from components like
an erector set, but that you are instead weaving a structure which
starts out globally complete, but flimsy; then gradually making it
stiffer buit still rather flimsy; and only finally making it completely
stiff and strong.*

*We believe that in our own time, the most natural version of this
process is to put up a shell of sheet materials, and then to make it
fully strong by filling it with compressive fill.*
#+end_quote

Look, Agile Building!

Alexander and his co-authors have found a powerful way of
managing complexity by isolating parts of the process of building to
individual patterns, but neatly tying them into the greater whole by
their use of introductory and closing paragraphs to explain the context
to which the pattern applies. When I read it, I find I'm constantly
flipping back and forth to look at these contextual patterns that
support (or use) the pattern that I'm concentrating on. The book itself
has the Quality Without a Name.

It was only after I'd read /The Timeless Way…/ and /A Pattern Language/ that
I came across the idea of Design Patterns in programming
#+begin_marginnote
In fact, I was
working as a contractor and had a copy of /The Timeless Way…/ on my desk
when a coworker spotted it and made a remark along the lines of “Ah,
going back to the source eh?”, which he then had to explain as I didn't
know what he was talking about.
#+end_marginnote
when a friend lent me the Gang of
Four's
#+header: :trim-pre t
#+begin_cite
Design Patterns.
#+end_cite

I don't really like /Design Patterns/. Too many of the patterns seem to be
concerned with working around problems with the static nature of C++ and
Java---not exactly useful if you're used to a more dynamic OO
language. Another, deeper failing, is the disjointed nature of the
patterns presented; there's no attempt to tie the patterns together in a
coherent language and the whole thing feels like a mishmash of ideas
waiting to be turned into a finished book.

There is one software patterns book I've read that gets it though, that
has The Quality Without A Name in the same way that /A Pattern Language/
does. That book is
#+header: :trim-pre t :trim-post t
#+begin_cite
Smalltalk Best Practice Patterns
#+end_cite
by [[http://www.c2.com/cgi/wiki?KentBeck][Kent Beck]]. If you don't know Smalltalk, don't be put off by that title though. Most of the patterns in the book can be applied directly to any
suitably dynamic OO language (Perl, Python, Perl 6, Javascript...) and
the syntax of Smalltalk is virtually nonexistent and easy enough to pick
up.

The book works well because Beck, quite deliberately, limits its scope
to the "tactics" of coding. Instead of going for the big things, we're
dealing with the nuts and bolts: how to choose good names, how to write
methods in ways that encourage reuse and flexibility, how to keep things
loosely coupled. Beck explains this stuff with concrete examples and
simple rules, that work phenomenally well together. It's hard to put my
finger on /why/ it works so well, but my gut feeling is that it's
because Beck has not forgotten the importance of context.

Very few of the patterns are strictly standalone, they refer to each
other up and down the ‘levels' of the various patterns and the
individual patterns are small enough, and well enough supported by the
other patterns in the language that they remain tightly focussed on the
issue they address.
#+header: :trim-post nil
#+begin_marginnote
2025 Piers here. When I read /Design Patterns,/ I get a nagging sense that there are patterns missing between the ones in the book. There are no such gaps in /Best Practice Patterns./
#+end_marginnote

/Smalltalk Best Practice Patterns/ is a complete pattern language,
something that I've not seen achieved in any other software patterns
book (though Martin Fowler's
#+header: :trim-pre t :trim-post t
#+begin_cite
Refactoring: Improving the Design of Existing Code
#+end_cite
gets pretty close.) It's easy to read; full of practical
wisdom from someone who knows their stuff and can explain it well.

I recommend this book wholeheartedly to anyone who wants to become a
better programmer, and especially to anyone who does object oriented
programming in a dynamic language of any kind. If you find me in a bar
amongst programmers, and we're talking about how to get better at our
craft, then I'll almost certainly be banging on about how good this book
is.

I believe the Java types are fans too, but if I were a java programmer
then I'd find the kind of flexibility inherent in Smalltalk as expressed
in this book would just make me want to abandon Java in favour of
something more expressive.

*** DONE The Fine Art of Complexity Management
CLOSED: [2025-09-20 Sat 12:02]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 20030801-the-fine-art-of-complexity-management
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- Note taken on [2025-09-20 Sat 12:28] \\
  <ul><li>Restored lost data from the Wayback Machine</li>
  <li>Added a margin note about Pixie</li></ul>
- State "DONE"       from "REVISING"   [2025-09-20 Sat 12:02] \\
  A note
- State "REVISING"   from "DONE"       [2025-09-20 Sat 11:49]
- State "DONE"       from "REVISING"   [2025-09-20 Sat 11:48]
- State "REVISING"   from "TODO"       [2025-09-20 Sat 11:48]
- State "DONE"       from "TODO"   [2003-08-01 Fri 11:46]
:END:

Picture this: A magician sits in front of you with a pack of cards in
his hands. He turns over the top card, it's the Two of Hearts. He has
you sign it. He then turns the card back over then takes the top card
from the deck and pushes it home somewhere in the middle. He asks you to
snap your fingers, then he turns over the top card of the deck again.
It's your signed Two of Hearts.

What I've described is the opening of one of the classics of card magic,
called
#+header: :trim-pre t :trim-post t
#+begin_cite
The Ambitious Card,
#+end_cite
in which a signed, selected card repeatedly
jumps to the top of the deck in ever more implausible conditions. On the
face of it, the effect is simple, the card just keeps jumping to the top
of the deck. Behind the scenes, the method is simple too; you just have
to execute a hidden move so that it looks like you're really doing what
you claim to be doing. And there's the rub. I
can execute the required move with no little skill, but if I stop to
think of the complexities of what I'm doing, I won't be able to do it
well. I certainly can't explain how it's done to another magician, well,
I can, but the explanation goes along the lines of "Just practice until
it looks like the real thing".

What does this have to do with complexity management? Well, apart from
the fact that a good magic trick should be presented in such a way that,
no matter how complex the method, the audience just sees the magic,
obviously. But there I go again, using the tool we all instinctively use
to manage complexity. That tool is the word 'just'. We all do it, we
push the complexities of something behind what I've taken to calling a
'Just Story'. Here's a just story for /sole meunière:/

#+begin_quote
The fish, fried in butter, is transferred to a serving dish and over it
is poured a quantity of /freshly cooked/, hissing, foaming butter. A
squeeze of lemon juice, a scrap of parsley, and the dish is ready.
#+end_quote

Couldn't be simpler, could it? Well... Elizabeth David, in
#+header: :trim-pre t :trim-post t
#+begin_cite
French Provincial Cookery
#+end_cite
goes on to explain the full complexity of the dish
so:

#+hugo: more

#+begin_quote
But do they think to tell you, the instructors of the nothing-is-simpler
school,
that the butter in which you fry your sole must be clarified
butter, that you must watch your fish like a hawk to see that it does
not stick and burn, that to turn it without breaking it is a tricky
business, that you should discard the remains of the butter in which
your fish was cooked, and that you must start again with a clean pan and
a quantity of fresh butter, not clarified, and that this butter must be
brought just exactly to the right point when it turns a pale hazel-nut
colour, no more and no less, that it must be poured instantly over the
waiting fish which must with equal immediacy be set in front of those
who are to eat it? Do they even tell you, the optimists who have seen
the dish being cooked without doing it themselves, or the professionals
who have special pans at their disposal, that in the ordinary 10-inch
frying pan to be found in most households there will not be room to cook
more than one not very large sole?

Few small households possess the large oval pans especially designed for
the shallow frying of fish, and one must be realistic about this point.
What is the use of instructing the housewife to cook /sole meunière/ for
six, or even four people in one small pan? By the time the second and
third batches have been cooked, the first will be cold and sodden. In a
restaurant or hotel the cooks can perhaps get away with this sort of
thing---they are not paying for spoiled materials. The housewife with
a critical family, or guests accustomed to good cooking, cannot take the
risk of wasting fine-quality and expensive ingredients. So, unless your
kitchen is supplied with a suitable pan, it is best not to try to cook
/sole meunière/ or similar dishes for more than two people.
#+end_quote

Ah, sorry, it does go on a bit I know, but Elizabeth David is a delight
to read (and even to transcribe). Now, David is writing here for someone
who wants to cook /sole meunière/, so the extended level of description
(rant?) is right for her intended audience. But someone who is thinking
of eating the dish only needs the just story. (Incidentally, should you
ever find a restaurant serving /sole meunière/, you can probably make
yourself really popular with your chef by all ordering it at once).

{{{newthought(The idea of hiding complexity behind ‘just')}}} is extremely powerful when
you are designing interfaces to programs and libraries. Think of a
module you're working on and try and describe the most useful part of
what it does in a single sentence. Now write the code and the interface
so the library does just that. This ties in remarkably well with Test
Driven Development. You just write a test that exercises the simple
interface, code 'til it passes and then refactor.

When you need to add a little more functionality, tell yourself another
just story (keeping it as simple as you possibly can), write the test,
code, refactor. Rinse and repeat. Can you tell how much complexity I'm
hiding behind this ‘simple' development cycle?

Damian Conway is an absolute master at the art of pushing complexity
behind simple just stories (abstractions). Take a look at
anything in his CPAN directory. Almost without exception, his code is
doing ingenious things, but he hides the complexity behind interfaces
of exquisite simplicity. Take a look at

[[https://metacpan.org/pod/Text::Autoformat][Text::Autoformat]], or [[cpandoc:Class::Multimethods][Class::Multimethods]] or, well almost anything he's
ever written and you'll see careful attention to interface.

We did a similar thing when we were working on Pixie.
#+begin_marginnote
Pixie was insanely ambitious failed attempt to make an object database for Perl. The idea was to marshal and unmarshal data from the backing store in a manner that was entirely transparent to the end user. They would just walk a normal Perl data structure.
#+end_marginnote
In essence you
just give Pixie an object, and it gives you a cookie back, which you can
use later to retrieve the object. Most of the time that's all you need.
Sometimes you want to give an object a memorable name, so you use
~$pixie->bind_name(aName => $the_object)~. Pixie handles the problems that
arise when you have complex nets of objects, it handles (in theory) the
issue of locking objects (but that bit's slightly broken at the moment),
in general it just works. But when it doesn't (suppose you have an
object that keeps its state somewhere that [[cpandoc:Data::Dumper][Data::Dumper]] can't see it)
you can just become complicit with Pixie and implement ~px_freeze~ and
~px_thaw~ methods extract state before saving. Our goal, at all times, is
to make everything as simple as possible for the end user, which can
increase the level of code complexity on the implementation side of the
interface (Perl's reflection capabilities, whilst extensive, often
require some serious hoop jumping to access), but hiding it behind the
interface in the way that we do means we only have to deal with it
once, making life easier for the user.

It could be said that Larry's doing the same thing with the design of
Perl 6. Don't believe me? Take a look at
[[http://www.perl.com/pub/2003/07/29/exegesis6.html][the latest
exegesis]] and count the just stories (I would say count the 'just's,
but Damian uses about 3 different meanings and not all of ‘em count for
'just story' purposes).

So, if you want to write a tool with a useful, humane interface, here's
the steps you need to go through once more:

1. Pick the most important/frequent thing that your module does/needs to
   do
2. Frame it as a simple story about what's happening
3. Recast that simple story as test code
4. Make the tests pass
5. Refactor
6. If you haven't run out of time/money/features to add, return to step 1.

And that's all there is to it. I didn't mean to end up with another
description of the process of Test-Driven Development, it just fell out
of my thinking about managing complexity.

Here's one last idea to take from this approach. Next time your boss
comes to you and asks “Can't you just...?” Stop. Think about what he
just asked. Your boss is managing complexity and she doesn't even know
it, and she's just described the interface she wants. Before you dismiss
her as asking for the impossible, at least consider whether or not you
could arrange things so that it looks like you're doing the really
simple thing she's asking for, rather than making it obvious to all your
users that you're doing the really complex thing that you have to do to
achieve it. You know that's what you're doing, but you
don't have to share your pain with people who don't know or care about
the underlying complexity.

Of course, you need a boss who'll trust you when you tell her that,
although what she just asked for sounds simple, implementing it is
rather more complicated and it's going to take some time. But do tell
her, that way she can decide if she really wants it. (Which is an
article for another day I think.)

*** DONE The Importance of Style
CLOSED: [2025-09-20 Sat 21:01]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 20030718-the-importance-of-style
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-20 Sat 21:01]
- State "DONE"       from "TODO"   [2003-07-18 Fri 11:46]
:END:
I was talking to
[[http://use.perl.org/~gav/journal/][Gavin Estey]] on iChat about the problems inherent in interviewing a new
programmer. The cost of screwing up can be enormous. How do you find out
whether the candidate is for real? How do you do it quickly?

Well, those are sticky questions, and there's a discussion of Perl
certification and standards coming up once I've marshalled my thoughts
properly.

Anyway, Gavin showed me one of the quiz questions they used in his
organization:

What's wrong with the following code?

#+begin_src perl
open FILE, "<$filename";
print FILE '$parameter1, ';
print FILE '$parameter2, ';
print FILE '$parameter3\n';
close FILE;
#+end_src

#+hugo: more

Here's my thoughts, in the order I came up with them:

1. Where's the =or die "Can't open $filename: $!"= at the end of the
   first line?
2. Globally scoped filenames are bad, m'kay? That first line would be
   better written as:
   ~open my $fh, '<', $filename or die "Can't open $filename for reading: $!"~
3. Why so /many/ print statements? And what kind of variable names are
   those? Replace ~$parameter1, $parameter2, $parameter3~ with a
   ~parameter~ array. Then those print statements could become
   ~{ print join(', ', @parameter), "\n" }~, which is a little ugly, so
   extract the hack into a helper function, let's call it ~sprint_list~.

So, the code becomes

#+begin_src perl
sub sprint_list { join ', ', @_ }

open my $fh, '<', $filename or die "Couldn't open $filename for reading: $!";
print $fh sprint_list(@parameter), "\n";
close $fh;
#+end_src

Given time I'd do something about ~sprint_list~ so I could just do
~println_list $fh, @parameter~, but this is, after all, only an
interview quiz I'm doing for fun.

Now, these are all matters of style, rather than syntax. The thing I
completely missed when I first looked at the code was a simple matter of
syntax that would have leapt out at me if I'd actually tried to run the
code. The /deliberate/ mistake in the above code stems from the use of
single quotes instead of double quotes. Of course, the rewritten code
fixes that bug almost incidentally --- Gav actually had to point it out
to me.

Which set me thinking. I contend (and I would do wouldn't I?) that the
kind of mind that looks at that code sample from the point of view of
good style and tries to fix that is more useful as a programmer than the
one that looks at the code and sees the typos. It's a little
like the difference between a proofreader who reads a manuscript looking
for literals, and the far more useful editor who reads the manuscript
gives feedback which improves its readability.

This comes back to the point that (I think) Larry Wall has made
regarding programming languages: The reason for writing any program in a
high level language is to communicate the original programmer's intent
/to other programmers/. If they were purely for telling the computer
what to do we might as well be programming in assembly language. Given
this, the programmer's job becomes the same as that of the writer---to
communicate effectively with other human beings. And we do that through
good style, not through good spelling.

Of course, at some point we're going to have to make sure that all the
is are dotted and the ts are crossed in our program, but that's why we
have the ‘-w' switch, test suites and all the other paraphenalia.

I have the feeling I shall be returning to this area soon.

*** DONE Extreme Speaking
CLOSED: [2025-09-20 Sat 21:25]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 20030724-extreme-speaking
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-20 Sat 21:25]
- State "DONE"       from "TODO"   [2003-07-24 Thu 11:46]
:END:
Somewhat to my own surprise, I'm at
[[http://yapc.mongueurs.fr/][YAPC::Europe]]
in Paris. I pitched up to the early birds session and offered a talk if
they'd had any people pull out and it turned out that they had --- Ronan
Oger was due to give a half day tutorial on [[http://yapc.mongueurs.net/yapc/talk/?tid=46][SVG-based GUIs]] on the first afternoon of the conference, but he wasn't going to
make it in time, so the organisers swapped his talk with Dave Cross's
talk on [[http://yapc.mongueurs.net/yapc/talk/?tid=26][Tieing and Overloading Objects in Perl]].

Dave's talk is an hour shorter than Ronan's, so Simon Wistow, Richard
Clamp and me offered three 20 minute talks to fill the gaps.

There was a catch; all the talks I'd taken to America had been aimed at
40 minutes and for the life of me I couldn't see how to make them any
shorter.

“Never mind,” I thought, "I can waffle about Pixie or refactoring or
something, or if all else fails I can brush off 12 Step Perl and get my
audience to do at least half of the work for me.

This was my plan, but then I had this idea for a cunning trick to make
Perl's method inheritance system a little more sane.

There's at least one problem with Perl's inheritance system --- if I
bless a hash into a class, then the blessed object ~isa~ HASH, but method
dispatch will not see any methods in the HASH class. So I fixed that.
The resulting code is faintly evil and I'm not going to show it here,
but there will be an [[http://search.cpan.org/search?query=Acme&#38;mode=all][Acme]]
#+header: :trim-post nil
#+begin_marginnote
2025 Piers here. There wasn't. I can't even remember how I made it work. The slides are long gone.
#+end_marginnote

So, having written the code in the morning I spent the first part of the
afternoon writing slides.

{{{newthought(It's surprisingly easy to do this sort of thing;)}}} the trick is the same as one that lies at the heart of Extreme Programming: Trust. In an XP environment you trust
yourself and the rest of your team to be smart enough to do the Right
Thing at the Right Time. Which isn't as scary as it might sound. In a programming context, if I trust myself to make a decision now,
then surely I can trust myself to make a decision that's at least as
good at some point in the future when I have more of the facts. As a
speaker, if I trust myself to be able to deliver a talk I wrote three
weeks before, then I can surely trust myself to deliver a talk I wrote
five minutes ago.

Try it, it works. But don't make a habit of it.

*** DONE Learning to Trust
CLOSED: [2025-09-24 Wed 21:44]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: learning-to-trust
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-24 Wed 21:44]
- State "REVISING"   from "DONE"      [2025-09-24 Wed]
- State "DONE"       from "TODO"      [2003-08-20 Wed]
:END:

I've bounced off writing this article several times in the past and I'm
still trying to find a good way into it. Here's the (n+1)th take on it
anyway.

Trust is everything. Trust is what keeps the wheels turning. Trust is
when all parties are pointing in the right direction and nobody's
playing CYA games. Trust is opening a joint account and moving in
together. Trust is when you stop using contraception...

#+hugo: more

It's not just emotional relationships, it's vital in business too. Too
often one comes across business cultures where nobody trusts anyone
else; it's endemic in the Dilbert worldview and it can cripple an
organisation. It's so easy to do: everyone knows that
Marketing/Sales/IT/Management/Finance/The Programmers/Creatives are Evil
Trolls/Self Serving Prima Donnas/Idiots/Leeches/Whatever. But... imagine
that isn't true; imagine instead that everyone in the company cares about doing a good job and delivering stuff of value.
Now act as if you believe it.

That's why it's so refreshing to read about Agile methods. Trust is
hardwired into them at such a deep level that almost nobody bothers to
mention it. It's why they seem like such radical ideas, they are so far
removed from the standard view of how organisations work. Much of the
(remarkably vehement) criticism (and subsequent failure to communicate)
that I've seen seems to stem from the fact that the critics are worried
about the downside when trust breaks down and the advocates are just
getting on with trusting each other because it works.

It's so easy to be cynical; to sit back and say “The world doesn't work
that way.” After all, simply by doing so you prove yourself right. But
so what? You were right. Well whoopee doo. Apart from a warm glow of
self-righteousness, what did that achieve?

I used to despair of my mother, who goes through life with the blithe
assumption that people are generally good and kind and honest, and who
is good and kind and honest herself. I used to think that she was going
to be ripped off at every turn but, do you know, she wasn't. Yes, it
happened occasionally, and when it did she was deeply hurt, but it
didn't change the way she lives her life. To change, to become
suspicious and cynical about other people's motives would be a far, far
greater loss than anything that was lost through trusting freely. So
that's how I try to live too. It is both easy and hard to do.

I've come to believe that people repay trust with trustworthiness. I was
delighted to read in the New Scientist about
[[http://fac.cgu.edu/~zakp/publications/CAPCOTrust.pdf][an experiment]] which seemed to back up my intuition. In an experiment,
randomly selected people were asked to give up to $10 dollars to a
person who was unknown to them. That other person would receive 3 times
as much money as the first person gave, and could then return any amount
of money to the first person. (The subjects didn't know who the other
party was, the ‘game' was handled by software). Economic theory, in the
shape of the Nash Equilibrium says that the rational thing to do is for
the first person to give $0. The second person's rational strategy would
be to keep all money they were given and to return none of it. This is
not what happened. It turns out that 50% of the first subjects sent some
money, and of those who received money, 75% returned some. (There
appears to be a reasonably simple neurological mechanism underlying
this surprising (to economists) high level of trust, the paper has more
details).

So, how do you increase the level of trust around you? Start by trusting
yourself. Start trusting others and expecting to be trusted in return.
Start being open about problems and triumphs; if you finish some code
early, let your manager know, if you realise that what you're working on
is going to to be late, let him know as soon as you know, maybe then he
can reprioritise to make sure the important stuff is done --- he
certainly can't do that if you don't tell him. And keep doing it. It's
no good if you give up after a week. NB: This doesn't mean always
agreeing with people, but remember that, no matter how stupid a request
may seem, there's a reason for it; don't just dismiss it out of hand.
And if you can't change your organisation, change your organisation ---
being in a no/low trust environment is a soul destroying process, you
owe it to yourself to move on to somewhere better. Trust yourself to
find the right place.

Trust is its own reward; betrayal its own punishment. A few years ago
now, my wife was talking to a Quaker friend of hers and said “It must be
awful to be in prison knowing you are innocent.”

“Oh,” said her friend, “it must be far worse to be in prison knowing you
are guilty.”

*** DONE Speaking of Trust...
CLOSED: [2025-09-24 Wed 22:02]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: speaking-of-trust
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-24 Wed 22:02]
- State "REVISING"   from "DONE"      [2025-09-24 Wed]
- State "DONE"       from "TODO"      [2003-08-20 Wed]
:END:

I really don't have time for those complete and utter arseholes who
abuse trust. In my narcissistic way I was going through my referer logs
to find out who was linking to me and what they were saying about me, as
I'm sure everyone does. Anyhow, I came across one URL that looked
slightly out of place, claiming as it did to come from a php programming
site...

#+hugo: more

So, I took a look. Strange... no mention of this site on the page
anywhere. And then I took a look at what these bastards were selling.
They were hawking a cunning tool, it looked for openly accessible
logstats scripts and then made a connection to them whilst lying about
the referring page so that the logs (and hence the stats pages) would
have a link to the URL this script was ‘promoting'.

The theory goes that, because Google ranks pages according to the number
of inbound links, this would increase your Google pagerank, and for
commercial sites pagerank is all. For instance, my brother's company
specialises in selling [[https://web.archive.org/web/20111112115729/http://www.longstonetyres.co.uk/][Vintage Tyres]] and, for a while after they
spruced up the website they got to the top of Google's ranking when
you searched for “Vintage Tyres”, and their hit rate (and the number
of sales enquiries coming from the internet) shot up, until someone
else topped the rankings for the same search.

Of course, the theory behind this tool is somewhat flawed, since the
pagerank is based on the pagerank of the site doing the linking if that
makes sense; 1000 links from low ranked sites are worth substantially
less than a link from the front page of a popular site.

What the pondlife who sell this software are doing is attempting to spam
Google. And they're not even doing it that well, but idiots are
presumably forking over more than $100 to use a tool whose express
purpose is to make the web less useful for the rest of us. (And I know
that there are buyers out there because I've seen said this tool's
fingerprints associated with another website in my logs).

In my last article I wrote about learning to trust people; to give the
people you deal with on a day to day basis the benefit of the doubt. But
bastards like these referer spammers are abusing trust on a massive
scale. The software they peddle deliberately attempts to subvert tools
that make the web that bit more useful. Because of this abuse of my
trust, I've had to drop back into sysadmin mode, and I /hate/ having to
think like a sysadmin. Sure I can do it, I did it professionally for
years, but I got out of it because to be any good you have to be
paranoid, and maintaining the appropriate level of paranoia was doing me
no good at all. I've had to password protect my stats page, tweak my
robots.txt file and generally fiddle around with things to make this
site less vulnerable to this particular abuse.

And I /hate/ having to do it. I hate the fact that being a good net
citizen means having to go through these paranoid hoops because their
are malicious bastards and ignorant innocents out there who, in their
greed are trying to turn the web into the cesspit that Usenet became,
and who are trying to abuse Google and other search engines in the same
way that the spammers are abusing email.

At YAPC::Europe this year I came as close as I've come in recent years
to attempting to hit someone who was openly bragging about doing this
sort of thing. I'm sure he knew that what he was doing was wrong, he
just didn't care. About the only thing that stopped me really losing it
was remembering the old adage “Do not wrestle with pigs; you only get
muddy and the pig enjoys it.”

*** DONE /The best thing for being sad/
CLOSED: [2025-09-24 Wed 22:09]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: the-best-thing-for-being-sad
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :work '((author . "T. H. White") (title . "The Once and Future King") (type . "The Once and Future King"))
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :cover '((s . "https://covers.openlibrary.org/b/olid/OL23243757M-S.jpg") (m . "https://covers.openlibrary.org/b/olid/OL23243757M-M.jpg") (l . "https://covers.openlibrary.org/b/olid/OL23243757M-L.jpg"))
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-24 Wed 22:09]
- State "REVISING"   from "DONE"      [2025-09-24 Wed]
- State "DONE"       from "TODO"      [2003-08-29 Fri]
:END:

#+begin_quote
“The best thing for being sad,” replied Merlin, beginning to puff and
blow, “is to learn something. That's the only thing that never fails.
You may grow old and trembling in your anatomies, you may lie awake at
night listening to the disorder of your veins, you may miss your only
love, you may see the world about you devastated by evil lunatics, or
know your honour trampled in the sewers of baser minds. There is only
one thing for it then---to learn. Learn why the world wags and what
wags it. That is the only thing which the mind can never exhaust, never
alienate, never be tortured by, never fear or distrust, and never dream
of regretting. Learning is the only thing for you. Look what a lot of
things there are to learn.”\\
       --- T.H. White, The Once and Future King
#+end_quote

#+hugo: more

T.H. White is one of my favourite writers. It's easy to be dismissive of
The Once and Future King, based on the Disney adaptation---which, like
their version of The Jungle Books, is great fun but a travesty of the
original. However, as I hope the extract shows, there's rather more to
him than that.

My favourite chapter in the book was the one dealing with the night Wart
spent in the castle mews with the falcons and the baleful nightmare,
Cully. Ever since I read it I've been fascinated by falconry---I'll
know I've made my fortune when I can retire to a large house in the
country and keep and become a falconer. I mentioned this to Gill shortly
after we met and she pressed The Goshawk on me. Wow. This is a
fabulously written account of White's attempts to train a Goshawk using
a medieval textbook as his guide (even when he wrote the book, the
profession had moved on a great deal, but White didn't know that). It's
been described by austringers
#+begin_marginnote
Great word, no? An austringer is someone who flies hawks, as opposed to a falconer, who flies falcons.
#+end_marginnote
as the ideal ‘how not to'
book. But you don't read it for the techniques, you read it for White's
perfect prose, for the boundless patience of the man and the seemingly
boundless stubbornness of the bloodyminded Cully. I've flown a Harris
Hawk on a course that Gill arranged for my birthday one year. Walking
around with a hawk on your fist, calmly talking to it and getting it
used to you is (for me) an indescribable experience; the best I can do
is point at The Goshawk and say “Read that!”

I wish I could say that Merlin's speech branded itself on my brain when
I first read it around 25 years ago, but sadly, I can't. It only had
that effect when I logged into my Linux box one morning and my standard
=.profile= ran [[https://web.archive.org/web/20111109163101/http://linux.ctyme.com/man/man0810.htm][~fortune~]] and up it popped. Merlin's dead right you know, the process of learning
things is the finest pill to purge melancholy I know. At my
father-in-law's funeral,
#+begin_marginnote
he had been a stalwart of the [[https://web.archive.org/web/20111109163101/http://www.wea.org.uk/][WEA]]
for a large part of his life
#+end_marginnote
we took that passage and had it printed
up on cards for the mourners, and Gill used it as a reading. Everyone
who knew him remarked on how appropriate and cheering it was. I hope
that it will be just as appropriate a reading for me when my time comes.
*** DONE ‘Extreme Building’
CLOSED: [2025-09-24 Wed 22:26]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: extreme-building
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :work '((author . "Christopher Alexander") (title . "The Mary Rose Museum") (type . "The Mary Rose Museum"))
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :cover '((s . "https://covers.openlibrary.org/b/olid/OL1409575M-S.jpg") (m . "https://covers.openlibrary.org/b/olid/OL1409575M-M.jpg") (l . "https://covers.openlibrary.org/b/olid/OL1409575M-L.jpg"))
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-24 Wed 22:26]
- State "REVISING"   from "DONE"       [2025-09-24 Wed]
- State "DONE"       from "TODO"       [2003-08-30 Sat]
:END:

#+begin_description
#+begin_quote
Our experience as contractors, engineers and architects during the last
15 years has proved one thing over and over again: The things placed on
drawings are inevitably -- always -- wrong in many particulars. Drawings
serve as an important rough sketch of something that will be built, but
must be executed with constant attention to room shape, light, wall and
ceiling detail, openings -- above all to the feelings which arise in
each place, in the construction, as it is taking shape. These feelings
are too complicated to predict and /cannot/ be predicted. When a
building is built from plans that are conceived on the drawing board and
then simply built, the result is sterile at best -- silly most of the
time -- and sometimes unthinkably bad. This is something familiar in
virtually all large buildings that have been built since 1950. It is
inevitable, given the process of construction used to build them. And it
is inevitable that this process must lead to unsatisfactory results.

--- Christopher Alexander, Gary Black & Miyoko Tsutsui /The Mary Rose
Museum/
#+end_quote

Another installment in my ongoing series of reviews of books that Amazon
will take an age to deliver.
#+end_description

#+begin_quote
Our experience as contractors, engineers and architects during the last
15 years has proved one thing over and over again: The things placed on
drawings are inevitably -- always -- wrong in many particulars. Drawings
serve as an important rough sketch of something that will be built, but
must be executed with constant attention to room shape, light, wall and
ceiling detail, openings -- above all to the feelings which arise in
each place, in the construction, as it is taking shape. These feelings
are too complicated to predict and /cannot/ be predicted. When a
building is built from plans that are conceived on the drawing board and
then simply built, the result is sterile at best -- silly most of the
time -- and sometimes unthinkably bad. This is something familiar in
virtually all large buildings that have been built since 1950. It is
inevitable, given the process of construction used to build them. And it
is inevitable that this process must lead to unsatisfactory results.

--- Christopher Alexander, Gary Black & Miyoko Tsutsui /The Mary Rose
Museum/
#+end_quote

#+header: :trim-pre nil :trim-post t
#+begin_cite
The /Mary Rose/ Museum
#+end_cite
is an account of the Center for Environmental
Structure's bid to build a museum around the /Mary Rose/, Henry VIII's
flagship, which, in 1545 unaccountably sank in calm seas, in the sight
of the King himself
#+begin_marginnote
One theory my wife has heard is that someone on board
said “Ee look, there's t' King!” at which point everyone on board rushed
over to one side of the ship to take a look, and the subsequent heeling
of the ship meant she started shipping water through the lowest gun
ports.
#+end_marginnote
with the loss of nearly 700 men. The
story of how the wreck was [[https://web.archive.org/web/20111112072501/http://www.maryrose.org/project/proj1.htm][found, raised and conserved]] is impressive in itself. I can remember
watching BBC specials on the process as it was happening and my
amazement at the dedication/insanity of those involved, but that's not
what Alexander's book is about.

In 1991, Christopher Alexander was in conversation with Prince Charles
(whose interest in architecture is (in)famous). They were lamenting the
then design for a museum to be built over where the /Mary Rose/ still
lies beneath a huge tent, continuously sprayed with a cold mist of water
to prevent any decay of the timbers. The proposed design was for yet
another anonymous hangar-like structure at odds with the other buildings
in the Portsmouth Naval Dockyard, and not exactly sympathetic to either
the /Mary Rose/ or /HMS Victory/ which sits in a nearby dry dock. The
Prince sketched (probably not on a fag packet, but who knows) a profile,
saying to Alexander “What about something like this?”, and off Alexander
went.

At Charles' request, the /Mary Rose/ Trust commissioned Alexander to
produce the proposal for building The /Mary Rose/ Museum that is,
ostensibly what this book is about. The bulk of the book's 128 pages is
taken up by a description of the proposed museum, outlining its
development from the original rough sketch through to a fully costed,
structurally feasible design.

At this point, the principle sponsor backed out leaving the project with
no funds and it had to be shelved. Alexander says that, by then, he and
his team had put in some 5000 man hours of work on the project; I'm sure
they must have been gutted to have the plug pulled. A smaller section at
the back then goes on to discuss the (much rougher) work the team did on
redesigning the museum so that it could be built in incremental fashion
without needing all the funds up front in the hope that the Trust's
funding could be spent on something permanent rather than having to
spend a large amount of the donated money on temporary measures to
maintain the structural integrity of the current ‘tent' over the ship.

So, it's a war story from a failed project, why should you part with the
thick end of £30 to read about that? And what does all this have to do
with programming? Here's why: Christopher Alexander is the most
influential bricks and mortar architect that the world of computer
programming has ever known, if only for his work on Pattern Languages
and ‘The Quality Without a Name'. As a literary form, the design pattern
and the larger pattern language are fabulously useful (and egregiously
abused) ways of describing how to solve many of the problems we face as
programmers.

However, what is often overlooked about Alexander's work is that an
awful lot of what he advocates about the process of generating a room,
building or town foreshadows the processes advocated by the Extreme
Programming people. You should not be surprised to learn that Kent Beck,
author of the seminal book on XP, was also one of the earliest writers
to use design patterns as a way of addressing programming issues.

In /The Mary Rose Museum,/ Alexander describes the ‘agile' process his
team uses on projects, and he also shows the basic contracts between
Owner and Architect, and Architect and Subcontractor that he and his
team use when building.

As a house owner who had some substantial house renovation done
I've been a signatory to a standard RIBA contract for building works,
and it's a very different beast indeed from the Center for Environmental
Structure (CES) contracts. I would rather have signed the CES ones.
Alexander maintains, and I think I agree with him, that his form of
contract deliberately nurtures the process of building something that
will live, while the standard contracts are based on the myth that the
plan is how it will be and any variation will cost the client. The CES
contracts state up front that change happens, and handle that change
without having tons of ‘extras' added to the cost. Here's an extract
from the Craftsman/Subcontractor
#+begin_marginnote
The contract is careful always to refer to
subcontractors as craftsmen “in order to emphasize the craft-like nature
of the work which CES expects.”
#+end_marginnote
contract.

#+begin_quote
ARTICLE 5. CRAFTSMAN'S GOAL. The ultimate purpose of this agreement is
to secure the craftsman's work under conditions which make the
craftsman's work a work of beauty and pride and self-respect, and in
which the craftsman leaves behind work he is proud of, and can cherish
in the future.
#+end_quote

#+begin_quote
It is specifically understood that the craftsman's goal is not only to
be paid for his work, but that the beauty and satisfaction of the work
itself provide part of the craftsman's reward. To this end, the
craftsman shall be treated as an artist who has some power and control
over his work as necessary to allow the creation of a beautiful and
fitting work within limits accepted by CES.
#+end_quote

It seems to me, as someone who believes that we programmers are more
craftsmen than engineers, that the CES contracts for building works may
well offer a useful model for designing contracts for building software
using agile processes. Certainly Alexander has interesting things to say
that will repay your careful reading and consideration.
*** DONE Reading 'The Traits Paper'
CLOSED: [2025-09-25 Thu 09:23]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 130414-reading-the-traits-paper
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 09:23]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2013-04-14 Sun]
:END:

#+begin_description
"Where do Moose roles come from and what are they for?"
#+end_description


There appear to be two camps around The One True =Moose::Roles= Way busily arguing about whether the following code should emit a warning:

#+begin_src perl
package Provider {
    use Moose::Role;

    sub foo { 'foo' };
    1;
}

package Consumer {
    package Moose;

    with 'Provider';

    sub foo { 'no, bar' }
    1;
}
#+end_src

One camp holds that the code should at least emit a warning and ideally
blow up at compile time. The other camp (Moose as implemented), holds
that it shouldn't. The debate gets somewhat heated, people end up
appealing to the [[http://scg.unibe.ch/archive/papers/Scha03aTraits.pdf][Traits paper]]
as if it were some kind of holy writ. What's annoying is that the folk
who appeal to that paper appear to have read a different paper from the
one I remember reading. So I went and read it again, and here's what it
has to say about overriding methods got from traits:

#+begin_quote
Trait composition enjoys the flattening property. This property says
that the semantics of a class defined using traits is exactly the same
as that of a class constructed directly from all of the non-overridden
methods of the traits. So, if class A is defined using trait T, and T
defines methods a and b, then the semantics of A is the same as it would
be if a and b were defined directly in the class A. Naturally, if the
glue code of A defines a method b directly, then this b would override
the method b obtained from T. Specifically, the flattening property
implies that the keyword super has no special semantics for traits; it
simply causes the method lookup to be started in the superclass of the
class that uses the trait.

Another property of trait composition is that the composition order is
irrelevant, and hence conflicting trait methods must be explicitly
disambiguated (cf. section 3.5). Conflicts between methods defined in
classes and methods defined by incorporated traits are resolved using
the following two precedence rules.

- Class methods take precedence over trait methods.
- Trait methods take precedence over superclass methods. This follows
  from the flattening property, which states that trait methods behave
  as if they were defined in the class itself.
#+end_quote

Which is pretty much as I remember, and strongly implies that Moose is
right not to issue a warning.

The paper has more to say on overriding trait implementations in its
section on 'Evaluation against the identified problems' (my italics):

#+begin_quote
Method conflicts may be resolved within traits by explicitly selecting
one of the conflicting methods, but more commonly conflicts are resolved
in classes by /overriding conflicts./
#+end_quote

And (relevant to another argument around role composition that's more or
less current):

#+begin_quote
... sometimes a trait needs to access a conflicting feature, e.g., in
order to resolve the conflict. These features are accessed by aliases,
rather than by explicitly naming the trait that provides the desired
feature. This leads to more robust trait hierarchies, since aliases
remain outside the implementations of methods. Contrast this approach
with multiple inheritance languages in which one must explicitly name
the class that provides a method in order to resolve an ambiguity. The
aliasing approach both avoids tangled class references in the source
code, and eliminates code that is hard to understand and fragile with
respect to change.
#+end_quote

There are folk arguing for removing the aliasing support from Moose role
composition, but I have to say that I find this argument compelling.

{{{newthought(When it comes down to it\,)}}} referencing the traits paper is just argument from authority, which is a classic logical fallacies. However,
if you /are/ going to appeal to an authority, try to make sure that
you're not misrepresenting what that authority says. The original traits
paper does not suggest that overriding a method got from a trait should
come with a warning. On the contrary, it recommends overriding as the
right way to resolve conflicts between multiple composed roles.

You may well think that this is problematic. You may be able to show
examples where silent overriding has bit you on the arse. You may even
have a good argument for introducing warnings. But "Because that's how
the traits paper says you should do it!" is a lousy argument, made
doubly lousy by the fact that is precisely /not/ what the traits paper
says you should do.

**** The view from 2025
I don't know whether this argument is still live, but I think what I missed is that when you use Smalltalk traits, there's nothing so ungainly or ‘loud’ as a warning when you do this kind of overriding, but there is an unobtrusive but distinctive mark next to the method in question's name in the browser so you can see at a glance that it's overriding something and, if that's a surprise, you can investigate further.

Throwing a warning (or even an error) on every run is the opposite of unobtrusive, so I'd still lean towards not doing that. Instead, I suggest checking an environment variable and only warning (or dieing, depending on the setting) if it's present. But I'm not the implementer, so I don't have these headaches. Thank goodness.
*** DONE Halfway through September and nothing new!
CLOSED: [2025-09-25 Thu 20:36]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 030917-halfway-through-september-and-nothing-new
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 20:36]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2003-09-17 Wed]
:END:

And there's nothing new in this post really. I've been indulging myself
in a gadget buying spree including finally getting myself a decent film
scanner and starting to get some of my old negatives and slides scanned
in. I'll be putting more stuff online as time goes on, but for the time
being here's a few photos from [[/photos/Silverstone/][Silverstone]] a
couple of years ago.

I've also finally bought myself a digital camera, in theory so I can't
use the 'but film/dev costs so much!' excuse. Asking how much the
camera, power grip and decently short lens are going to cost me is, of
course, beside the point.
[[http://homepage.mac.com/pdcawley/PhotoAlbum1.html][Here]] is an album
of photos that will mostly be be of interest to my family. The
[[http://homepage.mac.com/pdcawley/.Pictures/Photo%20Album%20Pictures/2003-09-12%2004.19.30%20-0700/Image-8B5395A4E51211D7.jpg][last one]] is probably decent even if you're not related to the subject
though.

*** DONE Monstrous Regiment :truncated:
CLOSED: [2025-09-25 Thu 20:43]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 031003-monstrous-regiment
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :work '((author . "Terry Pratchett") (title . "Monstrous Regiment") (type . "Monstrous Regiment"))
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :cover '((s . "https://covers.openlibrary.org/b/olid/OL7441386M-S.jpg") (m . "https://covers.openlibrary.org/b/olid/OL7441386M-M.jpg") (l . "https://covers.openlibrary.org/b/olid/OL7441386M-L.jpg"))
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 20:43]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2003-10-03 Fri]
:END:

Once upon a time, when the world was still enormously old but I was a
good deal younger, a friend with whom I played D&D
#+begin_marginnote
First edition AD&D actually
#+end_marginnote
pressed a copy of Terry Pratchett's The Colour of Magic on me, telling me it was the best thing ever. So off I went and read it and it was indeed the best thing ever.

Well, I was 14 at the time.

#+hugo: more

**** 2025 Piers Here
Sadly, this one didn't survive my botched import of a typo database, and it didn't get archived by the Wayback Machine either. I should definitely re-read and re-review /Monstrous Regiment/ though.
*** DONE Recent problems
CLOSED: [2025-09-25 Thu 20:48]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 031004-recent-problems
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 20:48]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2003-10-04 Sat]
:END:



My new firewall seems to have forgotten all about port forwarding rules
for a week or so. Which isn't good when that's how this site is served.

All better now. I hope.

*** DONE Back on the Air
CLOSED: [2025-09-25 Thu 20:50]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 031102-back-on-the-air
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 20:50]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2003-11-02 Sun]
:END:

How long did it take me to finally get my finger out and move this blog
over to the new box?

I think the only answer that makes sense is "Too long".

Now I just have to wrestle the godawful CSS into submission.

*** DONE Staff of Life :truncated:
CLOSED: [2025-09-25 Thu 20:52]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 031102-staff-of-life
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 20:52]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2003-11-02 Sun]
:END:

One of my earliest memories is of standing on a low stool, stirring a
teaspoonful of sugar into fresh yeast to wake it up while mum heated a
pan of milk to blood heat before everything all got mixed together to
make a lovely, enriched bread dough that, now I think about it, I could
probably make tomorrow without recourse to a recipe book.

She'd cover it with a tea towel and set it to rise, until the dough would
be lifting the centre of the towel slightly. Once it had risen she'd tip
the dough out and knock it back before dividing it up into buns and
plaits (if I'd been good, I was allowed to do some plaiting...). She'd
lay 'em out on baking sheets to recover slightly, then, just before they
went into the oven they'd get a quick egg or milk wash and a quick
sprinkling of poppy seeds.

*** DONE Not my best week... :truncated:
CLOSED: [2025-09-25 Thu 21:11]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 031116-not-my-best-week
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 21:11]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2003-11-16 Sun]
:END:

Remember boys and girls, always, always, always have a backup.

**** 2025 Here
Yeah, tell me about it!
*** DONE Finding a problem... :truncated:
CLOSED: [2025-09-25 Thu 21:12]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 031128-finding-a-problem
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 21:12]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2003-11-28 Fri]
:END:

You probably don't know this yet, but I'm in the process of preparing a
course on Test Driven Development & Refactoring with Perl which I hope
will find me some favour and income.

One of the trickier aspects, daft as it sounds, is finding a good
problem to use for the course. Ideally you need something that you can
see measurable improvement in as the code is developed, and a well
defined set of requirements. One of the standard problems I've come
across is that of scoring 10-pin bowling.

**** 2025 thoughts
I have no recollection of this at all.
*** DONE Am I awfully intolerant? :truncated:
CLOSED: [2025-09-25 Thu 21:16]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 031202-am-i-awfully-intolerant
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 21:16]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2003-12-02 Tue]
:END:

According to a quick search of groups.google.com, I've been using the
same [[mailto:pdcawley@bofh.org.uk][email address]] for almost exactly 9 years now and in that time I've never succumbed to the temptation to monkey with my mail headers and start hiding my obscured email address down in my sigfile beneath a sign saying 'Beware of the leopard'.

Why? Because, if someone wants to respond to something I've said, it
seems to be the height of rudeness to expect them to do anything other
than simply hit the reply button of their mail client -- generally
people (well me for certain, I can't be sure about everyone else) don't
bother.

But there's something worse (apart from the spammers who cause the
problem in the first place) than the invalid 'From' header.

**** 2025 Note
Another one I have no recollection of. And I have no idea what I'd put below the fold on this.

*** DONE The pleasures of orthogonality
CLOSED: [2025-09-25 Thu 21:36]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 031203-the-pleasures-of-orthogonality
:EXPORT_FILE_NAME: index
:END:
Focusing a large format camera can be a tricky process if you're not
used to it. Unless you have a remarkably simple scene there's usually a
period of frantic adjustment of swings and tilts to try and get the
plane of focus running through the most important elements of the scene.
Most large format photographers will have heard of the Scheimpflug Rule
which says that the plane of sharp focus, the film plane and the lens
plane must all intersect in a single line. This is one of those useful
in theory but useless in practice maxims.

:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 21:36]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2003-12-03 Wed]
:END:

The problem is that you can end up chasing your tail. Adjusting the
focus moves the line of intersection, which means that the plane of
sharp focus is suddenly missing the nearest point, so you adjust the
tilt to take that into account, but that changes the angle of the plane
of sharp focus so it misses the far point, so you adjust the focus,
but...

#+hugo: more

{{{newthought(Which is why a Harold Merklinger is a hero.)}}} He took another look at Scheimpflug's work and discovered what he
calls the ‘Hinge Rule'. Essentially the Hinge Rule lets you choose a
fixed pivot line that doesn't move about as you adjust lens:film
distance (there's a couple of caveats but they're easily worked around).
Knowing how to take advantage of the Hinge Rule means that your
focusing process has disentangled itself slightly and you don't suffer
from a single control altering two or three different things at the same
time. (Actually, it /still/ alters two or three different things, but it
/doesn't/ alter the thing you care about). It won't guarantee you get a
good photo, you still have to know where to stand and where to put the
edges, but it does make the process of making a photograph easier.

There's all sorts of other areas in photography where the battle is to
find controls which don't alter 5 things at once, usually they can't be
found so the trick is to get a good understanding of what the available
controls do to what, and use that knowledge to produce a final image
that looks right. I'd go so far as to argue that PhotoShop is so popular
is because it provides the skilled worker with a set of controls that
genuinely do alter one thing at a time rather than monkeying with an
entanglement.

In other words, PhotoShop introduces orthogonality. Orthogonality is a
term that comes from mathematics, a set of variables is orthogonal if
adjusting one variable has no effect on any of the others.

{{{newthought(Orthogonality is a desireable trait in programs too.)}}} When I change
something in the source code of my program, I don't want to have to go
changing stuff elsewhere to compensate for that change. Both Functional
Programming and Object Orientation are approaches that, used well, help
to increase the orthogonality of your program source, the process of
refactoring code is another process that should tend towards having a
neatly orthogonal code base.

And Programming /languages/ benefit from increased orthogonality. One of
the trends that I've noticed in Larry Wall's work on designing Perl 6 is
that Larry seems to be favouring solutions that disentangle things and
introduce orthogonal features. For instance, in a post about how
properties and object orientation will work in Perl 6 Larry said (my
italics):

#+begin_quote
The basic underlying philosophy is that classes should not be used both
to create objects and to specify the scope of reusable code. At least,
they should not be forced to do both of those. So I think /Perl 6 will
attempt to divorce those concerns./
#+end_quote

Talking about Perl's multimethod dispatch, he pointed out that =multi=
is “now completely orthogonal to scoping”.

Orthogonality's a strange thing though. Seeing it is often a matter of
point of view. A photographer focusing using the Scheimpflug Rule sees
no orthogonality or fixed points at all. Another photographer, with
exactly the same camera, scene and controls who is using the Hinge Rule
sees a fixed point and a set of neatly orthogonal adjustments that he
can make. When you're introducing new orthogonality to a programming
language, the trick is choosing which bits to make independent. Based on
his work so far, I'd say Larry is doing a good job of making those
choices.
*** DONE It's obvious...
CLOSED: [2025-09-25 Thu 21:54]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 040116-its-obvious
:EXPORT_FILE_NAME: index
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :work '((author . "Simon Winchester") (title . "The Meaning of Everything") (type . "The Meaning of Everything"))
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :cover '((s . "https://covers.openlibrary.org/b/olid/OL3323872M-S.jpg") (m . "https://covers.openlibrary.org/b/olid/OL3323872M-M.jpg") (l . "https://covers.openlibrary.org/b/olid/OL3323872M-L.jpg"))
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 21:54]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2004-01-16 Fri]
:END:

I've been reading /The Meaning of Everything/ by Simon Winchester, a
history of the /Oxford English Dictionary/ and, whilst I find his style
a little annoying, the story is fascinating. In the first chapter,
Winchester discusses the history of earlier English dictionaries
#+begin_marginnote
A subject covered in far more detail in the excellent /Chasing the
Sun/, by Jonathon Green if you're interested.
#+end_marginnote
One thing I find strange is that it took so
long for dictionaries to progress from lists of 'hard' words to becoming
the all inclusive things we know today. Early dictionary makers were
happy to simply list and define the kinds of words that I imagine you'd
find in a /Readers' Digest/ Word Power column whilst ignoring the nuts and
bolts of the language. Maybe they just assumed that everyone already
knew them.

#+hugo: more

But it turns out that dictionaries become really potent tools when they
are complete. After all, perfectly good, commonplace words fall out of use and others, once pure jargon, become current.
#+begin_marginnote
If you've read the Jargon
File (or the OED) you'll know that ‘emailled’ once meant ‘embossed (with
a raised pattern) or perhaps arranged in a net or open work’ though I
doubt it was ever a commonplace word back then
#+end_marginnote
Other words change
their meaning over time and a good dictionary, like the /OED,/ will trace
these shifts in meaning.

A good dictionary isn't afraid to state the obvious, if only because
it's not always obvious which words are obvious.

{{{newthought(Nor should we be.)}}} Which brings me, by a somewhat roundabout route to my
point. All too often I've seen books on the practise of programming that
I respect (/Refactoring/ and /The Pragmatic Programmer/ are two good
examples) dismissed out of hand because they are "just stating the
obvious". Christopher Alexander's books on building receive flak along
the same lines; architects dismiss /A Pattern Language,/ arguing that many
of the patterns are obvious and that, anyway, such a collection can't
really generate a beautiful town/room/building.

That Alexander now agrees with them on the latter point doesn't detract
from /A Pattern Language's/ greatness. It's a great book because it states
the obvious with such clarity and focus. It gives the reader names for
things that were nameless intuitions and it enables meaningful
discussion about those ideas because it provides a shared vocabulary.
The same can be said of programming books; /Refactoring/ is a
classic if only because if gives us a new vocabulary. /The Pragmatic
Programmer/ is a great book because it collects those gems of coder
wisdom that we've all come across between two covers, and because it
expresses them so well. Bentley's /Programming Pearls/ did the same thing
years ago, but we've learned
#+begin_marginnote
And forgotten, of course
#+end_marginnote
a few things since then...

Stating the obvious isn't a bad thing. Doing so poorly, without due
attention to your audience is the only sin. So don't be offended when
someone tells you something you already know. Think about what's been
said, maybe the other persons's perspective will improve your
understanding. Maybe the confirmation is good. Or maybe it's
unnecessary. So, politely let on that you already know this stuff and
let the conversation move on.

*** DONE Welcome to the world
CLOSED: [2025-09-25 Thu 22:00]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 040317-welcome-to-the-world
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 22:00]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2004-03-17 Wed]
:END:

At twelve minutes past noon today, my stepdaughter Iona gave birth to a
7lb 2oz son, Isaac Stamper.

I never expected I'd be a grandfather by 36...

*** DONE It's been a while...
CLOSED: [2025-09-25 Thu 22:05]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 040825-its-been-a-while
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 22:05]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2004-08-25 Wed]
:END:

Mmm... Eurofoo. At what other technical conference could you spend an
afternoon in an improvised comedy workshop, marvel at the bandwidth of
five guys from Fotango toting a terabyte from London to Amsterdam in 45
minutes, gasp at the audacity of the BBC's Creative Archive project and
rave about a favourite tech book before discovering that said book's
editor is sat next to you?

EuroFoo was the European iteration of the Friends Of O'Reilly Camp first
held at the O'Reilly offices in Sebastapol last year and jolly good fun
it was too. On the evidence of this conference there's a good deal to be
said for getting a bunch of smart people into a conference centre and
divvying up the program on the first night. The improvised comedy
workshop got on the program because, as we went round the room
introducing ourselves a couple of people mentioned that they did improv
and a bunch of us yelled out for a session. I missed them, but everyone
who went to the lockpicking sessions really enjoyed them.
#+header: :trim-post nil
#+begin_marginnote
and, owing to a
slight cockup with a car key, a Guildford Perl Monger's pocket and the
train to Schipol. Well, let's just say that the acquired skills came in
handy---last I heard they were stymied by the steering lock.
#+end_marginnote

As anyone who's read almost anything I've written about the practice of
programming in these pages knows, I'm rather keen on the underlying idea
of deciding things as late as possible; many of the talks had a
freshness to them that I don't think you'd get at a conference where
talk proposals got submitted 3 or 4 months earlier. Also, because there
were all of 140 or so delegates, the bar track was rather more laid
back; when I went to OSCON last year, the choice seemed to be between
running around like a blue arsed fly trying to network with all and
sundry all the time, or to form up into a relatively small circle of
acquaintance and just hang out with those guys. I ended up playing a
good deal of Zendo, and had a few games of Go with Holger Krekel, who,
at 3 dan is a good deal stronger than me and trounced me in all three
games, but who taught me a good deal in the process. Thanks Holger.

Oh yeah, and Python and PHP types aren't evil. Who'd've thought it?

This is probably my last /Just a Summary/ post before I begin the slow
morph into a teacher; if I can work out how to continue blogging my
teaching experiences here without compromising anyone's privacy I hope
that those of you who are still looking in on this blog despite the
ongoing lack of posts for the last n months will enjoy reading them as
much as you've enjoyed my wibbling about programming.

*** DONE Eurofoo photos
CLOSED: [2025-09-25 Thu 23:00]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 040825-eurofoo-photos
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 23:00]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2004-08-25 Wed]
:END:

Here's one of my photos from Eurofoo. I appear to have caught DJ Adams
at a particularly gormless looking moment. [[file:~/Documents/DJ-Gormless.png]]
*** DONE Cooking Fat!
CLOSED: [2025-09-26 Fri 00:13]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 040910-cooking-fat :truncated:
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-26 Fri 00:13]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2004-09-10 Fri]
:END:

The weather recently has been remarkably muggy, so I’ve been keeping
my office window open while I’m working. Which is all very well, but
we’re trying to keep the cats in, so I have to keep the office door
closed. Of course, it shouldn’t be too much of a worry, we’re on the
first floor (2nd floor if you’re American) and surely the cats
wouldn’t be so stupid as to go leaping out of the window. Still, best
to keep the door shut.

You can tell where this is going can’t you?

**** 2025 Update
Yeah, the cat jumped out of the window and woke me up with his yowling at some ungodly hour in the morning.

There was probably more detail in the bit that got lost during a migration and didn't get picked up by the [[https://web.archive.org/][Wayback Machine]], but the above is the nub of it.
*** DONE WYL: Introducing myself
CLOSED: [2025-09-25 Thu 23:21]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 041011-wyl-introducing-myself
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-25 Thu 23:21]
- State "REVISING"   from "DONE"       [2025-09-25 Thu]
- State "DONE"       from "TODO"       [2004-10-11 Mon]
:END:

This is the first exercise in chromatic's
[[http://www.wgz.org/chromatic/writeyourlife][Write Your Life]] essay writing project. Follow the link for more information.

#+hugo: more

How do I look? Right now, I look uncomfortable; I've just changed career
tracks and after years as a happy Perl programmer, I'm training to be a
maths teacher. Which is fine, not a problem. What makes me uncomfortable
is the dress code. After years of working in environments where the most
formal outfit you're likely to see is a polo shirt with the name of the
company embroidered on it (worn only by weirdoes and the poor schmucks
who drew the “Manning the trade show stand” short straw), suddenly, I'm
having to wear a suit.

It's not all bad; when one is as generously proportioned as me,
off-the-peg suits aren't an option. Once you reach the realms of the 64
inch waist and the 60 inch chest the only option is bespoke. So, right
now I'm wearing two pieces of a bespoke dark grey woollen suit that (oh
joy of joys!) fits me. It doesn't ride up around my ears when I'm
writing on the board. Give me a few more weeks and I might even start
feeling comfortable in it. I already look slimmer in it.

Hmm... somehow I don't think you'd recognize me from the above. So...
I've a large head, crew cut dark brown (and rapidly greying) hair. I
wear a full, but close cropped, beard which is slightly redder than the
hair on my head, but it's going grey too. My eyes are grey/blue behind a
pair of rimless glasses with rounded rectangular lenses that turn dark
brown in UV light. I'm 6 feet tall and weigh more than my bathroom
scales can measure (and they top out at 25 stones).

There are very few photos of me; I'm generally the one behind the
camera. I enjoy taking what I think of as ‘candid portraits' of friends
at parties, but I don't always carry my camera with me. Photography's a
strange thing, if I want to take good photos, then it's as if the social
part of my brain gets turned off, or turned to other things as I
concentrate on where the light is, where I need to stand, where to put
the edges and all the other minutiae of taking a photograph instead of a
snap. I've taken some great photos at parties, but I haven't really
enjoyed the parties as much as I would if I were actually taking part.
The “photographer's stance” almost requires you to stand apart. People
have commented on how, when I'm taking photos I kind of disappear into
the background---no mean feat when you're built to my scale and
shooting with long, fast lenses. I've no idea how I do it. I prefer film
to digital for most things, but I've still gone with a digital SLR
camera. Just because I prefer the quality of a black and white silver
print doesn't mean I can't appreciate the benefits of almost instant
feedback that digital gives you. A couple of months ago I was shooting
at my cousin's wedding. With my laptop and an appropriate card reader
I'd put together a slide show of everyone's digital photos before the
party had finished, which went down rather well with the bride and
groom.

I'm generally laid back. All the courses and material I've seen on
behaviour management in the classroom emphasises the importance of
under-reacting; responding with the head, not the gut. Most of the time
I do this naturally, I'm not pretty when I lose my temper, and I try not
to do it most of the time.

I am naturally argumentative though. As far as I'm concerned, argument
is a sport. I think it runs in my family. My dad's long enjoyed a good
argument with my uncle Joe, who seems to enjoy it too. A good argument
is far more enjoyable if both parties are aware that it's not ‘for
blood'. The old saw, “Do not wrestle with pigs, you only get muddy and
the pig enjoys it” is appropriate here. I've noticed that, sometimes, it
can be hard to tell who's the pig in the more vicious kind of argument.

Politically I'm a pragmatic anarchic atheist pacifist, which tends to
boil down to something approximating ‘woolly liberal' most of the time.
The problem with anarchy as a system of government is that it requires
good will and understanding from all concerned, which is probably
possible to maintain if you already have a functioning anarchy, but a
complete bloody nightmare if you want to get to a functioning anarchy
from anything else. Being a pacifist/coward means I'm not about to
propose any bloody revolutions, so I'll continue to choose the
alternatives that tend to increase freedom.

I'm not a big fan of recorded music. As far as I'm concerned a recording
is a pale shadow of what happens between musicians and the audience
during a live performance. Live performance is what it's about, whether
music, comedy, theatre or poetry reading. Nothing else comes close. As a
folk singer, I prefer the informal performance of a session or
singaround to formal performance with a stage and PA and all that jazz.
When audience and performers are sitting together, when the audience is
made up of performers waiting their turn. Well, it doesn't take much for
the magic to happen. Once there's a stage, and PA, and all that stuff in
the way it's far harder for the thing to catch light. It takes a
Springsteen, a Prince, a U2, or your favourite live band here, to really
do the business in a big arena.

Having said I don't particularly like recorded music, I still have a
home studio and a small collection of condenser microphones. Just
because listening to a recording isn't as good as being there doesn't
mean that recording has no value. My recording gear is a tool; an
objective listener if you like. Just because I'm not a professional
performer doesn't mean I don't want to get better at the craft of
singing, and one way to do that is to record myself then listen to the
results critically, to think about how I did something and how that made
it sound. It's a good deal easier to try something for the first time in
front of a microphone than it is to try it in front of an audience...

*** DONE WYL2: Putting Myself On The Map
CLOSED: [2025-09-26 Fri 00:13]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 041013-wyl2-putting-myself-on-the-map
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-26 Fri 00:13]
- State "REVISING"   from "DONE"       [2025-09-26 Fri]
- State "DONE"       from "TODO"       [2004-10-13 Wed]
:END:

This is exercise 2 in chromatic's excellent
[[http://www.wgz.org/chromatic/writeyourlife/][Write your life]] exercise.

Home. Four letters. Easy to understand. Hard to pin down.

If we take home as being “The place where one sleeps”, then home is a
two bedroom first floor Tyneside flat. If you are fortunate enough to
know Tyneside well, then I've just told you a great deal about where I
live; you can probably sketch the floor plan, especially if I tell you
that there's the usual extension at the back with a kitchen and bathroom
in it.

#+hugo: more

For the majority of you: Tyneside flats are purpose built flats.
Originally built as rental accommodation, a large proportion of them are
now owned by their occupiers. Built in terraces of two storey buildings,
flats are arranged in pairs; upper and lower. Ours is an upstairs flat,
which means it's slightly larger than the flat below it because there's
no hallway apart from the stairs, there's also a possibility of
extending up into the roof void.

You enter the flat through the right hand door and come straight
upstairs to a small inner hall with three doors leading from it. The
door to your left leads through into my office, a small, cluttered space
which barely contains a huge, height adjustable desk with a dual screen
PowerMac G5 setup, a Digidesign Command|8, a couple of audio monitors
and an A4 Wacom tablet on it. There's a certain amount of other detritus
on the desk, and every other available horizontal surface. I really
should tidy the place up;
#+begin_marginnote
*2025 update:* I'm still crap at tidying, but I've been diagnosed with ADHD. Hopefully, once I get on the appropriate meds, that should improve
#+end_marginnote
it's driving Gill up the wall, but somehow I
never seem to get around to it.

Back at the hall, the next door, moving clockwise from my office door,
is the door to our bedroom. It's a large room, with a King size bed, a
couple of built in wardrobes, a couple of bedside tables overflowing
with stuff, and an airer full of drying clothes. Gill's side of the bed
is the tidy side, my bedside table is as disorganised as my office.
Unusually, there are no dirty clothes on the floor by the bed at the
moment. Probably because we've just done a load of washing.

The last door on the landing leads into the sitting room, which is
reasonably large, and it needs to be. There's a small sofa; an easy
chair; a Stressless recliner (which is causing a depressing amount of
stress at the moment --- it keeps breaking); Gill's desk; three deep
bookshelves filled with books (most of the books aren't here yet); a
(small) dining table; a small dresser base with a mini hi-fi on top; the
TV/TiVo/DVD collection; a surprisingly pretty new gas fire; and an
annoyingly proportioned built in cupboard.

Opposite the door you came into the room through is the door into the
small galley kitchen. It's cramped but there's all the essentials there,
except for a dishwasher (we're still trying to work out how to cram one
in. If you've ever owned a dishwasher you will no doubt be aware
that they very rapidly decay from luxury to essential). Carrying on
through the kitchen there's the cats' landing (where their food and
drink bowls live) to the left, stairs lead down to the back door and the
litter tray and straight ahead is the bathroom complete with too small
bath and the depressingly cramped (when you're built on my scale) shower
over it.

We spend most of our time in the sitting room, as you can tell from the
books scattered about, the teapot that always seems to be on a side
table or in the kitchen beside a kettle that's about to boil...

However, I wouldn't call this flat /home/. Not properly. It's a
transitional space; where we live until we've sold the Newark house,
when we'll be able to sell this flat too and move into big old house
somewhere, with room for guests, an office for Gill, a recording area, a
darkroom, a decent sized kitchen...

The Newark house?

The Newark house is where we used to live, and it's far nearer to the
kind of place I want to make my home in. From the street, it almost
looks like a child's drawing of a house. Four windows, a door in the
middle, a pan tiled roof with a chimney stack right in the middle of the
roof. The bit you can see from the road is an approximately 400 year
old, timber framed cottage. You come in through the front door into a
long, low-ceilinged dining room with a 12 foot long dining table running
the length of it. The Newark house is a huge, rambling building, from
the road it looks like a simple two up/two down cottage, but it's
deceptive, the house goes back a long way. There's four bedrooms; a big
kitchen with massive range cooker; a library with built in shelving holding
some of the books; small bathroom holding a lovely long, deep and wide bath and a shower room
with a fabulously large shower.

There's a lot wrong with it too. For a start, it's in Newark, which is a
little tricky when I'm training as a maths teacher in Middlesbrough and
Gill's doing a degree at Newcastle University. Then there's the
surveys...

We thought we'd sold it. We really did. The buyers liked the fact that
it's old. They liked the eccentricity and general lack of verticality in
the front section. They liked the beams and the lime plaster. They even
liked the 4' high door from the main bedroom into the bathroom. What
they didn't like was the results of their structural survey. According
to their surveyor, the house is subsiding and subject to progressive and
continuing movement and even if remedial action is taken, he can't
guarantee that the house will remain standing. The phrase “only delaying
the inevitable” was used in his report. Understandably, our buyers were
somewhat taken aback by this.

So, we've called in our original structural surveyor, who reckons that
there's been no movement since he surveyed the building over a year ago.
Our insurers' surveyor has paid a visit and reckons there's no
subsidence (but there's some engineers turning up for a peace of mind
check on the drains). With any luck we'll be able to get away with
reinforcing some of the ties and supplying a bunch of certifications
from the various surveyors and the buyers (who love the house) will be
willing to complete. Or they won't.

If they don't, it looks like we might be moving back to Newark for a
while come the summer while we get the work done and maybe while I do my
induction year as a newly qualified teacher, then sell the house and
move back to the North East so Gill can either complete her degree or
switch to a masters. Or we'll stay in Newark for a while longer; it does
have the advantage of being a good deal nearer to friends in the South,
but it's still within striking distance of Gateshead, which is where my
step-daughter lives.
*** DONE WYL3: A Day In The Life
CLOSED: [2025-09-26 Fri 11:32]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 041013-wyl3-a-day-in-the-life
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-26 Fri 11:32]
- State "REVISING"   from "DONE"       [2025-09-26 Fri]
- State "DONE"       from "TODO"       [2004-10-13 Wed]
:END:

Exercise 3 in the [[http://www.wgz.org/chromatic/writeyourlife/][Write Your Life]] project.

On a typical morning, I wake up before the alarm goes at 0630, stumble
through into the bathroom, then back into the sitting room where I get
suited and booted for the day. (Gill, being a sensible type, gets to
sleep in some more, so banging around the bedroom in the dark isn't a
particularly good idea). If I'm running to time, I nip into the office,
check my mail and skim through my RSS feeds.

#+hugo: more

Because the commute into Middlesbrough is time dependent, I try
to get out of the house by 0715. If I manage to do that, the run into
the school where I'm on placement takes about 45 minutes---if I leave
much later then it'll take at least an hour, and punctuality is
essential when you're teaching.

I still find being in school as a
‘teacher' a little weird; it's like being backstage. Right now, I'm
spending most of my time observing classes. I'll be doing a little bit
of teaching in the next week though, and I start my teaching practice
proper at the beginning of November.

I'm enjoying lesson observations, but I'm itching to get teaching now.
The way observations work is that I watch while the teacher introduces the
topic, and then we both help the pupils with their exercises. I
sometimes find it shocking what the kids get wrong though and, after
spending almost all my school years ignoring teachers who nagged me to
show my working and do some bloody homework for once, I'm finally
starting to understand where they were coming from. I've even managed to
explain to kids why it's a good idea without having to resort to the “If
you show the working and you go wrong, we can spot where you went wrong
and you might not lose all the marks” gambit by pointing out that,
whilst they may understand what they're doing now, they'll be coming
back to these books in two years time when they're revising for exams
and a page full of answers isn't that useful.
+header: :trim-post nil
#+begin_marginnote
Note to Extreme Programmers: this argument may be familiar.
#+end_marginnote

The school day finishes at 1530 and it takes about an hour to get home
(Middlesbrough's clogged with parents doing the school run, so things
take longer). Once I'm home I'll either sit and read, do some
preparation for the next day, burn some time on the X Box or hang out on
IRC and generally catch up with mail and stuff. Gill's usually home
before me, and she's recently been drawing the cooking short straw.
Lately I've been going to bed by nine---I dread to think how I'm going
to cope once I've started teaching;
#+begin_marginnote
Spoiler from 2025: I didn't cope.
#+end_marginnote
I'm exhausted now.

Every other Tuesday night however, I head over to the Cumberland for a
singing session with a bunch of fellow folkies. The Cumberland session
is one of the most enjoyable singarounds I've been to, it's relatively
small with a really high proportion of good singers. And, unusually
these days, the majority of ’em sing traditional songs instead of
modern songs in the 'folk idiom'. Last night saw a particularly bloody
selection of Child ballads, a couple of delightfully bawdy songs and the
odd selection from the Sacred Harp. I think I may have been the only
person who sang a ‘written' song, and that was
[[http://www.worldburnsclub.com/poems/translations/434.htm][Composed in August]], which isn't exactly a new song. I've had some fabulous nights there, including one glorious evening with
[[http://www.ncl.ac.uk/sacs/staff/profile/anderson][Alistair Anderson]], [[http://www.ncl.ac.uk/sacs/staff/profile/sj.kerr][Sandra Kerr]], three of the
[[http://www.threescompany.org.uk/][Witches of Elswick]] and “fiddly”
[[http://www.squeezy.fsnet.co.uk/spiers_boden/][Jon Boden]]; at one point we were competing for who could sing the longest
ballad (Fay Hield won with a 15 minute reading of
[[http://www.tam-lin.org/][Tam Lin]]) which we followed up with a couple of rounds of Peter Bellamy
appreciation. We were glad there was an extension that night.

And then to bed. Not the most exciting of daily routines I'd be the
first to admit, but I'm happy enough on it.
*** DONE WYL4: Easy Life
CLOSED: [2025-09-26 Fri 10:32]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 041018-wyl4-easy-life
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-26 Fri 10:32]
- State "REVISING"   from "DONE"       [2025-09-26 Fri]
- State "DONE"       from "TODO"       [2004-10-18 Mon]
:END:

Exercise 4 of chromatic's [[http://www.wgz.org/chromatic/writeyourlife/][Write Your Life]] tells me to:

#+begin_quote
Create a new invention, change your life circumstances, or somehow write
away a difficult or time-consuming task. First define the problem, show
how it affects you, and then invent it away.
#+end_quote

But I'm not going to do that, exactly, because I already did it.

#+hugo: more

The Perl 6 Summary is a weekly summary of the traffic in the various
Perl 6 related mailing lists. I've written it for the last two and a
half years, and I've managed to pretty much stick to a weekly schedule.
But it's a resource hog. Even once I got into the swing of it, a busy
week on the lists could easily mean I would spend 8 hours writing the
summary --- after all, if you want to write a decent précis of a thread
with 100 or so messages in it you're going to need to read (or at least
skim) it. Some threads were easy to handle, especially those in
[[http://www.nntp.perl.org/group/perl.perl6.internals][perl6-internals]]
which could often be summarized as

#+begin_quote
Joe Bloggs had a problem with IMCC's string parsing. He and
Leo discussed it for a while to nail down the problem,
then Leo fixed it.
#+end_quote

[[http://www.sidhe.org/~dan/blog/][Dan Sugalski]]'s design documents often prompted rather more discussion, but
I could usually hand-wave it away with “... then it all got a bit
technical” and simply link to the root of the thread for those who were
interested.

The other list, perl6-language is a different matter. It would go quiet
for weeks at a time before pulling a Mount Saint Helens and exploding
into life. Sometimes there was provocation---an Apocalypse or an
Exegesis, say. Sometimes a seeming innocuous starter question or
proposal would precipitate a pyroclastic torrent of proposal, counter
proposal and the odd moment of sanity. Once things quietened down, you
could usually rely on Larry
#+begin_marginnote
Larry Wall, creator of Perl. If you're reading this and
don't know who Larry is already then I'm curious to know how you found
this blog.
#+end_marginnote
to extract the good stuff, but discussions could run for weeks.

Whilst such behaviour can be seen as a sign of a healthy list, it was
far from easy to summarise. Threads would branch off in weird
directions, only occasionally reuniting with the main line of the
discussion (assuming there even was a main line anyway). Getting
something I was happy with could take ages.

Ages I can't spare any more. So, last week, I gave up writing the
summaries. My teacher training course is using too many of my own
personal computrons for me to be able to spare the mental effort
required to get the summaries written. It's been a wrench to do it, but
it's a big weight off my mind.

And the feedback from summary readers has been phenomenal. I've always
solicited feedback in the summaries, and the little I got was positive,
but I've had more feedback since I stopped than I've had in, probably,
the last year, and it's all been good. Which is lovely.

****** Bah! Paperwork.
:PROPERTIES:
:CUSTOM_ID: bah-paperwork.
:END:
As you may or may not know, one of the banes of a teacher's life is the
paperwork. There's /tons/ of it. Timetables, lesson plans, seating
plans, medium term plans, schemes of work. If you're a trainee then you
have fewer lessons, but twice as much paperwork per lesson. UK teacher
training is now ‘evidence based' which means that part of your job as a
trainee is to collect evidence of your competence as a teacher. And
evidence is usually on paper.

So, anything I can do to reduce the weight of paper I have to tote
around every day has to be a good thing. Ideally I want some way of
tying everything together. I want clickable seating plans so I can
quickly check my notes on a particular pupil. I want all my lesson plans
in one place, linked back to any assessments of the lesson as taught. I
want links from my timetable to the sets I'm teaching...

In short, I want a Wiki.

One of the great things about the web is that often you don't have to
invent something yourself, you just have to be aware of possible
solutions. So on Thursday I grabbed a Wiki installation
#+begin_marginnote
I went with [[http://www.instiki.org/][Instiki]]
for reasons of not wanting to be arsed with Apache configuration,
coupled with a desire to learn more Ruby if the time presents itself
#+end_marginnote
and spent a couple of hours feeding it some of the information I've been
gathering about the classes I'll be teaching in the next half term. It's
great.

I've not used a personal Wiki before---I've not had the need---but now I've started with one,
#+begin_marginnote
It didn't last. That kind of thing rarely does. Probably down to the ADHD, I now realise. These days, what notes I have tend to live in one big Org file, parts of which occasionally get published here -- 2025 Piers
#+end_marginnote
I'm not sure why it's taken me this
long. It's great. Now, if I can just hack it to generate inline images
from TeX markup.

****** I'll tell you what I want, what I really really want
Teleportation. That's what I want. I really resent losing an hour and
half of every week day to the delights of commuting to Middlesbrough
from Gateshead. I drive a Mini Cooper, and it's a lovely car to drive.
But plugging up and down a dual carriageway isn't where it's at it's
best. If I could zap myself to and from school every day the problem
would be solved. What a shame that our current understanding of The
Rules seems to imply that, whilst quantum weirdness doesn't rule out
teleportation, other complexities seem to rule it out big style for
anything on the macro scale. Bummer.

*** DONE Wilf on the Best Swing Ever
CLOSED: [2025-09-28 Sun 11:25]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 040827-wilf-on-the-best-swing-ever
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-28 Sun 11:25]
- State "REVISING"   from "DONE"       [2025-09-28 Sun]
- State "DONE"       from "TODO"       [2004-08-27 Fri]
:END:


[[file:~/tmp/best-swing.jpg]]
In the garden of my parents' house is a
big old willow tree. Attached to a branch some 30 or 40 feet up is this
swing, which swings out over a tiny stream. Because the swing is
actually attached to a block and tackle, it's possible, once you have
the knack to keep it swinging (and indeed increase the swing's
amplitude) by judiciously shortening and releasing the rope.

This is, truly, the swing of the gods.

One day, when my nephews Bert and Wilf are older, they'll realise this.
Until then it's just the best fun ever.

*** DONE Developments
CLOSED: [2025-09-28 Sun 16:44]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 050714-developments
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-28 Sun 16:44]
- State "REVISING"   from "DONE"       [2025-09-28 Sun]
- State "DONE"       from "TODO"       [2005-07-14 Thu]
:END:

There were many things I didn't like about working in London: the long
commute in, the bloody tube, the long commute home, the expense...

But then there are the things I miss. Here's a small example.

#+hugo: more

I used to send my negatives to [[http://www.metroimaging.co.uk/][Metro Imaging]] to be developed and contact printed. Back in the Fat Times I
had an account, so I'd phone them up and an hour or so later a courier
would appear at reception, pick up my films and haul ‘em off to
Clerkenwell. The next day, another courier would arrive with my contacts
and the negatives all neatly filed. The service was (and presumably
still is) exemplary, with no extra charge for their couriers (they were
reassuringly expensive in the first place). In all the time I used Metro
I /never/ got anything back where the standard of work was less than
excellent. Okay, there was one time they cross processed a roll of slide
film as C41, but I'd dropped it off at the C41 desk and not the E6 desk
and I hadn't given them correct instructions---they waived that charge
immediately without any hassle though.

Maybe I've been spoiled, but if you're going to call yourself a pro lab
then the very minimum you should be providing to your customers is a
guarantee of clean negs and no quibbles when things go wrong.

Then I moved to Newcastle. I might be using the wrong lab, but there
appears to be only one pro lab in town that handles black and white. And
in the last 10 or so rolls of film they've handled, 80% of them have
come back covered in dust, drying marks or both. 5 of those rolls were
from my stepdaughter's wedding. Almost every image I've scanned has
needed substantial work with PhotoShop's (marvellous) healing brush
before they were fit to be put on Flickr. When I raised this with them,
expecting a grovelling apology and a full refund, the first response I
got was positively confrontational and I only ever managed to get a 40%
discount on the spoiled films.

I had initially thought that it was only the wedding films that had been
screwed and they'd mended their ways, but over the past couple of days
I've finally got round to scanning in some photos I took on St George's
day, and there's those drying marks again, which means an extra 30
minutes per image (and probably more needed, this was pretty quick and
dirty).

So, if you're reading this in the north east and you shoot on black and
white film, who do you use for dev and print? Or maybe I should just see
if Metro will let me mail my film to them. I've got another five rolls
of unprocessed film and I don't want the pain of drying marks again. Nor
do I want the hassle of learning to do it myself with so little space in
the flat.
*** DONE I was a choirboy once... :truncated:
CLOSED: [2025-09-28 Sun 17:09]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 050716-i-was-a-choirboy-once
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-28 Sun 17:09]
- State "REVISING"   from "DONE"       [2025-09-28 Sun]
- State "DONE"       from "TODO"       [2005-07-16 Sat]
:END:

I remember, from about the age of 9, setting out from our tall Georgian
terraced house with the green door and the brass lion knocker to walk
the mile or so to choir practice. Through the park in the middle of the
square, past the Gaumont Cinema (the last of its chain to bear the name
-- it became the Odeon only when the headed paper ran out) and on down
Hall Gate past Barker & Wigfall with its bewildering window display of
bicycles, televisions and furniture. Past the godawful concrete arcade
that still contained the Pilgrim Bookshop, Doncaster's only specialist
bookshop. Past the Odeon arcade and right into Silver Street passing the
High Class Butchers and Dad's tailor, then through Bowers Fold, the
little pedestrianized snicket that leads through to the market place
with a little toy shop in the middle.

#+hugo: more

... and that's all there is. Another one lost to my slapdash approach to data migration.


*** DONE Argh! My Ears!
CLOSED: [2025-09-28 Sun 17:05]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 050716-argh-my-ears
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-28 Sun 17:05]
- State "REVISING"   from "DONE"       [2025-09-28 Sun]
- State "DONE"       from "TODO"       [2005-07-16 Sat]
:END:


It's two in the morning, I can't sleep and someone's attempting to
commit an outrage upon my ears. According to the BBC's website, I have
been watching

#+begin_quote
**Myth and Music**

Open University. Composer Judith Weir explains why she wrote a series of
works based on Scottish folktales about people who have disappeared
mysteriously.
#+end_quote

Which sounds like it might be interesting. And it is interesting ---
people slow down to look at traffic accidents don't they?

#+hugo: more

Ms Weir witters on about all being part of a tradition and how she's
just carrying that on, and then we cut away to listen to a singer and
pianist doing grave damage to /Bonny George Campbell./

/Bonny George Campbell/ concerns a lord who rode out one day and never
came back. It doesn't say why, nor why he rode out with a sword at his
knee in the first place. Here's the full text of the version I sing:

#+begin_quote
High upon highland and low upon Tay\\
Bonny George Campbell rode out on a day.\\
Saddled and bridled and booted rode he.\\
Home came his good horse, but never came he.\\
\\
Down came his mother with her heart full of care.\\
Down came his pretty wife, a curling of her hair\\
The meadow lies green, and the corn is unshorn\\
And bonny George Campbell he'll never return\\
\\
Saddled and bridled, so gallant rode he\\
With a plume in his helmet and a sword by his knee.\\
Home came his saddle so bloody to see.\\
Home came his good horse, but never came he.
#+end_quote

Gill sings “The meadow lies green and my baby's unborn”, but I reckon
that rather lays it on with a trowel.

Now, I've heard classically trained singers having a crack at
traditional songs---it's almost never a good idea. The daft buggers
only sing the dots. And they're so mannered. It's cruel; folk songs and
tunes are living things, what brings them to life is the variation and
ornamentation a particular singer brings to them. Classical singers
don't seem to know how to do that.

Oh, and another thing, the piano is not traditionally used to accompany
the singing of Border ballads. The traditional accompaniment is the
silence of a listening audience.

So, you can imagine my reaction when I hear a gruesomely operatic tenor
and his partner in crime on the piano proceed to perform Ms Weir's
setting of the song. She's changed the tune, and some of the words
(reducing the strength of the second stanza for my money), and for extra
points, the piano accompaniment seems to bear no relationship to...
well... anything. To compound the injury (and I know this sounds like
someone complaining about how the dreadful food at their hotel came in
such small portions) the narrator proceeded to talk all over the piece.
The song ends and we cut back to the composer and she's patently /proud/
of the festering pile of aural muck she's foisted on those members of
license paying public who are still up at 2 in the morning. She has the
air of someone who's rescuing something.

Music is something for everyone to listen to, make and participate in.
The composer who takes a tune with a beautiful, singable set of words
and serves ‘em up in a new setting that can only be attempted by
professionals who have to be careful not to listen too hard to each
other for fear of hitting notes that sound good together is missing the
point. I loathe the 'professionals only' attitude.

The music industry says that sharing music is bad because the music
shared will obviously be the product of an artist with a record
deal whose income will be hurt. Peer-to-peer distribution has the
potential to be more than that, it enables anyone to distribute /their/
music. Lots of it will be, um, not to my taste, but that's fine. The bar
to entry is so low; a decent microphone and the kit to record yourself
is, whilst not cheap, far from the kind of expensive it used to be.

But no, to the mainstream, music is a product, made by highly skilled
professionals who Autotune and comp their ‘talent' into shiny
chromeplated loveliness and serve it up as the latest thing, whilst
always, always, looking out for the next thing. After all, you wouldn't
want the talent to think it has a career would you?

Music is too important for that.

In his song Here is my Home Si Kahn writes about the act of singing
together as a secular sacrament and I think he's dead right.

Music is about a connection between musician and audience, something we
share, something that makes us better people for the length of a song.
I'm not sure it's possible to make music without an audience. Oh you can
practice, but the real stuff comes out when you're playing with and for
other people.

Whatever else you do this week, try and hear (or make) some live music.
It doesn't really matter if it's any good, what matters is the sharing.

But if it's a performance of Judith Weir's work, I suggest you try
somewhere else first---find the worst busker on the planet, the bloke
with a tin whistle, a dog on a string and about three quarters of a half
remembered tune. Trust me, it's still an improvement.

******* COMMENT Comments
:PROPERTIES:
:CUSTOM_ID: comments
:END:

<<comments_div>>
1.

   <<comment-80>>

   [[http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=60]]

   roofpant@hotmail.com over 1 year later:

   I like your version -- as per Nic Jones

   I did find this on the web, which explains his loss
   ([[http://www.kyloerecords.co.uk/100/03.htm][http://www.kyloerecords.co.uk/100/03.htm]])

   I couldn't agree more with your sentiments about classical singers
   who make complete dog's breakfasts of decent songs.

   3. Bonny George Campbell (Roud 338)

   High in the Highlands, oh, laich by the Tay,\\
   Bonny George Campbell went riding one day.\\
   He saddled and he bridled, so gallant and so free.\\
   But hame came his good horse, but never came he.

   Out comes his mother a-tearing her hair,\\
   Then out comes his young wife so lovely and fair.\\
   Oh, the valleys they lie so green and the corn lies unshorn,\\
   But for bonny George Campbell, he will never return.

   For a band of MacDonalds he met on his way,\\
   For they took him and they hung him,\\
   And they strung him to a tree.\\
   So hame came his good horse, but never came he.

   Now the valleys they lie so green and the corn lies unshorn,\\
   But for bonny George Campbell, he will never return.

2.

   <<comment-81>>

   [[http://www.gravatar.com/avatar.php?gravatar_id=0196ff65610046d2f8ba58bc4a45f144&size=60]]

   [[http://www.bofh.org.uk/][Piers
   Cawley]] over 1 year later:

   Wow. Thanks.

*** DONE We're getting there
CLOSED: [2025-09-28 Sun 17:22]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 050728-were-getting-there
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-28 Sun 17:22]
- State "REVISING"   from "DONE"       [2025-09-28 Sun]
- State "DONE"       from "TODO"       [2005-07-28 Thu]
:END:

#+begin_subsection
**View from 2025**\\
None of this works at the moment, and I'm highly unlikely to reinstate it the form described here.
#+end_subsection

After much poring over /The Truck Wheels/ pdf [fn:14] and the /Pickaxe book,/
accompanied by a certain amount of waving of dead chickens, I'm
pleased to direct your attention to the sidebar where you will find a
selection of relevant links to Amazon. If your interest is piqued, maybe
you'd like to toddle over there and spend your hard earned cash on these
and other fine books, enabling me to live in the lap of luxury on
kickbacks from everyone's favourite book pimp.

In the future I hope to have slightly prettier links, but I'm still
finding my way around the code, and Amazon Web Services, and...

Still, I'm pleased with it so far.
*** DONE What's the right answer?
CLOSED: [2025-09-28 Sun 17:27]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 050728-whats-the-right-answer
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-28 Sun 17:27]
- State "REVISING"   from "DONE"       [2025-09-28 Sun]
- State "DONE"       from "TODO"       [2005-07-28 Thu]
:END:

So, in my quest to get Amazon links working I've been spending time
hanging out on the =#rubyonrails= irc channel asking dumb questions and
generally liking the place, when someone asked “Are you the famous
Perl Programmer, Piers Cawley?”

What's the right answer? Sadly, I wasn't shameless enough to simply
answer “Yes.”

Coincidence is good isn't it? A couple of hours earlier, I'd been
reading [[http://www.livejournal.com/users/marypcb/][Mary Branscombe]] on the talk [[http://www.oblomovka.com/][Danny O'Brien]] gave at this year's OpenTech about ‘geek micro celebrity' or some such topic. How very odd.
*** DONE The Latest Paypal Phisherman
CLOSED: [2025-09-28 Sun 17:32]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 050729-the-latest-paypal-phisherman
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-28 Sun 17:32]
- State "REVISING"   from "DONE"       [2025-09-28 Sun]
- State "DONE"       from "TODO"       [2005-07-29 Fri]
:END:

So, I just read the latest phishing attempt. Someone purporting to be
[[http://www.paypal.com/][Paypal]]
tells me that someone else has sent me £12. Which would be lovely, if
true.

However, a cursory inspection of the HTML source shows that it's a scam
site. Lovely.

Interestingly, the mail refers to images served by Paypal. If I were
paypal, or any of the other online money handlers come to that, I'd be
seriously considering tweaking my image servers to return “The page you
are currently looking at is probably a scam” type images to any request
that doesn't come with the appropriate referer and/or cookie. Sure, it
uses up processor cycles, but I'm guessing that processor cycles are
cheaper than fraud.

Just a thought.

*** DONE Javascript heresy
CLOSED: [2025-09-29 Mon 08:42]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 081029-javascript-heresy
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-29 Mon 08:42]
- State "REVISING"   from "DONE"       [2025-09-29 Mon]
- State "DONE"       from "TODO"       [2008-10-29 Wed]
:END:

So, remind me, what's the rationale for always using the optional =;=
when you're writing Javascript? The only reasons I can think of, off the
top of my head are, “Because you'll break minifiers without it” and
“Because Douglas Crockford doesn't like it”. Well, broken minifiers that
can't parse the language correctly can kiss my fat hairy arse and
argument from authority cuts little ice here.

[[http://morethanseven.net/][Gareth Rushgrove]] pointed me at
[[http://icanhaz.com/semicoloninsertion][an article]], which suggested that it's because Javascript will insert a
semicolon after the =return= in:

#+begin_src javascript
return
{ key: "value" }
#+end_src

But that's not exactly surprising, and falls squarely into the “Don't do
that then” category of bugs, or putting it another way, the [[http://blog.plover.com/][Dominus]]
Doctrine (“You can't just make shit up and expect the computer to know
what you mean, retardo!”) applies.

Ruby also has an optional semicolon, but good style is avoid using them
and we seem to survive. In fact, the Ruby parser is rather less capable
than Javascript's:

#+begin_src javascript
jQuery('.class')
  .addClass('whatever')
  .html('New inner HTML')
#+end_src

is legal Javascript, but, in Ruby you have to write:

#+begin_src ruby
jQuery('.class') \
  .addClass('whatever') \
  .html('New inner HTML')
#+end_src

because if you don't the compiler throws its toys out of the pram and,
for bonus
points, the resulting parse error implies that the parser
knows what you meant but decided to throw the error anyway. Ho hum.

Is there something I've missed? Or should I make a preemptive stand
against incompetent minifiers and start writing my Javascript without
semicolons?

***** Updates
:PROPERTIES:
:CUSTOM_ID: updates
:END:
In the comments, “James” offers a succinct piece of code using Prototype
that demonstrates the problem rather neatly. In the absence of
semicolons, code like:

#+begin_src javascript
var foo = 3
, bar = 2 + foo

[foo, bar].each(function (i) { console.log(i) })
#+end_src

gets parsed as

#+begin_src javascript
var foo = 3
, bar = 2 + foo[foo, bar].each(...)
#+end_src

Which isn't exactly what you want. If I were feeling churlish, I might
argue that such problems are one reason why the jQueryish way:

#+begin_src javascript
var foo = 3
, bar = 2 + foo
$.each([foo, bar], function () {...})
#+end_src

is a better way of iterating over things, but I'm not entirely sure that
it is. Looks like I'll keep taking the semicolons.

***** [[http://www.bofh.org.uk/2008/10/29/javascript-heresy#commentary][5 historic comments]] »
:PROPERTIES:
:CUSTOM_ID: commentary
:CLASS: feedback
:END:
#+begin_marginnote
This old comment system doesn't work any more, but you can use webmentions to
respond and they'll show up here eventually.
#+end_marginnote

****** ![[http://www.gravatar.com/avatar.php?gravatar_id=49d7ddd7cad2d9fefa8b75ac3acc75dd&size=48&url=http://notes.infomixer.com/][http://www.gravatar.com/avatar.php?gravatar_id=49d7ddd7cad2d9fefa8b75ac3acc75dd&size=48&url=http://notes.infomixer.com/]] By [[http://notes.infomixer.com/][Mario]] Wed, 29 Oct 2008 12:08:11 GMT
:PROPERTIES:
:CUSTOM_ID: by-mario-wed-29-oct-2008-120811-gmt
:END:

I remember a time when one of the two main webbrowsers didn't cope
well if you left semi-colons out. It was Netscape, and it's been a
while since that was a main webbrowser, so I wonder whether this is
just collectively remembered, but nobody dares to mention it because
it would imply that Internet Explorer was doing something right all
along.

****** ![[http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=48&url=][http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=48&url=]] By James Wed, 29 Oct 2008 20:07:00 GMT
:PROPERTIES:
:CUSTOM_ID: by-james-wed-29-oct-2008-200700-gmt
:END:
#+begin_src html
<script src="http://prototypejs.org/assets/2008/9/29/prototype-1.6.0.3.js" type="text/javascript" charset="utf-8"></script>
<script type="text/javascript">
    var foo = 3
    var bar = 2 + foo
    [foo, bar].each(function(i) { console.log(i) })
</script>
#+end_src


****** ![[http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=48&url=][http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=48&url=]] By bitherder Thu, 30 Oct 2008 04:45:31 GMT
:PROPERTIES:
:CUSTOM_ID: by-bitherder-thu-30-oct-2008-044531-gmt
:END:
I've run into problems in the past where I've gotten some JS code
working in FF, but doesn't work with IE when semi's are left out.

Also, for splitting Ruby statements with long call sequences in them,
you /can/ do the following:

#+begin_src ruby
jQuery('.class').
  addClass('whatever').
  html('New inner HTML')
#+end_src

But, as you point out, you can't do it with the period (.) at the
beginning of statement segments, because Ruby will only figure out
that the line needs to be continued if there is an “operator” at the
end of the line.


****** ![[http://www.gravatar.com/avatar.php?gravatar_id=0196ff65610046d2f8ba58bc4a45f144&size=48&url=http://www.bofh.org.uk][http://www.gravatar.com/avatar.php?gravatar_id=0196ff65610046d2f8ba58bc4a45f144&size=48&url=http://www.bofh.org.uk]] By [[http://www.bofh.org.uk/][Piers Cawley]] Thu, 30 Oct 2008 05:38:30 GMT
  :PROPERTIES:
  :CUSTOM_ID: by-piers-cawley-thu-30-oct-2008-053830-gmt
  :END:
@bitherder: But the trailing dot style is gruesome, as I have ranted
before (I was arguing for a compulsory semicolon in Ruby at the time
-- I am nothing if not various in my opinions).

@James: Ah... yes. That'd be a nasty surprise and no mistake. I knew
there had to be a better reason than making minifiers happy.

****** ![[http://www.gravatar.com/avatar.php?gravatar_id=9bc66138520204ede006080dedfefc1a&size=48&url=http://www.greenhometherapy.com/][http://www.gravatar.com/avatar.php?gravatar_id=9bc66138520204ede006080dedfefc1a&size=48&url=http://www.greenhometherapy.com/]] By [[http://www.greenhometherapy.com/][Dr. Green]] Sun, 30 Nov 2008 13:52:55 GMT
:PROPERTIES:
:CUSTOM_ID: by-dr.-green-sun-30-nov-2008-135255-gmt
:END:

Interesting argument. I must admit that I use the ; to finish lines
and have never thought about not using it. As someone who uses
minifies to reduce load time, I guess I'll be sticking with it.

  --------------

*** DONE I think I'm in love with an Axe
CLOSED: [2025-09-29 Mon 09:35]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 080929-i-think-im-in-love-with-an-axe
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-29 Mon 09:35]
- State "REVISING"   from "DONE"       [2025-09-29 Mon]
- State "DONE"       from "TODO"       [2008-09-29 Mon]
:END:

We've just spent the weekend on one of [[http://www.robin-wood.co.uk/][Robin Wood's]] spoon carving workshops, which was my 41st birthday present
from Gill. It was great fun, if a little tiring. There is something
primally satisfying about turning a piece of wood into woodchips.
Getting a spoon or spatula at the end of the process is a huge bonus. We
came away with a bag full of more or less decent [[http://en.wikipedia.org/wiki/Treen_(wooden)][treen]],
a couple of woodcarving knives and a burning desire to own one of
Robin's small drinking vessels.

Oh. And I fell in love with an Axe. The Gränsfors Bruks
[[http://www.gransfors.com/htm_eng/produkter/new_prod/p_slojdbila.html][Swedish Carving Axe]] to be precise. This is the tool you use for turning a log
into a spoon blank, and for much of the rough shaping of that blank.
During the course of the weekend, I tried both the Gränsfors axe and an
English ‘Kent pattern' axe of the sort that can be picked up at car boot
sales for pennies and sharpened and rehandled easily (quite what you use
to rough out the new handle is left as an exercise to the interested
reader). The English axe was very nice, but the Swedish one was just
lovely. In particular, there's a move which involves gripping the handle
right by the head and flicking your wrist. This takes the top half of
the blade through the wood in a precise sweeping motion that slices off
wood in a way that's almost erotically satisfying.

Yup. I don't get out much. Why do you ask?

My choice lies before me: an English blade for maybe a fiver from a car boot
sale or a sultry Swedish beauty for seventy quid from [[http://www.gransfors.co.uk/gransfors%20tools.html][gransfors.co.uk]]? It's not
even a choice. The Swedish beauty had me at ‘car boot sale' -- I'm not sure
which circle of hell car boot sales belong in, but I'm certain I don't want
want to go there. Besides, I'm a photographer and a computer programmer. Most
of the [[http://www.dpreview.com/previews/nikond700/][bits]] [[http://www.ebonycamera.com/][and]] [[http://www.apple.com/macbookair/][pieces]] cost hundreds or thousands of pounds.

Now, where did I put my credit card?
*** DONE If you're going to add a hook, make it a big one
CLOSED: [2025-09-29 Mon 09:51]
:PROPERTIES:
:EXPORT_HUGO_BUNDLE: 080908-if-youre-going-to-add-a-hook-make-it-a-big-one
:EXPORT_FILE_NAME: index
:END:
:LOGBOOK:
- State "DONE"       from "REVISING"   [2025-09-29 Mon 09:51]
- State "REVISING"   from "DONE"       [2025-09-29 Mon]
- State "DONE"       from "TODO"       [2008-09-08 Mon]
:END:



Jay Fields [[http://blog.jayfields.com/2008/09/domain-specific-languages-dont-follow.html][responds to]] Ola Bini's [[http://olabini.com/blog/2008/09/evil-hook-methods/][Evil Hook Methods?]] about the common ruby
idiom that lets us write:

#+begin_src ruby
class Fruit
  include DataMapper::Resource
  property :id, Integer, :serial => true
  property :name, String
  property :notes, Text, :lazy => false
end
#+end_src

What Ola and Jay don't like about that is the way that a single
=include DataMapper::Resource= actually adds class methods to Fruit
because the implementation of =DataMapper::Resource.included= looks
like:

#+begin_src ruby
module DataMapper::Resource
  def included(module)
    module.send :include, InstanceMethods
    module.send :extend, ClassMethods
  end
end
#+end_src

Which is a perfectly common idiom nowadays, but which breaks =include='s
contract in annoying ways. Jay proposes fixing this by adding a =become=
method to Object which would wrap the =include= and =extend= in such
away that they'd be called by the including class. Huzzah. And it makes
sense... sort of. But it really doesn't go far enough.

Let's take another look at the original code snippet shall we? The thing
that I notice is the wide scope of that ‘property' method. It really
isn't needed anywhere except for defining how a =Fruit= is mapped onto
the database. What happens if we take a leaf out of Perl's book:

#+begin_src ruby
class Fruit
  use DataMapper::Resource {
    property :id, Integer, :serial => true
    property :name, String
    property :notes, Text, :lazy => false
  }
  property :foo # => raises an exception
end
#+end_src

The block gives our extending module somewhere to play, it can introduce
a full on domain specific pidgin for the duration of the block with no
fear of polluting the including class with anything but the methods its
contracted to provide. So, how do we implement =use=. Something like the
following should serve the purpose:

#+begin_src ruby
class Module
  def self.use(mod, *args, &block)
    mod.used_by(self, *args, &block)
  end

  def self.used_by(mod, *args, &block)
    if instance_behaviours || class_behaviours
      mod.become(self)
    else
      mod.send(:include, self)
    end
  end

  def self.become(mod)
    include mod.instance_behaviours) if mod.instance_behaviours
    extend mod.class_behaviours if mod.class_behaviours
  end

  def self.instance_behaviours
    nil
  end

  def self.class_behaviours
    nil
  end
end
#+end_src

The key idea here is that, in the default case, =use= will ignore all
its arguments beyond the first and just include that module (a more
robust implementation would probably ensure that an exception was raised
if any extra arguments got passed). If the module author had written her
module to comply with Jay's proposed =become=, then we simply call
=become=.

The interesting stuff happens when a module wants to do something a
little more trick. So a version of DataMapper might do something like:

#+begin_src ruby
class DataMapper::Resource
  def self.used_by(mod, &block)
    mod.become build_behaviours(mod, &block)
  end
end
#+end_src

And =build_behaviours= would =instance_eval= the block with an object
that would capture the properties and use them to build a set of class
and instance methods appropriate to the description.

Another module might simply take a hash to describe how things should be
parameterized. It all depends on the needs of the module being used. The
aim being to avoid polluting the caller's namespace any more than
necessary. If I use a DataMapper type package, then all I want to end up
with in my client classes are appropriate instance accessor methods, I
don't need spare class methods like =property= or =storage_names= that
are only of any use when I'm describing my class.

***** Updates
:PROPERTIES:
:CUSTOM_ID: updates
:END:
I edited one of the code snippets to remove a particularly heinous piece
of brace matching. Thanks to Giles Bowkett for the catch. Also edited
another snippet to make it into real ruby rather than some bastard
combination of Ruby and Perl. Thanks to Yossef for that catch.

***** [[http://www.bofh.org.uk/2008/09/08/if-youre-going-to-add-a-hook-make-it-a-big-one][10 historic comments]] »
:PROPERTIES:
:CUSTOM_ID: commentary
:CLASS: feedback
:END:

****** ![[http://www.gravatar.com/avatar.php?gravatar_id=ce8b03e5750097942c58e12b46724312&size=48&url=http://gilesbowkett.blogspot.com][http://www.gravatar.com/avatar.php?gravatar_id=ce8b03e5750097942c58e12b46724312&size=48&url=http://gilesbowkett.blogspot.com]] By [[http://gilesbowkett.blogspot.com/][Giles Bowkett]] Mon, 08 Sep 2008 03:23:44 GMT
:PROPERTIES:
:CUSTOM_ID: by-giles-bowkett-mon-08-sep-2008-032344-gmt
:END:
I think starting a block with ~{~ and ending it with ~end~ is evil. Either
~{}~, or ~do/end~. Anything else is the work of the devil.

Further, I demand that Matz alter the language to prevent people from
using it in a way that I personally do not approve of.

I demand satisfaction!


****** ![[http://www.gravatar.com/avatar.php?gravatar_id=0196ff65610046d2f8ba58bc4a45f144&size=48&url=http://www.bofh.org.uk/][http://www.gravatar.com/avatar.php?gravatar_id=0196ff65610046d2f8ba58bc4a45f144&size=48&url=http://www.bofh.org.uk/]] By [[http://www.bofh.org.uk/][Piers Cawley]] Mon, 08 Sep 2008 04:12:40 GMT
:PROPERTIES:
:CUSTOM_ID: by-piers-cawley-mon-08-sep-2008-041240-gmt
:END:
Christ! If that works then consider me boggled.

I'll fix the typo immediately sir!


****** ![[http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=48&url=http://blog.tracefunc.com][http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=48&url=http://blog.tracefunc.com]] By [[http://blog.tracefunc.com/][Jamie Macey]] Mon, 08 Sep 2008 09:20:53 GMT
:PROPERTIES:
:CUSTOM_ID: by-jamie-macey-mon-08-sep-2008-092053-gmt
:END:
This isn't a workable solution, as it doesn't provide a mechanism for
the other important public class-methods like Model.all and
Model.first.


****** ![[http://www.gravatar.com/avatar.php?gravatar_id=0196ff65610046d2f8ba58bc4a45f144&size=48&url=http://www.bofh.org.uk/][http://www.gravatar.com/avatar.php?gravatar_id=0196ff65610046d2f8ba58bc4a45f144&size=48&url=http://www.bofh.org.uk/]] By [[http://www.bofh.org.uk/][Piers Cawley]] Mon, 08 Sep 2008 11:19:42 GMT
:PROPERTIES:
:CUSTOM_ID: by-piers-cawley-mon-08-sep-2008-111942-gmt
:END:
@Jamie: How do you work that out?

The instance methods generated by ~build_behaviours~ get put on the
~instance_behaviours~ attribute of whatever it returns, the public
class methods get put on the ~class_behaviours~ attribute. Problem
solved.

~used_by~ gets license to do whatever the hell it likes to its user
after all. Yes, so can ~include/included~, but that's not how its
contract is documented, so it's problematic. A new interface for
extending modules and classes gets to write its own contract, the
trick is coming up with a minimal interface which allows for richer
possibilities than the existing interfaces.

Experience with Perl shows that having an extension method that you
can pass arbitrary arguments allows a great deal of flexibility in
this area.


****** ![[http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=48&url=][http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=48&url=]] By Yossef Tue, 09 Sep 2008 22:59:50 GMT
:PROPERTIES:
:CUSTOM_ID: by-yossef-tue-09-sep-2008-225950-gmt
:END:
~sub~  included? Someone's been thinking about Perl just a little too
much.

Also, there's no reason to use send to extend an object. That's a
public method.


****** ![[http://www.gravatar.com/avatar.php?gravatar_id=0196ff65610046d2f8ba58bc4a45f144&size=48&url=http://www.bofh.org.uk][http://www.gravatar.com/avatar.php?gravatar_id=0196ff65610046d2f8ba58bc4a45f144&size=48&url=http://www.bofh.org.uk]] By [[http://www.bofh.org.uk/][Piers Cawley]] Wed, 10 Sep 2008 01:25:12 GMT
:PROPERTIES:
:CUSTOM_ID: by-piers-cawley-wed-10-sep-2008-012512-gmt
:END:
Argh! Thanks for spotting the sub. You should see what happens when I
try to write Perl nowadays...

I haven't changed the =send :extend= part though, mostly because of
the company it's keeping in its method.

#+begin_src ruby
def included(module)
  module.send :include, instance_behaviours
  module.extend, :class_behaviours
end
#+end_src

Just looks weird.


****** ![[http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=48&url=][http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=48&url=]] By Yossef Wed, 10 Sep 2008 22:01:09 GMT
:PROPERTIES:
:CUSTOM_ID: by-yossef-wed-10-sep-2008-220109-gmt
:END:
I tried to write some Perl after spending at least a year away. It was
an awkward, bumbling experiment. I couldn't even remember that I had
to use ~package~.

I guess what I meant to say was that there's no reason other than
aesthetics to use ~send~ to extend an object. It's valid enough in
this context, but there are times I've seen it on its own, and that's
just wrong. And note that I whole-heartedly agree with your comment on
Jay Fields's post regarding ~extend~ vs. ~extend_with~.


****** ![[http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=48&url=http://blog.tracefunc.com][http://www.gravatar.com/avatar.php?gravatar_id=d41d8cd98f00b204e9800998ecf8427e&size=48&url=http://blog.tracefunc.com]] By [[http://blog.tracefunc.com/][Jamie Macey]] Thu, 11 Sep 2008 17:25:35 GMT
:PROPERTIES:
:CUSTOM_ID: by-jamie-macey-thu-11-sep-2008-172535-gmt
:END:
@Piers I must have missed that 4th code block that handled the
include/extend (where the class methods obviously go) and was just
looking at the 3rd one, with the block for local extension.


****** ![[http://www.gravatar.com/avatar.php?gravatar_id=3efeaee8256d256a05c4a19c3a57001a&size=48&url=http://www.brikd.com][http://www.gravatar.com/avatar.php?gravatar_id=3efeaee8256d256a05c4a19c3a57001a&size=48&url=http://www.brikd.com]] By [[http://www.brikd.com/][Mr eel]] Fri, 12 Sep 2008 01:04:51 GMT
:PROPERTIES:
:CUSTOM_ID: by-mr-eel-fri-12-sep-2008-010451-gmt
:END:
Personally, I think using include in this way has become a common and
well-understood idiom. Doing backflips to avoid it isn't really
worthwhile.


****** ![[http://www.gravatar.com/avatar.php?gravatar_id=0196ff65610046d2f8ba58bc4a45f144&size=48&url=http://www.bofh.org.uk/][http://www.gravatar.com/avatar.php?gravatar_id=0196ff65610046d2f8ba58bc4a45f144&size=48&url=http://www.bofh.org.uk/]] By [[http://www.bofh.org.uk/][Piers Cawley]] Sun, 14 Sep 2008 16:18:00 GMT
:PROPERTIES:
:CUSTOM_ID: by-piers-cawley-sun-14-sep-2008-161800-gmt
:END:
@Mr eel: I tend to agree with you. If all we were buying was avoiding
that, I wouldn't be bothered. However, I think there's value in
something which makes it easy to pass an argument or block to the
mixed in module as it's mixed in.

* Notes :@note:
:PROPERTIES:
:EXPORT_HUGO_SECTION: /note
:END:
** DONE [2025-08-21 Thu 22:23]
CLOSED: [2025-08-21 Thu 22:27]
:PROPERTIES:
:export_file_name: 1
:END:
I'm working on adding short notes without titles to the blog.

Basically something that maps neatly to Mastodon toots or Bluesky skeets. The chief difficulty will likely be styling them in a fashion that's consistent with the rest of the blog, but still compact

** DONE [2025-08-22 Fri 23:12]
CLOSED: [2025-08-24 Sun 11:42]
:PROPERTIES:
:export_file_name: 2
:END:

Notes appear to be working.
I have the horrible feeling that the CSS I'm using to style things is about as inelegant as it's possible to be, but things to seem to be looking okay in a decent array of viewport sizes. I'll call that a win.

** DONE [2025-08-24 Sun 11:38]
CLOSED: [2025-08-24 Sun 11:42]
:PROPERTIES:
:export_file_name: 3
:END:
I feel like I'm in a maze of twisty SCSS files and am getting very confuzzled. However, the layout's mostly working except in a narrow viewport, when the timestamp on a note happily fits in the left margin, but the timestamp on a post is truncated to the left because the font size doesn't seem to reduce as much. As far as I can tell, they're both the same size according to the stylesheet.

Ho hum… mostly working is better than not working. Check out the book cover thumbnails!

** DONE [2025-08-28 Thu 08:39]
CLOSED: [2025-08-28 Thu 08:39]
:PROPERTIES:
:export_file_name: 4
:END:
I confess that the blog is implying that it works with webmentions, but the infrastructure I used to display them isn't working at the moment. Fixing it's on the long TODO list that I might never get around to. However, the service that catches any webmentions is still in operation, so I'm not keen to remove it entirely.

Maybe I need to bump fixing things up the priority list.

** DONE [2025-08-28 Thu 08:59] :noteToSelf:
CLOSED: [2025-08-28 Thu 09:00]
:PROPERTIES:
:export_file_name: 5
:END:
I really should get around to replacing bloody GitHub.

God help me if I end up self-hosting my own instance of some code forge, but AI bollocks can fuck right off. I keep hoping that people are going to wake up and realise it's the very worst kind of emperor's new clothes bullshit, but they're taking their own sweet time about it.

** DONE [2025-08-28 Thu 17:30]
CLOSED: [2025-08-28 Thu 17:33]
:PROPERTIES:
:export_file_name: 6
:END:

This is absolutely what a sane person might write in their blog, isn't it?

#+begin_example
,#+begin_example
,,#+begin_src emacs-lisp :tangle nil :noweb-ref bibble
,#+end_example
,#+begin_src emacs-lisp
#+end_example
#+begin_src emacs-lisp
(setq some-variable 'some-value)
#+end_src
#+begin_example
,#+end_src
,#+begin_example
,,#+end_src
,#+end_example
#+end_example

And then doing this to their CSS to make it work

#+begin_src css
.highlight+.highlight {
    margin-top: 0;
}
#+end_src

I'm going to hell, aren't I?

{{{newthought(For bonus points\,)}}} see if you can work out what's /actually/ written in the source file for this note.
** DONE [2025-09-07 Sun 02:09]
CLOSED: [2025-09-07 Sun 02:11]
:PROPERTIES:
:export_file_name: 7
:END:
I /think/ I have webmentions displaying correctly again. However, we're updating everything manually again at the moment, at least until I get a webhook up and running again, so it might take a while for your replies, reposts &c. to show up on the site.

Still, it does appear to be working again.

** DONE [2025-09-07 Sun 09:19]
CLOSED: [2025-09-07 Sun 09:22]
:PROPERTIES:
:export_file_name: 8
:END:
Yay! Kicking it old school with a =Makefile= to automate building and deploying this site. I don't know if I can entrust it to a cron job yet because the deployment involves ssh, and I'm a bit fuzzy on the workings of key management in such circumstances

** DONE [2025-09-08 Mon 07:22] :emacs:temptations:
CLOSED: [2025-09-08 Mon 07:27]
:PROPERTIES:
:export_file_name: 9
:END:

The pull of "One Big Text File" is strong

I'm semi-seriously contemplating pulling the Hugo theme that I use to generate this website into a single Org file and using Org's Literate Programming tooling to spit it out into individual layout files.

I may need an intervention.

** DONE [2025-09-09 Tue 06:55] :emacs:hugo:kaizen:
CLOSED: [2025-09-09 Tue 07:51]
:PROPERTIES:
:export_file_name: 10
:END:

Progress!

@@hugo:{{%newthought %}}@@Before:@@hugo:{{% /newthought %}}@@

#+begin_example
./data/mentions/3f256ff[...]494.json
./data/mentions/62afe34[...]020.json
...
#+end_example

Hmm, so which file pertains to which post?

#+begin_src go-html-template
{{ $slug := .RelPermalink | sha256 }}
{{ $all_mentions := index site.Data.mentions $slug | default slice }}
{{ $likes := where $all_mentions "wm-property" "like-of" }}
#+end_src

At least the template code to get at it is more or less sane.

@@hugo:{{%newthought %}}@@During:@@hugo:{{% /newthought %}}@@

#+begin_example
./data/mentions/note/8/mentions.json
./data/mentions/note/9/mentions.json
#+end_example

Well, that's clear as day!

#+begin_src go-html-template
{{ $key := (split path.Dir .RelPermalink) "/" | after 1 | append "mentions" }}
{{ $all_mentions := index site.Data.mentions $key | default slice }}
{{ $likes := where $all_mentions "wm-property" "like-of" }}
#+end_src

What the actual fuck? I /want/ to write ~{{ index site.Data.mentions .RelPermalink }}~ and have done with it. To the data mungery!

@@hugo:{{%newthought %}}@@Now@@hugo:{{% /newthought %}}@@

#+begin_example
./data/mentions/all.json
#+end_example

That's a tad more opaque, isn't it? Ah well, there's always =jq=. I can't see what's got new mentions from git status any more, but also, I can't forget to add any new data files either. Call it a win on aggregate.

#+begin_src go-html-template
{{ $all_mentions = index site.Data.mentions.all .RelPermalink | default dict }}
{{ $likes := index $all_mentions "like-of" | default slice }}
#+end_src

Well structured data for the win! And I'm working on eliminating the annoying ~default dict~ and ~default slice~ in that too.
** DONE [2025-09-10 Wed 06:38]
CLOSED: [2025-09-10 Wed 06:40]
:PROPERTIES:
:export_file_name: 11
:END:
Oh! The reason Hugo didn't load =data/mentions.json= was that the directory =data/mentions/= exists!

Moved the webmentions data to =data/webmentions.json= and all is fine.

** DONE [2025-09-10 Wed 07:15] :fingers_crossed:automation:
CLOSED: [2025-09-10 Wed 07:16]
:PROPERTIES:
:export_file_name: 12
:END:
All being well, this note was deployed here by a cron job, and all the webmentions data got updated too.

All being well…
** DONE [2025-09-11 Thu 08:21] :indieweb:webmentions:
CLOSED: [2025-09-11 Thu 08:25]
:PROPERTIES:
:export_file_name: 13
:END:
Now I can display received Webmentions, I need to start working on sending them.

I don't want to rely on an external service if I can help it, because that's how my old setup decayed, so don't hold your breath.

But the output of =rsync --itemize-changes ...= is looking tasty as a mechanism for spotting which URLs have changed between deployment runs.

Time to start experimenting.

Hmm… the first experiment doesn't look too promising.
** DONE [2025-09-11 Thu 16:27]
CLOSED: [2025-09-13 Sat 14:07]
:PROPERTIES:
:export_file_name: 14
:export_hugo_custom_front_matter: :mentions '(((url . "/note/13/") (type . in-reply-to)))
:END:
Further to my [[*\[2025-09-11 Thu 08:21\]][last note]], I think I might have a working script to send webmentions for any updated pages.  Now to plumb it into the rest of the automation!

~#!/usr/bin/env emacs -script~ is a powerful drug!
** DONE [2025-09-20 Sat 09:50]
CLOSED: [2025-09-20 Sat 09:59]
:PROPERTIES:
:EXPORT_FILE_NAME: 15
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :mentions '(((url . "https://bofh.org.uk/2003/08/01/the-fine-art-of-complexity-management/") (type . in-reply-to)))
:END:
For… reasons, I found myself trawling back through the early entries here and found that a bunch of them had been truncated at some point in the blog's history of migrating from engine to engine. Luckily, the [[https://web.archive.org/][Wayback Machine]] has a sufficiently complete archive, so I'm slowly working my way through the broken posts, bringing them into the big old =Content.org= file that the site's generated from and adding a margin note or two to supply a bit of 2025 context where appropriate. [[https://bofh.org.uk/2003/08/01/the-fine-art-of-complexity-management/][The Fine Art of Complexity Management]] is the first post to receive such attention. Twenty two years on, I still think it's good advice.

* COMMENT Local Variables :ARCHIVE:

* Footnotes

[fn:1] [[https://gohugo.io][Hugo]] is the static site generator I use to build this blog. Another example of letting the computer do all the fiddly repetitive bits. In this case, to handle all the fiddly bits of writing full HTML pages, building index pages and the rest.

[fn:2] Real Tempest machines have a gorgeously weighted 'spinner' -- a free spinning rotary encoder with enough resolution that there still multiple 'steps' per tube segment. It meant that your blaster had a lovely fluid movement with very direct control. Basically, Tempest is pretty damned close to perfect on its original hardware and if you ever get the chance to play on a well maintained machine, you should grab it!

[fn:3] It's also annoyingly temperamental at the moment; I'm working on that though.

[fn:4]  @@html:<dfn><code>org-mode</code></dfn>@@ is an Emacs outliner that grew into a calendar/outliner/spreadsheet/document processor/literate programming tool/dessert wax/floor topping.

It's what I used to use [[https://bofh.org.uk/2019/02/25/baking-with-emacs/][to manage my bakery]], and it's amazing.

Like Emacs itself, it's almost infinitely flexible, which makes it incredibly hard to get started with. There's oodles of org configurations out there to crib from and all of them are a mixture of the useful and irrelevant, because it turns out that people have different opinions about how they want to organise their writing and/or life. My config is very much under construction.

[fn:5] The Github Actions based build process is also substantially more reliable than the hand rolled server hook I was using. There's something to be said assembling your build pipeline from a bunch of stuff that lots of other people use (and maintain). Also, it reduces the number of moving parts on the Raspberry Pi that's serving these pages, which is no bad thing.

[fn:6] An @@html:<dfn>@@h-entry@@html:</dfn>@@ is something that a web user might want to mention. At present, all the h-entries on this site are articles, but other people use them to mark up photos, videos, notes, calendar entries or anything else that makes sense to think of as an entry in a collection of stuff. If you'll look at this page in your browser's inspector, you'll see that the content is wrapped in ~<article class="h-entry" …>…</article>~ tags. Other tags within that block are are marked with other classes (so the title has ~p-name~ and the body has ~e-content~), according to the definition of the [[http://microformats.org/wiki/h-entry][h-entry microformat]]. By marking my site up with these micropformats, life becomes much easier for any IndieWeb tools to extract appropriate information from the site.

[fn:7] I used the delightfully named [[https://www.expert-sleepers.co.uk/augustusloop.html][Augustus Loop]] from Expert Sleepers combined with a Lua script I wrote to make it behave more or less the way I wanted it to. Kind of fiddly to set up, but repaid the effort. There's still a few things that AL can do that I can't do with Loopy Pro, but as I write those are due in the next big Loopy patch.

[fn:8] Logic isn't really set up to do live sound, but MainStage, which is, can't do multi track recording and playback and I couldn't work out how to configure its looper to emulate that. So I just used Logic.

[fn:9] Catch me every Friday night at [[https://youtube.com/pierscawley/live]] from 8pm UK Time.

[fn:10] I tried a few of the Zoom singarounds that sprang up, but for reasons I can't quite put my finger on, I found them far more stressful than just singing to the camer and interacting with an audience in text chat. The audio only Clubhouse ballad sessions that I started were way less stressy for me too.

[fn:11] And a fancy dual-USB audio interface that means I can capture Loopy's audio really cleanly. Check out the [[https://www.amazon.co.uk/iConnectivity-AUDIO4c-Interface-Streaming-Performance/dp/B092L7TXL1?crid=2DB9Z9YW1UMFK&keywords=iconnectivity+audio4c&qid=1686042094&sprefix=iconnectivity+audio4c%2Caps%2C107&sr=8-5&linkCode=ll1&tag=justasummary-21&linkId=7d14e0bff14f201073ea18059f5abde5&language=en_GB&ref_=as_li_ss_tl][iConnectivity AUDIO4c]] (affiliate link) if that's a thing you might need. There are other dual-USB audio interfaces that are probably at least as good, but this is the one I've got experience of using.

[fn:12] Check out @@hugo:{{< embed "https://youtu.be/hWPmADRfPFQ" />}}@@ for an example.

[fn:13] I don't actually do that, because I have a slightly more complex setup that supports multiple song structures with the same set of clips. I'll explain all that later.

[fn:14]  The Pragmatic Programmers are fine people. Rails is a well thought
out and documented framework. However, I'm really struggling to come up
with a pithy description of the picture on the cover of /Agile Web
Development with Rails./ Do I lack the word power, or have Dave and
David dropped the ball on cover design?

# Local Variables:
# org-log-into-drawer: "LOGBOOK"
# org-hugo-suppress-lastmod-period: 86400.0
# eval: (org-transclusion-mode t)
# eval: (org-hugo-auto-export-mode t)
# End:
